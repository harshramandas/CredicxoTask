{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>TASK - HARSH RAMAN</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><bold><h1>ANSWER</h1></bold></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Importing Dataset</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('musk_csv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>molecule_name</th>\n",
       "      <th>conformation_name</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>...</th>\n",
       "      <th>f158</th>\n",
       "      <th>f159</th>\n",
       "      <th>f160</th>\n",
       "      <th>f161</th>\n",
       "      <th>f162</th>\n",
       "      <th>f163</th>\n",
       "      <th>f164</th>\n",
       "      <th>f165</th>\n",
       "      <th>f166</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>MUSK-211</td>\n",
       "      <td>211_1+1</td>\n",
       "      <td>46</td>\n",
       "      <td>-108</td>\n",
       "      <td>-60</td>\n",
       "      <td>-69</td>\n",
       "      <td>-117</td>\n",
       "      <td>49</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>-308</td>\n",
       "      <td>52</td>\n",
       "      <td>-7</td>\n",
       "      <td>39</td>\n",
       "      <td>126</td>\n",
       "      <td>156</td>\n",
       "      <td>-50</td>\n",
       "      <td>-112</td>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>MUSK-211</td>\n",
       "      <td>211_1+10</td>\n",
       "      <td>41</td>\n",
       "      <td>-188</td>\n",
       "      <td>-145</td>\n",
       "      <td>22</td>\n",
       "      <td>-117</td>\n",
       "      <td>-6</td>\n",
       "      <td>57</td>\n",
       "      <td>...</td>\n",
       "      <td>-59</td>\n",
       "      <td>-2</td>\n",
       "      <td>52</td>\n",
       "      <td>103</td>\n",
       "      <td>136</td>\n",
       "      <td>169</td>\n",
       "      <td>-61</td>\n",
       "      <td>-136</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>MUSK-211</td>\n",
       "      <td>211_1+11</td>\n",
       "      <td>46</td>\n",
       "      <td>-194</td>\n",
       "      <td>-145</td>\n",
       "      <td>28</td>\n",
       "      <td>-117</td>\n",
       "      <td>73</td>\n",
       "      <td>57</td>\n",
       "      <td>...</td>\n",
       "      <td>-134</td>\n",
       "      <td>-154</td>\n",
       "      <td>57</td>\n",
       "      <td>143</td>\n",
       "      <td>142</td>\n",
       "      <td>165</td>\n",
       "      <td>-67</td>\n",
       "      <td>-145</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>MUSK-211</td>\n",
       "      <td>211_1+12</td>\n",
       "      <td>41</td>\n",
       "      <td>-188</td>\n",
       "      <td>-145</td>\n",
       "      <td>22</td>\n",
       "      <td>-117</td>\n",
       "      <td>-7</td>\n",
       "      <td>57</td>\n",
       "      <td>...</td>\n",
       "      <td>-60</td>\n",
       "      <td>-4</td>\n",
       "      <td>52</td>\n",
       "      <td>104</td>\n",
       "      <td>136</td>\n",
       "      <td>168</td>\n",
       "      <td>-60</td>\n",
       "      <td>-135</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>MUSK-211</td>\n",
       "      <td>211_1+13</td>\n",
       "      <td>41</td>\n",
       "      <td>-188</td>\n",
       "      <td>-145</td>\n",
       "      <td>22</td>\n",
       "      <td>-117</td>\n",
       "      <td>-7</td>\n",
       "      <td>57</td>\n",
       "      <td>...</td>\n",
       "      <td>-60</td>\n",
       "      <td>-4</td>\n",
       "      <td>52</td>\n",
       "      <td>104</td>\n",
       "      <td>137</td>\n",
       "      <td>168</td>\n",
       "      <td>-60</td>\n",
       "      <td>-135</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 170 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID molecule_name conformation_name  f1   f2   f3  f4   f5  f6  f7  ...    \\\n",
       "0   1      MUSK-211           211_1+1  46 -108  -60 -69 -117  49  38  ...     \n",
       "1   2      MUSK-211          211_1+10  41 -188 -145  22 -117  -6  57  ...     \n",
       "2   3      MUSK-211          211_1+11  46 -194 -145  28 -117  73  57  ...     \n",
       "3   4      MUSK-211          211_1+12  41 -188 -145  22 -117  -7  57  ...     \n",
       "4   5      MUSK-211          211_1+13  41 -188 -145  22 -117  -7  57  ...     \n",
       "\n",
       "   f158  f159  f160  f161  f162  f163  f164  f165  f166  class  \n",
       "0  -308    52    -7    39   126   156   -50  -112    96      1  \n",
       "1   -59    -2    52   103   136   169   -61  -136    79      1  \n",
       "2  -134  -154    57   143   142   165   -67  -145    39      1  \n",
       "3   -60    -4    52   104   136   168   -60  -135    80      1  \n",
       "4   -60    -4    52   104   137   168   -60  -135    80      1  \n",
       "\n",
       "[5 rows x 170 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Train - Test Split</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "independentVariables = dataset.iloc[:, 3:-1].values\n",
    "dependentVariables = dataset.iloc[:, -1].values\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(independentVariables, dependentVariables, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5278, 166) (1320, 166) (5278,) (1320,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Standard Scaling</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harshramandas/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Embedding, Flatten, LeakyReLU, PReLU, ELU, BatchNormalization, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Creating a Sequential Model</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Adding a dense hidden layer and activating it with a relu as regression</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(units = 120, kernel_initializer = 'he_uniform', activation = 'relu', input_dim = 166))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(units = 6, kernel_initializer = 'he_uniform', activation = 'relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Adding Final layer with sigmoid activation for a binary classification.</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(units = 1, kernel_initializer = 'glorot_uniform', activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_441 (Dense)            (None, 120)               20040     \n",
      "_________________________________________________________________\n",
      "dense_442 (Dense)            (None, 6)                 726       \n",
      "_________________________________________________________________\n",
      "dense_443 (Dense)            (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 20,773\n",
      "Trainable params: 20,773\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Training the model</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "Train on 4222 samples, validate on 1056 samples\n",
      "Epoch 1/40\n",
      "4222/4222 [==============================] - 12s 3ms/step - loss: 0.2699 - acc: 0.8920 - val_loss: 0.1768 - val_acc: 0.9309\n",
      "Epoch 2/40\n",
      "4222/4222 [==============================] - 0s 107us/step - loss: 0.1435 - acc: 0.9432 - val_loss: 0.1317 - val_acc: 0.9545\n",
      "Epoch 3/40\n",
      "4222/4222 [==============================] - 0s 109us/step - loss: 0.1066 - acc: 0.9621 - val_loss: 0.1220 - val_acc: 0.9555\n",
      "Epoch 4/40\n",
      "4222/4222 [==============================] - 0s 112us/step - loss: 0.0865 - acc: 0.9709 - val_loss: 0.0990 - val_acc: 0.9650\n",
      "Epoch 5/40\n",
      "4222/4222 [==============================] - 0s 109us/step - loss: 0.0718 - acc: 0.9768 - val_loss: 0.0864 - val_acc: 0.9706\n",
      "Epoch 6/40\n",
      "4222/4222 [==============================] - 0s 110us/step - loss: 0.0573 - acc: 0.9808 - val_loss: 0.0746 - val_acc: 0.9716\n",
      "Epoch 7/40\n",
      "4222/4222 [==============================] - 0s 111us/step - loss: 0.0482 - acc: 0.9834 - val_loss: 0.0710 - val_acc: 0.9744\n",
      "Epoch 8/40\n",
      "4222/4222 [==============================] - 0s 110us/step - loss: 0.0401 - acc: 0.9848 - val_loss: 0.0634 - val_acc: 0.9754\n",
      "Epoch 9/40\n",
      "4222/4222 [==============================] - 0s 111us/step - loss: 0.0336 - acc: 0.9886 - val_loss: 0.0601 - val_acc: 0.9763\n",
      "Epoch 10/40\n",
      "4222/4222 [==============================] - 0s 112us/step - loss: 0.0300 - acc: 0.9912 - val_loss: 0.0498 - val_acc: 0.9839\n",
      "Epoch 11/40\n",
      "4222/4222 [==============================] - 0s 109us/step - loss: 0.0218 - acc: 0.9950 - val_loss: 0.0463 - val_acc: 0.9820\n",
      "Epoch 12/40\n",
      "4222/4222 [==============================] - 0s 111us/step - loss: 0.0201 - acc: 0.9948 - val_loss: 0.0493 - val_acc: 0.9848\n",
      "Epoch 13/40\n",
      "4222/4222 [==============================] - 0s 110us/step - loss: 0.0173 - acc: 0.9953 - val_loss: 0.0433 - val_acc: 0.9839\n",
      "Epoch 14/40\n",
      "4222/4222 [==============================] - 0s 110us/step - loss: 0.0128 - acc: 0.9981 - val_loss: 0.0369 - val_acc: 0.9886\n",
      "Epoch 15/40\n",
      "4222/4222 [==============================] - 0s 109us/step - loss: 0.0092 - acc: 0.9988 - val_loss: 0.0368 - val_acc: 0.9905\n",
      "Epoch 16/40\n",
      "4222/4222 [==============================] - 0s 110us/step - loss: 0.0080 - acc: 0.9995 - val_loss: 0.0359 - val_acc: 0.9877\n",
      "Epoch 17/40\n",
      "4222/4222 [==============================] - 0s 108us/step - loss: 0.0077 - acc: 0.9988 - val_loss: 0.0587 - val_acc: 0.9801\n",
      "Epoch 18/40\n",
      "4222/4222 [==============================] - 0s 109us/step - loss: 0.0078 - acc: 0.9983 - val_loss: 0.0352 - val_acc: 0.9877\n",
      "Epoch 19/40\n",
      "4222/4222 [==============================] - 1s 130us/step - loss: 0.0059 - acc: 0.9993 - val_loss: 0.0363 - val_acc: 0.9877\n",
      "Epoch 20/40\n",
      "4222/4222 [==============================] - 1s 129us/step - loss: 0.0039 - acc: 0.9998 - val_loss: 0.0315 - val_acc: 0.9905\n",
      "Epoch 21/40\n",
      "4222/4222 [==============================] - 1s 135us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0308 - val_acc: 0.9934\n",
      "Epoch 22/40\n",
      "4222/4222 [==============================] - 0s 114us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0305 - val_acc: 0.9924\n",
      "Epoch 23/40\n",
      "4222/4222 [==============================] - 0s 112us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0308 - val_acc: 0.9915\n",
      "Epoch 24/40\n",
      "4222/4222 [==============================] - 0s 111us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0297 - val_acc: 0.9905\n",
      "Epoch 25/40\n",
      "4222/4222 [==============================] - 0s 111us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0313 - val_acc: 0.9915\n",
      "Epoch 26/40\n",
      "4222/4222 [==============================] - 0s 112us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0310 - val_acc: 0.9905\n",
      "Epoch 27/40\n",
      "4222/4222 [==============================] - 0s 111us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0289 - val_acc: 0.9915\n",
      "Epoch 28/40\n",
      "4222/4222 [==============================] - 0s 112us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0326 - val_acc: 0.9915\n",
      "Epoch 29/40\n",
      "4222/4222 [==============================] - 0s 112us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0297 - val_acc: 0.9934\n",
      "Epoch 30/40\n",
      "4222/4222 [==============================] - 0s 112us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0347 - val_acc: 0.9905\n",
      "Epoch 31/40\n",
      "4222/4222 [==============================] - 0s 111us/step - loss: 8.7634e-04 - acc: 1.0000 - val_loss: 0.0287 - val_acc: 0.9934\n",
      "Epoch 32/40\n",
      "4222/4222 [==============================] - 0s 112us/step - loss: 7.1153e-04 - acc: 1.0000 - val_loss: 0.0298 - val_acc: 0.9924\n",
      "Epoch 33/40\n",
      "4222/4222 [==============================] - 0s 111us/step - loss: 6.8277e-04 - acc: 1.0000 - val_loss: 0.0292 - val_acc: 0.9943\n",
      "Epoch 34/40\n",
      "4222/4222 [==============================] - 1s 120us/step - loss: 5.8658e-04 - acc: 1.0000 - val_loss: 0.0298 - val_acc: 0.9934\n",
      "Epoch 35/40\n",
      "4222/4222 [==============================] - 1s 135us/step - loss: 5.3840e-04 - acc: 1.0000 - val_loss: 0.0300 - val_acc: 0.9924\n",
      "Epoch 36/40\n",
      "4222/4222 [==============================] - 1s 133us/step - loss: 4.9045e-04 - acc: 1.0000 - val_loss: 0.0311 - val_acc: 0.9924\n",
      "Epoch 37/40\n",
      "4222/4222 [==============================] - 1s 120us/step - loss: 4.9098e-04 - acc: 1.0000 - val_loss: 0.0322 - val_acc: 0.9915\n",
      "Epoch 38/40\n",
      "4222/4222 [==============================] - 0s 116us/step - loss: 4.7976e-04 - acc: 1.0000 - val_loss: 0.0308 - val_acc: 0.9915\n",
      "Epoch 39/40\n",
      "4222/4222 [==============================] - 1s 136us/step - loss: 5.2064e-04 - acc: 1.0000 - val_loss: 0.0321 - val_acc: 0.9924\n",
      "Epoch 40/40\n",
      "4222/4222 [==============================] - 1s 120us/step - loss: 3.7710e-04 - acc: 1.0000 - val_loss: 0.0295 - val_acc: 0.9943\n"
     ]
    }
   ],
   "source": [
    "model = classifier.fit(X_train, y_train, validation_split = 0.2, batch_size = 50, nb_epoch = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Saving the model.</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.save_weights(\"classifier.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
     ]
    }
   ],
   "source": [
    "print(model.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Plotting accuracy curve</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(model.history['acc'])\n",
    "plt.plot(model.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Plotting loss curve.</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(model.history['loss'])\n",
    "plt.plot(model.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Confusion Matrix</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1117    3]\n",
      " [   6  194]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Accuracy and Loss Score</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = classifier.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9931818181818182  and Loss: 0.04057913881230034\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",acc,\" and Loss:\",loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>F1 score, Precision and Recall.</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  0.9866587457648817\n",
      "Precision:  0.9836607142857143\n",
      "Recall:  0.9897143709516297\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 score: \", f1_score(y_pred, y_test,average=\"macro\"))\n",
    "print(\"Precision: \", precision_score(y_pred, y_test,average=\"macro\"))\n",
    "print(\"Recall: \", recall_score(y_pred, y_test,average=\"macro\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Trial Runs/Rough Work</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h2>Using Grid Search to find optimum no. of layers, epochs and batch size.</h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h3>This was taking huge time in my machine and Google collab, so I tried doing it manually.</h3></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from tensorflow.keras.activations import relu, sigmoid\n",
    "\n",
    "# def create_model(layers, activation):\n",
    "#     model = Sequential()\n",
    "#     for i, nodes in enumerate(layers):\n",
    "#         if i==0:\n",
    "#             model.add(Dense(nodes,input_dim=X_train.shape[1]))\n",
    "#             model.add(Activation(activation))\n",
    "#             model.add(Dropout(0.3))\n",
    "#         else:\n",
    "#             model.add(Dense(nodes))\n",
    "#             model.add(Activation(activation))\n",
    "#             model.add(Dropout(0.3))\n",
    "            \n",
    "#     model.add(Dense(units = 1, kernel_initializer= 'glorot_uniform', activation = 'sigmoid')) \n",
    "    \n",
    "#     model.compile(optimizer='adam', loss='binary_crossentropy',metrics=['accuracy'])\n",
    "#     return model\n",
    "\n",
    "# model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "\n",
    "# layers = [[6, 6, 3], [40, 20, 6]]\n",
    "# activations = ['sigmoid', 'relu']\n",
    "# param_grid = dict(layers=layers, activation=activations, batch_size = [10], epochs=[100])\n",
    "# grid = GridSearchCV(estimator=model, param_grid=param_grid,cv=5)\n",
    "\n",
    "# grid_result = grid.fit(X_train, y_train)\n",
    "# print(grid_result.best_score_,grid_result.best_params_)\n",
    "# y_pred = grid.predict(X_test)\n",
    "# y_pred = (y_pred > 0.5)\n",
    "# cm = confusion_matrix(y_test, y_pred)\n",
    "# score = accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Multi Layered Neural Network. Several Test Runs.</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Simple Sequential model with [6,6,1] layers, batch size = 10 and epochs = 100</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(units = 6, kernel_initializer = 'he_uniform', activation = 'relu', input_dim = 166))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(units = 6, kernel_initializer = 'he_uniform', activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classifier.add(Dense(units = 1, kernel_initializer = 'glorot_uniform', activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_361 (Dense)            (None, 6)                 1002      \n",
      "_________________________________________________________________\n",
      "dense_362 (Dense)            (None, 6)                 42        \n",
      "_________________________________________________________________\n",
      "dense_363 (Dense)            (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 1,051\n",
      "Trainable params: 1,051\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "Train on 4222 samples, validate on 1056 samples\n",
      "Epoch 1/100\n",
      "4222/4222 [==============================] - 12s 3ms/step - loss: 0.3303 - acc: 0.8477 - val_loss: 0.2521 - val_acc: 0.8892\n",
      "Epoch 2/100\n",
      "4222/4222 [==============================] - 2s 485us/step - loss: 0.2116 - acc: 0.9157 - val_loss: 0.1720 - val_acc: 0.9422\n",
      "Epoch 3/100\n",
      "4222/4222 [==============================] - 2s 468us/step - loss: 0.1398 - acc: 0.9479 - val_loss: 0.1349 - val_acc: 0.9564\n",
      "Epoch 4/100\n",
      "4222/4222 [==============================] - 2s 451us/step - loss: 0.1132 - acc: 0.9612 - val_loss: 0.1174 - val_acc: 0.9612\n",
      "Epoch 5/100\n",
      "4222/4222 [==============================] - 2s 488us/step - loss: 0.0967 - acc: 0.9661 - val_loss: 0.1027 - val_acc: 0.9650\n",
      "Epoch 6/100\n",
      "4222/4222 [==============================] - 2s 469us/step - loss: 0.0829 - acc: 0.9702 - val_loss: 0.0920 - val_acc: 0.9687\n",
      "Epoch 7/100\n",
      "4222/4222 [==============================] - 2s 458us/step - loss: 0.0740 - acc: 0.9744 - val_loss: 0.0862 - val_acc: 0.9669\n",
      "Epoch 8/100\n",
      "4222/4222 [==============================] - 2s 529us/step - loss: 0.0656 - acc: 0.9761 - val_loss: 0.0811 - val_acc: 0.9706\n",
      "Epoch 9/100\n",
      "4222/4222 [==============================] - 2s 507us/step - loss: 0.0582 - acc: 0.9792 - val_loss: 0.0876 - val_acc: 0.9669\n",
      "Epoch 10/100\n",
      "4222/4222 [==============================] - 2s 479us/step - loss: 0.0509 - acc: 0.9825 - val_loss: 0.0757 - val_acc: 0.9697\n",
      "Epoch 11/100\n",
      "4222/4222 [==============================] - 2s 488us/step - loss: 0.0463 - acc: 0.9832 - val_loss: 0.0616 - val_acc: 0.9782\n",
      "Epoch 12/100\n",
      "4222/4222 [==============================] - 2s 508us/step - loss: 0.0391 - acc: 0.9882 - val_loss: 0.0607 - val_acc: 0.9763\n",
      "Epoch 13/100\n",
      "4222/4222 [==============================] - 2s 431us/step - loss: 0.0344 - acc: 0.9882 - val_loss: 0.0590 - val_acc: 0.9763\n",
      "Epoch 14/100\n",
      "4222/4222 [==============================] - 2s 425us/step - loss: 0.0335 - acc: 0.9858 - val_loss: 0.0632 - val_acc: 0.9811\n",
      "Epoch 15/100\n",
      "4222/4222 [==============================] - 2s 471us/step - loss: 0.0265 - acc: 0.9898 - val_loss: 0.0540 - val_acc: 0.9792\n",
      "Epoch 16/100\n",
      "4222/4222 [==============================] - 2s 513us/step - loss: 0.0219 - acc: 0.9924 - val_loss: 0.0457 - val_acc: 0.9848\n",
      "Epoch 17/100\n",
      "4222/4222 [==============================] - 2s 477us/step - loss: 0.0188 - acc: 0.9946 - val_loss: 0.0437 - val_acc: 0.9839\n",
      "Epoch 18/100\n",
      "4222/4222 [==============================] - 2s 501us/step - loss: 0.0152 - acc: 0.9960 - val_loss: 0.0424 - val_acc: 0.9867\n",
      "Epoch 19/100\n",
      "4222/4222 [==============================] - 2s 538us/step - loss: 0.0161 - acc: 0.9934 - val_loss: 0.0423 - val_acc: 0.9848\n",
      "Epoch 20/100\n",
      "4222/4222 [==============================] - 2s 434us/step - loss: 0.0126 - acc: 0.9957 - val_loss: 0.0363 - val_acc: 0.9896\n",
      "Epoch 21/100\n",
      "4222/4222 [==============================] - 2s 515us/step - loss: 0.0102 - acc: 0.9981 - val_loss: 0.0355 - val_acc: 0.9886\n",
      "Epoch 22/100\n",
      "4222/4222 [==============================] - 2s 465us/step - loss: 0.0079 - acc: 0.9988 - val_loss: 0.0392 - val_acc: 0.9848\n",
      "Epoch 23/100\n",
      "4222/4222 [==============================] - 2s 544us/step - loss: 0.0078 - acc: 0.9983 - val_loss: 0.0508 - val_acc: 0.9801\n",
      "Epoch 24/100\n",
      "4222/4222 [==============================] - 2s 531us/step - loss: 0.0080 - acc: 0.9988 - val_loss: 0.0385 - val_acc: 0.9896\n",
      "Epoch 25/100\n",
      "4222/4222 [==============================] - 2s 429us/step - loss: 0.0067 - acc: 0.9979 - val_loss: 0.0339 - val_acc: 0.9877\n",
      "Epoch 26/100\n",
      "4222/4222 [==============================] - 2s 452us/step - loss: 0.0083 - acc: 0.9976 - val_loss: 0.0476 - val_acc: 0.9896\n",
      "Epoch 27/100\n",
      "4222/4222 [==============================] - 2s 444us/step - loss: 0.0084 - acc: 0.9974 - val_loss: 0.0499 - val_acc: 0.9886\n",
      "Epoch 28/100\n",
      "4222/4222 [==============================] - 2s 467us/step - loss: 0.0035 - acc: 0.9995 - val_loss: 0.0508 - val_acc: 0.9886\n",
      "Epoch 29/100\n",
      "4222/4222 [==============================] - 2s 458us/step - loss: 0.0032 - acc: 0.9995 - val_loss: 0.0407 - val_acc: 0.9915\n",
      "Epoch 30/100\n",
      "4222/4222 [==============================] - 2s 464us/step - loss: 0.0035 - acc: 0.9991 - val_loss: 0.0484 - val_acc: 0.9886\n",
      "Epoch 31/100\n",
      "4222/4222 [==============================] - 2s 495us/step - loss: 0.0031 - acc: 0.9993 - val_loss: 0.0539 - val_acc: 0.9905\n",
      "Epoch 32/100\n",
      "4222/4222 [==============================] - 2s 476us/step - loss: 0.0083 - acc: 0.9972 - val_loss: 0.0410 - val_acc: 0.9896\n",
      "Epoch 33/100\n",
      "4222/4222 [==============================] - 2s 471us/step - loss: 0.0034 - acc: 0.9995 - val_loss: 0.0410 - val_acc: 0.9915\n",
      "Epoch 34/100\n",
      "4222/4222 [==============================] - 2s 458us/step - loss: 0.0088 - acc: 0.9967 - val_loss: 0.0461 - val_acc: 0.9896\n",
      "Epoch 35/100\n",
      "4222/4222 [==============================] - 2s 455us/step - loss: 0.0025 - acc: 0.9995 - val_loss: 0.0498 - val_acc: 0.9896\n",
      "Epoch 36/100\n",
      "4222/4222 [==============================] - 2s 427us/step - loss: 0.0022 - acc: 0.9995 - val_loss: 0.0437 - val_acc: 0.9915\n",
      "Epoch 37/100\n",
      "4222/4222 [==============================] - 2s 456us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0436 - val_acc: 0.9924\n",
      "Epoch 38/100\n",
      "4222/4222 [==============================] - 2s 483us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0471 - val_acc: 0.9905\n",
      "Epoch 39/100\n",
      "4222/4222 [==============================] - 2s 436us/step - loss: 7.3419e-04 - acc: 1.0000 - val_loss: 0.0459 - val_acc: 0.9915\n",
      "Epoch 40/100\n",
      "4222/4222 [==============================] - 2s 432us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0483 - val_acc: 0.9915\n",
      "Epoch 41/100\n",
      "4222/4222 [==============================] - 2s 477us/step - loss: 0.0174 - acc: 0.9934 - val_loss: 0.0509 - val_acc: 0.9886\n",
      "Epoch 42/100\n",
      "4222/4222 [==============================] - 2s 542us/step - loss: 0.0045 - acc: 0.9979 - val_loss: 0.0468 - val_acc: 0.9905\n",
      "Epoch 43/100\n",
      "4222/4222 [==============================] - 2s 447us/step - loss: 0.0014 - acc: 0.9998 - val_loss: 0.0377 - val_acc: 0.9915\n",
      "Epoch 44/100\n",
      "4222/4222 [==============================] - 2s 441us/step - loss: 6.5822e-04 - acc: 1.0000 - val_loss: 0.0400 - val_acc: 0.9924\n",
      "Epoch 45/100\n",
      "4222/4222 [==============================] - 2s 439us/step - loss: 0.0012 - acc: 0.9998 - val_loss: 0.0363 - val_acc: 0.9924\n",
      "Epoch 46/100\n",
      "4222/4222 [==============================] - 2s 467us/step - loss: 7.9312e-04 - acc: 1.0000 - val_loss: 0.0388 - val_acc: 0.9915\n",
      "Epoch 47/100\n",
      "4222/4222 [==============================] - 2s 439us/step - loss: 6.3180e-04 - acc: 1.0000 - val_loss: 0.0359 - val_acc: 0.9915\n",
      "Epoch 48/100\n",
      "4222/4222 [==============================] - 2s 429us/step - loss: 4.1486e-04 - acc: 1.0000 - val_loss: 0.0355 - val_acc: 0.9915\n",
      "Epoch 49/100\n",
      "4222/4222 [==============================] - 2s 429us/step - loss: 4.6744e-04 - acc: 1.0000 - val_loss: 0.0378 - val_acc: 0.9924\n",
      "Epoch 50/100\n",
      "4222/4222 [==============================] - 2s 428us/step - loss: 0.0016 - acc: 0.9998 - val_loss: 0.0441 - val_acc: 0.9915\n",
      "Epoch 51/100\n",
      "4222/4222 [==============================] - 2s 431us/step - loss: 0.0205 - acc: 0.9931 - val_loss: 0.0471 - val_acc: 0.9905\n",
      "Epoch 52/100\n",
      "4222/4222 [==============================] - 2s 433us/step - loss: 0.0115 - acc: 0.9974 - val_loss: 0.0335 - val_acc: 0.9924\n",
      "Epoch 53/100\n",
      "4222/4222 [==============================] - 2s 430us/step - loss: 0.0020 - acc: 0.9993 - val_loss: 0.0383 - val_acc: 0.9915\n",
      "Epoch 54/100\n",
      "4222/4222 [==============================] - 2s 436us/step - loss: 8.4194e-04 - acc: 0.9998 - val_loss: 0.0375 - val_acc: 0.9924\n",
      "Epoch 55/100\n",
      "4222/4222 [==============================] - 2s 428us/step - loss: 4.9739e-04 - acc: 1.0000 - val_loss: 0.0348 - val_acc: 0.9934\n",
      "Epoch 56/100\n",
      "4222/4222 [==============================] - 2s 431us/step - loss: 3.9668e-04 - acc: 1.0000 - val_loss: 0.0367 - val_acc: 0.9915\n",
      "Epoch 57/100\n",
      "4222/4222 [==============================] - 2s 433us/step - loss: 3.5529e-04 - acc: 1.0000 - val_loss: 0.0363 - val_acc: 0.9915\n",
      "Epoch 58/100\n",
      "4222/4222 [==============================] - 2s 431us/step - loss: 3.2793e-04 - acc: 1.0000 - val_loss: 0.0377 - val_acc: 0.9915\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4222/4222 [==============================] - 2s 432us/step - loss: 3.2693e-04 - acc: 1.0000 - val_loss: 0.0406 - val_acc: 0.9915\n",
      "Epoch 60/100\n",
      "4222/4222 [==============================] - 2s 450us/step - loss: 2.8008e-04 - acc: 1.0000 - val_loss: 0.0401 - val_acc: 0.9924\n",
      "Epoch 61/100\n",
      "4222/4222 [==============================] - 2s 451us/step - loss: 3.1947e-04 - acc: 1.0000 - val_loss: 0.0507 - val_acc: 0.9867\n",
      "Epoch 62/100\n",
      "4222/4222 [==============================] - 2s 428us/step - loss: 0.0260 - acc: 0.9941 - val_loss: 0.0555 - val_acc: 0.9877\n",
      "Epoch 63/100\n",
      "4222/4222 [==============================] - 2s 424us/step - loss: 0.0021 - acc: 0.9993 - val_loss: 0.0460 - val_acc: 0.9905\n",
      "Epoch 64/100\n",
      "4222/4222 [==============================] - 2s 440us/step - loss: 5.5123e-04 - acc: 1.0000 - val_loss: 0.0397 - val_acc: 0.9905\n",
      "Epoch 65/100\n",
      "4222/4222 [==============================] - 2s 509us/step - loss: 2.9421e-04 - acc: 1.0000 - val_loss: 0.0399 - val_acc: 0.9905\n",
      "Epoch 66/100\n",
      "4222/4222 [==============================] - 2s 506us/step - loss: 2.8516e-04 - acc: 1.0000 - val_loss: 0.0391 - val_acc: 0.9905\n",
      "Epoch 67/100\n",
      "4222/4222 [==============================] - 2s 455us/step - loss: 2.6268e-04 - acc: 1.0000 - val_loss: 0.0389 - val_acc: 0.9905\n",
      "Epoch 68/100\n",
      "4222/4222 [==============================] - 2s 433us/step - loss: 2.4729e-04 - acc: 1.0000 - val_loss: 0.0388 - val_acc: 0.9915\n",
      "Epoch 69/100\n",
      "4222/4222 [==============================] - 2s 488us/step - loss: 2.2980e-04 - acc: 1.0000 - val_loss: 0.0396 - val_acc: 0.9915\n",
      "Epoch 70/100\n",
      "4222/4222 [==============================] - 2s 448us/step - loss: 2.5704e-04 - acc: 1.0000 - val_loss: 0.0431 - val_acc: 0.9915\n",
      "Epoch 71/100\n",
      "4222/4222 [==============================] - 2s 439us/step - loss: 0.0153 - acc: 0.9943 - val_loss: 0.0558 - val_acc: 0.9896\n",
      "Epoch 72/100\n",
      "4222/4222 [==============================] - 2s 461us/step - loss: 0.0090 - acc: 0.9979 - val_loss: 0.0606 - val_acc: 0.9867\n",
      "Epoch 73/100\n",
      "4222/4222 [==============================] - 2s 443us/step - loss: 0.0028 - acc: 0.9995 - val_loss: 0.0391 - val_acc: 0.9924\n",
      "Epoch 74/100\n",
      "4222/4222 [==============================] - 2s 441us/step - loss: 4.4266e-04 - acc: 1.0000 - val_loss: 0.0411 - val_acc: 0.9934\n",
      "Epoch 75/100\n",
      "4222/4222 [==============================] - 2s 440us/step - loss: 2.6567e-04 - acc: 1.0000 - val_loss: 0.0416 - val_acc: 0.9915\n",
      "Epoch 76/100\n",
      "4222/4222 [==============================] - 2s 443us/step - loss: 2.3550e-04 - acc: 1.0000 - val_loss: 0.0417 - val_acc: 0.9934\n",
      "Epoch 77/100\n",
      "4222/4222 [==============================] - 2s 445us/step - loss: 1.9850e-04 - acc: 1.0000 - val_loss: 0.0430 - val_acc: 0.9915\n",
      "Epoch 78/100\n",
      "4222/4222 [==============================] - 2s 439us/step - loss: 2.0139e-04 - acc: 1.0000 - val_loss: 0.0429 - val_acc: 0.9915\n",
      "Epoch 79/100\n",
      "4222/4222 [==============================] - 2s 436us/step - loss: 1.8863e-04 - acc: 1.0000 - val_loss: 0.0435 - val_acc: 0.9934\n",
      "Epoch 80/100\n",
      "4222/4222 [==============================] - 2s 476us/step - loss: 1.8188e-04 - acc: 1.0000 - val_loss: 0.0464 - val_acc: 0.9934\n",
      "Epoch 81/100\n",
      "4222/4222 [==============================] - 2s 473us/step - loss: 1.6285e-04 - acc: 1.0000 - val_loss: 0.0432 - val_acc: 0.9934\n",
      "Epoch 82/100\n",
      "4222/4222 [==============================] - 2s 462us/step - loss: 1.6265e-04 - acc: 1.0000 - val_loss: 0.0483 - val_acc: 0.9924\n",
      "Epoch 83/100\n",
      "4222/4222 [==============================] - 2s 467us/step - loss: 1.2272e-04 - acc: 1.0000 - val_loss: 0.0494 - val_acc: 0.9915\n",
      "Epoch 84/100\n",
      "4222/4222 [==============================] - 2s 435us/step - loss: 0.0184 - acc: 0.9960 - val_loss: 0.0610 - val_acc: 0.9820\n",
      "Epoch 85/100\n",
      "4222/4222 [==============================] - 2s 444us/step - loss: 0.0133 - acc: 0.9950 - val_loss: 0.0551 - val_acc: 0.9896\n",
      "Epoch 86/100\n",
      "4222/4222 [==============================] - 2s 492us/step - loss: 0.0013 - acc: 0.9998 - val_loss: 0.0520 - val_acc: 0.9915\n",
      "Epoch 87/100\n",
      "4222/4222 [==============================] - 2s 445us/step - loss: 4.5661e-04 - acc: 1.0000 - val_loss: 0.0573 - val_acc: 0.9886\n",
      "Epoch 88/100\n",
      "4222/4222 [==============================] - 2s 460us/step - loss: 4.0433e-04 - acc: 0.9998 - val_loss: 0.0487 - val_acc: 0.9905\n",
      "Epoch 89/100\n",
      "4222/4222 [==============================] - 2s 556us/step - loss: 1.6879e-04 - acc: 1.0000 - val_loss: 0.0505 - val_acc: 0.9905\n",
      "Epoch 90/100\n",
      "4222/4222 [==============================] - 2s 430us/step - loss: 1.5790e-04 - acc: 1.0000 - val_loss: 0.0495 - val_acc: 0.9915\n",
      "Epoch 91/100\n",
      "4222/4222 [==============================] - 2s 454us/step - loss: 1.3950e-04 - acc: 1.0000 - val_loss: 0.0515 - val_acc: 0.9905\n",
      "Epoch 92/100\n",
      "4222/4222 [==============================] - 2s 428us/step - loss: 1.4162e-04 - acc: 1.0000 - val_loss: 0.0513 - val_acc: 0.9915\n",
      "Epoch 93/100\n",
      "4222/4222 [==============================] - 2s 432us/step - loss: 1.2026e-04 - acc: 1.0000 - val_loss: 0.0513 - val_acc: 0.9905\n",
      "Epoch 94/100\n",
      "4222/4222 [==============================] - 2s 475us/step - loss: 1.4080e-04 - acc: 1.0000 - val_loss: 0.0520 - val_acc: 0.9915\n",
      "Epoch 95/100\n",
      "4222/4222 [==============================] - 2s 463us/step - loss: 1.3137e-04 - acc: 1.0000 - val_loss: 0.0500 - val_acc: 0.9915\n",
      "Epoch 96/100\n",
      "4222/4222 [==============================] - 2s 485us/step - loss: 2.5771e-04 - acc: 1.0000 - val_loss: 0.0529 - val_acc: 0.9896\n",
      "Epoch 97/100\n",
      "4222/4222 [==============================] - 2s 440us/step - loss: 0.0169 - acc: 0.9960 - val_loss: 0.0778 - val_acc: 0.9830\n",
      "Epoch 98/100\n",
      "4222/4222 [==============================] - 2s 438us/step - loss: 0.0053 - acc: 0.9981 - val_loss: 0.0529 - val_acc: 0.9905\n",
      "Epoch 99/100\n",
      "4222/4222 [==============================] - 2s 435us/step - loss: 6.2477e-04 - acc: 0.9998 - val_loss: 0.0474 - val_acc: 0.9886\n",
      "Epoch 100/100\n",
      "4222/4222 [==============================] - 2s 440us/step - loss: 0.0038 - acc: 0.9988 - val_loss: 0.0667 - val_acc: 0.9886\n"
     ]
    }
   ],
   "source": [
    "model = classifier.fit(X_train, y_train, validation_split = 0.2, batch_size = 10, nb_epoch = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1116    4]\n",
      " [   7  193]]\n",
      "0.9916666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "score = accuracy_score(y_pred, y_test)\n",
    "print(cm)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Simple Sequential model with [6,3,1] layers, batch size = 10 and epochs = 100. Reduced nodes in the 2nd layer that decreased accuracy from 99.167% to 98.712%</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_364 (Dense)            (None, 6)                 1002      \n",
      "_________________________________________________________________\n",
      "dense_365 (Dense)            (None, 3)                 21        \n",
      "_________________________________________________________________\n",
      "dense_366 (Dense)            (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 1,027\n",
      "Trainable params: 1,027\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "Train on 4222 samples, validate on 1056 samples\n",
      "Epoch 1/100\n",
      "4222/4222 [==============================] - 11s 3ms/step - loss: 0.3598 - acc: 0.8709 - val_loss: 0.2192 - val_acc: 0.9138\n",
      "Epoch 2/100\n",
      "4222/4222 [==============================] - 2s 436us/step - loss: 0.1979 - acc: 0.9261 - val_loss: 0.1750 - val_acc: 0.9384\n",
      "Epoch 3/100\n",
      "4222/4222 [==============================] - 2s 437us/step - loss: 0.1578 - acc: 0.9415 - val_loss: 0.1470 - val_acc: 0.9441\n",
      "Epoch 4/100\n",
      "4222/4222 [==============================] - 2s 436us/step - loss: 0.1306 - acc: 0.9467 - val_loss: 0.1287 - val_acc: 0.9489\n",
      "Epoch 5/100\n",
      "4222/4222 [==============================] - 2s 434us/step - loss: 0.1085 - acc: 0.9569 - val_loss: 0.1101 - val_acc: 0.9593\n",
      "Epoch 6/100\n",
      "4222/4222 [==============================] - 2s 479us/step - loss: 0.0960 - acc: 0.9621 - val_loss: 0.0979 - val_acc: 0.9593\n",
      "Epoch 7/100\n",
      "4222/4222 [==============================] - 2s 441us/step - loss: 0.0865 - acc: 0.9612 - val_loss: 0.0894 - val_acc: 0.9631\n",
      "Epoch 8/100\n",
      "4222/4222 [==============================] - 2s 441us/step - loss: 0.0794 - acc: 0.9640 - val_loss: 0.0832 - val_acc: 0.9659\n",
      "Epoch 9/100\n",
      "4222/4222 [==============================] - 2s 441us/step - loss: 0.0737 - acc: 0.9661 - val_loss: 0.0817 - val_acc: 0.9650\n",
      "Epoch 10/100\n",
      "4222/4222 [==============================] - 2s 460us/step - loss: 0.0677 - acc: 0.9678 - val_loss: 0.0752 - val_acc: 0.9669\n",
      "Epoch 11/100\n",
      "4222/4222 [==============================] - 2s 459us/step - loss: 0.0646 - acc: 0.9699 - val_loss: 0.0874 - val_acc: 0.9621\n",
      "Epoch 12/100\n",
      "4222/4222 [==============================] - 2s 441us/step - loss: 0.0598 - acc: 0.9742 - val_loss: 0.0664 - val_acc: 0.9773\n",
      "Epoch 13/100\n",
      "4222/4222 [==============================] - 2s 437us/step - loss: 0.0575 - acc: 0.9739 - val_loss: 0.0665 - val_acc: 0.9706\n",
      "Epoch 14/100\n",
      "4222/4222 [==============================] - 2s 440us/step - loss: 0.0550 - acc: 0.9763 - val_loss: 0.0603 - val_acc: 0.9792\n",
      "Epoch 15/100\n",
      "4222/4222 [==============================] - 2s 442us/step - loss: 0.0512 - acc: 0.9787 - val_loss: 0.0592 - val_acc: 0.9754\n",
      "Epoch 16/100\n",
      "4222/4222 [==============================] - 2s 439us/step - loss: 0.0453 - acc: 0.9811 - val_loss: 0.0546 - val_acc: 0.9801\n",
      "Epoch 17/100\n",
      "4222/4222 [==============================] - 2s 471us/step - loss: 0.0423 - acc: 0.9825 - val_loss: 0.0518 - val_acc: 0.9782\n",
      "Epoch 18/100\n",
      "4222/4222 [==============================] - 2s 441us/step - loss: 0.0421 - acc: 0.9811 - val_loss: 0.0497 - val_acc: 0.9801\n",
      "Epoch 19/100\n",
      "4222/4222 [==============================] - 2s 543us/step - loss: 0.0394 - acc: 0.9834 - val_loss: 0.0451 - val_acc: 0.9811\n",
      "Epoch 20/100\n",
      "4222/4222 [==============================] - 2s 547us/step - loss: 0.0375 - acc: 0.9844 - val_loss: 0.0479 - val_acc: 0.9801\n",
      "Epoch 21/100\n",
      "4222/4222 [==============================] - 2s 449us/step - loss: 0.0355 - acc: 0.9856 - val_loss: 0.0549 - val_acc: 0.9782\n",
      "Epoch 22/100\n",
      "4222/4222 [==============================] - 2s 440us/step - loss: 0.0316 - acc: 0.9877 - val_loss: 0.0354 - val_acc: 0.9867\n",
      "Epoch 23/100\n",
      "4222/4222 [==============================] - 2s 434us/step - loss: 0.0299 - acc: 0.9891 - val_loss: 0.0347 - val_acc: 0.9858\n",
      "Epoch 24/100\n",
      "4222/4222 [==============================] - 2s 442us/step - loss: 0.0295 - acc: 0.9889 - val_loss: 0.0426 - val_acc: 0.9858\n",
      "Epoch 25/100\n",
      "4222/4222 [==============================] - 2s 441us/step - loss: 0.0265 - acc: 0.9908 - val_loss: 0.0393 - val_acc: 0.9848\n",
      "Epoch 26/100\n",
      "4222/4222 [==============================] - 2s 436us/step - loss: 0.0251 - acc: 0.9919 - val_loss: 0.0339 - val_acc: 0.9839\n",
      "Epoch 27/100\n",
      "4222/4222 [==============================] - 2s 443us/step - loss: 0.0240 - acc: 0.9917 - val_loss: 0.0622 - val_acc: 0.9697\n",
      "Epoch 28/100\n",
      "4222/4222 [==============================] - 2s 460us/step - loss: 0.0233 - acc: 0.9915 - val_loss: 0.0321 - val_acc: 0.9839\n",
      "Epoch 29/100\n",
      "4222/4222 [==============================] - 2s 457us/step - loss: 0.0204 - acc: 0.9936 - val_loss: 0.0306 - val_acc: 0.9858\n",
      "Epoch 30/100\n",
      "4222/4222 [==============================] - 2s 444us/step - loss: 0.0198 - acc: 0.9934 - val_loss: 0.0271 - val_acc: 0.9867\n",
      "Epoch 31/100\n",
      "4222/4222 [==============================] - 2s 446us/step - loss: 0.0195 - acc: 0.9931 - val_loss: 0.0385 - val_acc: 0.9867\n",
      "Epoch 32/100\n",
      "4222/4222 [==============================] - 2s 501us/step - loss: 0.0187 - acc: 0.9950 - val_loss: 0.0302 - val_acc: 0.9886\n",
      "Epoch 33/100\n",
      "4222/4222 [==============================] - 2s 459us/step - loss: 0.0186 - acc: 0.9938 - val_loss: 0.0338 - val_acc: 0.9848\n",
      "Epoch 34/100\n",
      "4222/4222 [==============================] - 2s 488us/step - loss: 0.0202 - acc: 0.9936 - val_loss: 0.0327 - val_acc: 0.9848\n",
      "Epoch 35/100\n",
      "4222/4222 [==============================] - 2s 495us/step - loss: 0.0167 - acc: 0.9955 - val_loss: 0.0279 - val_acc: 0.9877\n",
      "Epoch 36/100\n",
      "4222/4222 [==============================] - 2s 520us/step - loss: 0.0150 - acc: 0.9960 - val_loss: 0.0304 - val_acc: 0.9896\n",
      "Epoch 37/100\n",
      "4222/4222 [==============================] - 2s 499us/step - loss: 0.0170 - acc: 0.9950 - val_loss: 0.0298 - val_acc: 0.9867\n",
      "Epoch 38/100\n",
      "4222/4222 [==============================] - 2s 509us/step - loss: 0.0159 - acc: 0.9948 - val_loss: 0.0422 - val_acc: 0.9792\n",
      "Epoch 39/100\n",
      "4222/4222 [==============================] - 2s 444us/step - loss: 0.0207 - acc: 0.9936 - val_loss: 0.0342 - val_acc: 0.9848\n",
      "Epoch 40/100\n",
      "4222/4222 [==============================] - 2s 442us/step - loss: 0.0140 - acc: 0.9957 - val_loss: 0.0255 - val_acc: 0.9877\n",
      "Epoch 41/100\n",
      "4222/4222 [==============================] - 2s 458us/step - loss: 0.0131 - acc: 0.9955 - val_loss: 0.0243 - val_acc: 0.9896\n",
      "Epoch 42/100\n",
      "4222/4222 [==============================] - 2s 473us/step - loss: 0.0120 - acc: 0.9957 - val_loss: 0.0381 - val_acc: 0.9867\n",
      "Epoch 43/100\n",
      "4222/4222 [==============================] - 2s 444us/step - loss: 0.0127 - acc: 0.9962 - val_loss: 0.0181 - val_acc: 0.9905\n",
      "Epoch 44/100\n",
      "4222/4222 [==============================] - 2s 447us/step - loss: 0.0140 - acc: 0.9957 - val_loss: 0.0462 - val_acc: 0.9848\n",
      "Epoch 45/100\n",
      "4222/4222 [==============================] - 2s 443us/step - loss: 0.0168 - acc: 0.9943 - val_loss: 0.0282 - val_acc: 0.9848\n",
      "Epoch 46/100\n",
      "4222/4222 [==============================] - 2s 447us/step - loss: 0.0118 - acc: 0.9962 - val_loss: 0.0585 - val_acc: 0.9830\n",
      "Epoch 47/100\n",
      "4222/4222 [==============================] - 2s 454us/step - loss: 0.0114 - acc: 0.9964 - val_loss: 0.0245 - val_acc: 0.9886\n",
      "Epoch 48/100\n",
      "4222/4222 [==============================] - 2s 481us/step - loss: 0.0120 - acc: 0.9964 - val_loss: 0.0223 - val_acc: 0.9877\n",
      "Epoch 49/100\n",
      "4222/4222 [==============================] - 2s 476us/step - loss: 0.0139 - acc: 0.9953 - val_loss: 0.0369 - val_acc: 0.9839\n",
      "Epoch 50/100\n",
      "4222/4222 [==============================] - 2s 460us/step - loss: 0.0096 - acc: 0.9979 - val_loss: 0.0424 - val_acc: 0.9867\n",
      "Epoch 51/100\n",
      "4222/4222 [==============================] - 2s 472us/step - loss: 0.0125 - acc: 0.9962 - val_loss: 0.0264 - val_acc: 0.9858\n",
      "Epoch 52/100\n",
      "4222/4222 [==============================] - 2s 459us/step - loss: 0.0110 - acc: 0.9957 - val_loss: 0.0250 - val_acc: 0.9896\n",
      "Epoch 53/100\n",
      "4222/4222 [==============================] - 2s 459us/step - loss: 0.0095 - acc: 0.9974 - val_loss: 0.0393 - val_acc: 0.9848\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4222/4222 [==============================] - 2s 445us/step - loss: 0.0153 - acc: 0.9934 - val_loss: 0.0427 - val_acc: 0.9830\n",
      "Epoch 55/100\n",
      "4222/4222 [==============================] - 2s 432us/step - loss: 0.0103 - acc: 0.9962 - val_loss: 0.0287 - val_acc: 0.9905\n",
      "Epoch 56/100\n",
      "4222/4222 [==============================] - 2s 433us/step - loss: 0.0077 - acc: 0.9979 - val_loss: 0.0311 - val_acc: 0.9886\n",
      "Epoch 57/100\n",
      "4222/4222 [==============================] - 2s 432us/step - loss: 0.0079 - acc: 0.9974 - val_loss: 0.0360 - val_acc: 0.9886\n",
      "Epoch 58/100\n",
      "4222/4222 [==============================] - 2s 433us/step - loss: 0.0124 - acc: 0.9957 - val_loss: 0.0333 - val_acc: 0.9867\n",
      "Epoch 59/100\n",
      "4222/4222 [==============================] - 2s 434us/step - loss: 0.0126 - acc: 0.9960 - val_loss: 0.0294 - val_acc: 0.9915\n",
      "Epoch 60/100\n",
      "4222/4222 [==============================] - 2s 437us/step - loss: 0.0079 - acc: 0.9972 - val_loss: 0.0262 - val_acc: 0.9896\n",
      "Epoch 61/100\n",
      "4222/4222 [==============================] - 2s 473us/step - loss: 0.0068 - acc: 0.9981 - val_loss: 0.0298 - val_acc: 0.9905\n",
      "Epoch 62/100\n",
      "4222/4222 [==============================] - 2s 543us/step - loss: 0.0073 - acc: 0.9979 - val_loss: 0.0298 - val_acc: 0.9915\n",
      "Epoch 63/100\n",
      "4222/4222 [==============================] - 2s 497us/step - loss: 0.0107 - acc: 0.9967 - val_loss: 0.0309 - val_acc: 0.9886\n",
      "Epoch 64/100\n",
      "4222/4222 [==============================] - 2s 496us/step - loss: 0.0103 - acc: 0.9969 - val_loss: 0.0261 - val_acc: 0.9924\n",
      "Epoch 65/100\n",
      "4222/4222 [==============================] - 2s 436us/step - loss: 0.0129 - acc: 0.9962 - val_loss: 0.0333 - val_acc: 0.9877\n",
      "Epoch 66/100\n",
      "4222/4222 [==============================] - 2s 496us/step - loss: 0.0066 - acc: 0.9981 - val_loss: 0.0339 - val_acc: 0.9896\n",
      "Epoch 67/100\n",
      "4222/4222 [==============================] - 2s 446us/step - loss: 0.0091 - acc: 0.9969 - val_loss: 0.0358 - val_acc: 0.9848\n",
      "Epoch 68/100\n",
      "4222/4222 [==============================] - 2s 467us/step - loss: 0.0070 - acc: 0.9979 - val_loss: 0.0463 - val_acc: 0.9858\n",
      "Epoch 69/100\n",
      "4222/4222 [==============================] - 2s 440us/step - loss: 0.0096 - acc: 0.9969 - val_loss: 0.0395 - val_acc: 0.9886\n",
      "Epoch 70/100\n",
      "4222/4222 [==============================] - 2s 452us/step - loss: 0.0058 - acc: 0.9983 - val_loss: 0.0323 - val_acc: 0.9924\n",
      "Epoch 71/100\n",
      "4222/4222 [==============================] - 2s 483us/step - loss: 0.0089 - acc: 0.9967 - val_loss: 0.0635 - val_acc: 0.9830\n",
      "Epoch 72/100\n",
      "4222/4222 [==============================] - 2s 504us/step - loss: 0.0114 - acc: 0.9955 - val_loss: 0.0264 - val_acc: 0.9896\n",
      "Epoch 73/100\n",
      "4222/4222 [==============================] - 2s 480us/step - loss: 0.0085 - acc: 0.9974 - val_loss: 0.0332 - val_acc: 0.9905\n",
      "Epoch 74/100\n",
      "4222/4222 [==============================] - 2s 493us/step - loss: 0.0078 - acc: 0.9974 - val_loss: 0.0201 - val_acc: 0.9924\n",
      "Epoch 75/100\n",
      "4222/4222 [==============================] - 2s 488us/step - loss: 0.0054 - acc: 0.9983 - val_loss: 0.0237 - val_acc: 0.9896\n",
      "Epoch 76/100\n",
      "4222/4222 [==============================] - 2s 444us/step - loss: 0.0053 - acc: 0.9983 - val_loss: 0.0267 - val_acc: 0.9905\n",
      "Epoch 77/100\n",
      "4222/4222 [==============================] - 2s 443us/step - loss: 0.0051 - acc: 0.9983 - val_loss: 0.0221 - val_acc: 0.9924\n",
      "Epoch 78/100\n",
      "4222/4222 [==============================] - 2s 439us/step - loss: 0.0223 - acc: 0.9929 - val_loss: 0.0597 - val_acc: 0.9896\n",
      "Epoch 79/100\n",
      "4222/4222 [==============================] - 2s 438us/step - loss: 0.0103 - acc: 0.9967 - val_loss: 0.0447 - val_acc: 0.9867\n",
      "Epoch 80/100\n",
      "4222/4222 [==============================] - 2s 443us/step - loss: 0.0057 - acc: 0.9981 - val_loss: 0.0410 - val_acc: 0.9905\n",
      "Epoch 81/100\n",
      "4222/4222 [==============================] - 2s 437us/step - loss: 0.0050 - acc: 0.9983 - val_loss: 0.0434 - val_acc: 0.9915\n",
      "Epoch 82/100\n",
      "4222/4222 [==============================] - 2s 441us/step - loss: 0.0055 - acc: 0.9981 - val_loss: 0.0402 - val_acc: 0.9896\n",
      "Epoch 83/100\n",
      "4222/4222 [==============================] - 2s 444us/step - loss: 0.0052 - acc: 0.9983 - val_loss: 0.0390 - val_acc: 0.9924\n",
      "Epoch 84/100\n",
      "4222/4222 [==============================] - 2s 442us/step - loss: 0.0128 - acc: 0.9957 - val_loss: 0.0425 - val_acc: 0.9896\n",
      "Epoch 85/100\n",
      "4222/4222 [==============================] - 2s 440us/step - loss: 0.0120 - acc: 0.9953 - val_loss: 0.0590 - val_acc: 0.9867\n",
      "Epoch 86/100\n",
      "4222/4222 [==============================] - 2s 463us/step - loss: 0.0096 - acc: 0.9962 - val_loss: 0.0449 - val_acc: 0.9905\n",
      "Epoch 87/100\n",
      "4222/4222 [==============================] - 2s 479us/step - loss: 0.0087 - acc: 0.9969 - val_loss: 0.0507 - val_acc: 0.9896\n",
      "Epoch 88/100\n",
      "4222/4222 [==============================] - 2s 473us/step - loss: 0.0053 - acc: 0.9986 - val_loss: 0.0486 - val_acc: 0.9915\n",
      "Epoch 89/100\n",
      "4222/4222 [==============================] - 2s 585us/step - loss: 0.0050 - acc: 0.9986 - val_loss: 0.0425 - val_acc: 0.9886\n",
      "Epoch 90/100\n",
      "4222/4222 [==============================] - 2s 568us/step - loss: 0.0137 - acc: 0.9955 - val_loss: 0.0484 - val_acc: 0.9896\n",
      "Epoch 91/100\n",
      "4222/4222 [==============================] - 2s 464us/step - loss: 0.0060 - acc: 0.9983 - val_loss: 0.0368 - val_acc: 0.9915\n",
      "Epoch 92/100\n",
      "4222/4222 [==============================] - 2s 540us/step - loss: 0.0045 - acc: 0.9986 - val_loss: 0.0403 - val_acc: 0.9905\n",
      "Epoch 93/100\n",
      "4222/4222 [==============================] - 2s 526us/step - loss: 0.0046 - acc: 0.9986 - val_loss: 0.0604 - val_acc: 0.9858\n",
      "Epoch 94/100\n",
      "4222/4222 [==============================] - 3s 670us/step - loss: 0.0050 - acc: 0.9981 - val_loss: 0.0380 - val_acc: 0.9905\n",
      "Epoch 95/100\n",
      "4222/4222 [==============================] - 2s 560us/step - loss: 0.0042 - acc: 0.9986 - val_loss: 0.0463 - val_acc: 0.9896\n",
      "Epoch 96/100\n",
      "4222/4222 [==============================] - 2s 587us/step - loss: 0.0044 - acc: 0.9986 - val_loss: 0.0427 - val_acc: 0.9915\n",
      "Epoch 97/100\n",
      "4222/4222 [==============================] - 4s 941us/step - loss: 0.0122 - acc: 0.9967 - val_loss: 0.0446 - val_acc: 0.9915\n",
      "Epoch 98/100\n",
      "4222/4222 [==============================] - 3s 800us/step - loss: 0.0157 - acc: 0.9960 - val_loss: 0.0394 - val_acc: 0.9896\n",
      "Epoch 99/100\n",
      "4222/4222 [==============================] - 2s 584us/step - loss: 0.0052 - acc: 0.9983 - val_loss: 0.0475 - val_acc: 0.9886\n",
      "Epoch 100/100\n",
      "4222/4222 [==============================] - 2s 541us/step - loss: 0.0045 - acc: 0.9986 - val_loss: 0.0446 - val_acc: 0.9896\n",
      "[[1111    9]\n",
      " [   8  192]]\n",
      "0.9871212121212121\n"
     ]
    }
   ],
   "source": [
    "classifier = Sequential()\n",
    "\n",
    "classifier.add(Dense(units = 6, kernel_initializer = 'he_uniform', activation = 'relu', input_dim = 166))\n",
    "\n",
    "classifier.add(Dense(units = 3, kernel_initializer = 'he_uniform', activation = 'relu'))\n",
    "\n",
    "classifier.add(Dense(units = 1, kernel_initializer = 'glorot_uniform', activation = 'sigmoid'))\n",
    "\n",
    "classifier.summary()\n",
    "\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "model = classifier.fit(X_train, y_train, validation_split = 0.2, batch_size = 10, nb_epoch = 100)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "score = accuracy_score(y_pred, y_test)\n",
    "print(cm)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Simple Sequential model with [20,6,1] layers, batch size = 10 and epochs = 100.\n",
    "Increased the no. of nodes in 1st hidden layer which increased the accuracy to 99.318%</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_367 (Dense)            (None, 20)                3340      \n",
      "_________________________________________________________________\n",
      "dense_368 (Dense)            (None, 6)                 126       \n",
      "_________________________________________________________________\n",
      "dense_369 (Dense)            (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 3,473\n",
      "Trainable params: 3,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "Train on 4222 samples, validate on 1056 samples\n",
      "Epoch 1/100\n",
      "4222/4222 [==============================] - 11s 3ms/step - loss: 0.2866 - acc: 0.8875 - val_loss: 0.1734 - val_acc: 0.9384\n",
      "Epoch 2/100\n",
      "4222/4222 [==============================] - 2s 446us/step - loss: 0.1357 - acc: 0.9455 - val_loss: 0.1356 - val_acc: 0.9479\n",
      "Epoch 3/100\n",
      "4222/4222 [==============================] - 2s 448us/step - loss: 0.1005 - acc: 0.9626 - val_loss: 0.1331 - val_acc: 0.9403\n",
      "Epoch 4/100\n",
      "4222/4222 [==============================] - 2s 450us/step - loss: 0.0800 - acc: 0.9706 - val_loss: 0.0967 - val_acc: 0.9687\n",
      "Epoch 5/100\n",
      "4222/4222 [==============================] - 2s 448us/step - loss: 0.0632 - acc: 0.9770 - val_loss: 0.0851 - val_acc: 0.9678\n",
      "Epoch 6/100\n",
      "4222/4222 [==============================] - 2s 534us/step - loss: 0.0530 - acc: 0.9803 - val_loss: 0.0706 - val_acc: 0.9735\n",
      "Epoch 7/100\n",
      "4222/4222 [==============================] - 2s 492us/step - loss: 0.0439 - acc: 0.9839 - val_loss: 0.0581 - val_acc: 0.9801\n",
      "Epoch 8/100\n",
      "4222/4222 [==============================] - 2s 456us/step - loss: 0.0360 - acc: 0.9879 - val_loss: 0.0600 - val_acc: 0.9801\n",
      "Epoch 9/100\n",
      "4222/4222 [==============================] - 2s 457us/step - loss: 0.0327 - acc: 0.9886 - val_loss: 0.0533 - val_acc: 0.9811\n",
      "Epoch 10/100\n",
      "4222/4222 [==============================] - 2s 453us/step - loss: 0.0245 - acc: 0.9922 - val_loss: 0.0688 - val_acc: 0.9801\n",
      "Epoch 11/100\n",
      "4222/4222 [==============================] - 2s 483us/step - loss: 0.0225 - acc: 0.9917 - val_loss: 0.0531 - val_acc: 0.9801\n",
      "Epoch 12/100\n",
      "4222/4222 [==============================] - 2s 466us/step - loss: 0.0166 - acc: 0.9950 - val_loss: 0.0537 - val_acc: 0.9792\n",
      "Epoch 13/100\n",
      "4222/4222 [==============================] - 2s 459us/step - loss: 0.0154 - acc: 0.9953 - val_loss: 0.0414 - val_acc: 0.9877\n",
      "Epoch 14/100\n",
      "4222/4222 [==============================] - 2s 454us/step - loss: 0.0118 - acc: 0.9964 - val_loss: 0.0437 - val_acc: 0.9867\n",
      "Epoch 15/100\n",
      "4222/4222 [==============================] - 2s 456us/step - loss: 0.0108 - acc: 0.9962 - val_loss: 0.0496 - val_acc: 0.9820\n",
      "Epoch 16/100\n",
      "4222/4222 [==============================] - 2s 457us/step - loss: 0.0115 - acc: 0.9969 - val_loss: 0.0628 - val_acc: 0.9820\n",
      "Epoch 17/100\n",
      "4222/4222 [==============================] - 2s 456us/step - loss: 0.0173 - acc: 0.9941 - val_loss: 0.0375 - val_acc: 0.9886\n",
      "Epoch 18/100\n",
      "4222/4222 [==============================] - 2s 455us/step - loss: 0.0064 - acc: 0.9988 - val_loss: 0.0385 - val_acc: 0.9877\n",
      "Epoch 19/100\n",
      "4222/4222 [==============================] - 2s 454us/step - loss: 0.0041 - acc: 0.9995 - val_loss: 0.0316 - val_acc: 0.9915\n",
      "Epoch 20/100\n",
      "4222/4222 [==============================] - 2s 456us/step - loss: 0.0037 - acc: 0.9995 - val_loss: 0.0354 - val_acc: 0.9915\n",
      "Epoch 21/100\n",
      "4222/4222 [==============================] - 2s 458us/step - loss: 0.0056 - acc: 0.9983 - val_loss: 0.0391 - val_acc: 0.9924\n",
      "Epoch 22/100\n",
      "4222/4222 [==============================] - 2s 489us/step - loss: 0.0088 - acc: 0.9967 - val_loss: 0.0644 - val_acc: 0.9811\n",
      "Epoch 23/100\n",
      "4222/4222 [==============================] - 2s 468us/step - loss: 0.0127 - acc: 0.9955 - val_loss: 0.0365 - val_acc: 0.9896\n",
      "Epoch 24/100\n",
      "4222/4222 [==============================] - 2s 461us/step - loss: 0.0034 - acc: 0.9995 - val_loss: 0.0441 - val_acc: 0.9886\n",
      "Epoch 25/100\n",
      "4222/4222 [==============================] - 2s 450us/step - loss: 0.0063 - acc: 0.9986 - val_loss: 0.0333 - val_acc: 0.9886\n",
      "Epoch 26/100\n",
      "4222/4222 [==============================] - 2s 455us/step - loss: 0.0017 - acc: 0.9998 - val_loss: 0.0315 - val_acc: 0.9924\n",
      "Epoch 27/100\n",
      "4222/4222 [==============================] - 2s 451us/step - loss: 8.3609e-04 - acc: 1.0000 - val_loss: 0.0337 - val_acc: 0.9924\n",
      "Epoch 28/100\n",
      "4222/4222 [==============================] - 2s 454us/step - loss: 7.9394e-04 - acc: 1.0000 - val_loss: 0.0389 - val_acc: 0.9915\n",
      "Epoch 29/100\n",
      "4222/4222 [==============================] - 2s 450us/step - loss: 5.9387e-04 - acc: 1.0000 - val_loss: 0.0353 - val_acc: 0.9915\n",
      "Epoch 30/100\n",
      "4222/4222 [==============================] - 2s 453us/step - loss: 0.0122 - acc: 0.9953 - val_loss: 0.0570 - val_acc: 0.9848\n",
      "Epoch 31/100\n",
      "4222/4222 [==============================] - 2s 469us/step - loss: 0.0045 - acc: 0.9986 - val_loss: 0.0418 - val_acc: 0.9924\n",
      "Epoch 32/100\n",
      "4222/4222 [==============================] - 2s 493us/step - loss: 0.0059 - acc: 0.9981 - val_loss: 0.0391 - val_acc: 0.9915\n",
      "Epoch 33/100\n",
      "4222/4222 [==============================] - 2s 490us/step - loss: 7.2175e-04 - acc: 1.0000 - val_loss: 0.0401 - val_acc: 0.9924\n",
      "Epoch 34/100\n",
      "4222/4222 [==============================] - 2s 453us/step - loss: 4.7230e-04 - acc: 1.0000 - val_loss: 0.0405 - val_acc: 0.9924\n",
      "Epoch 35/100\n",
      "4222/4222 [==============================] - 2s 522us/step - loss: 3.6923e-04 - acc: 1.0000 - val_loss: 0.0430 - val_acc: 0.9915\n",
      "Epoch 36/100\n",
      "4222/4222 [==============================] - 2s 571us/step - loss: 3.3697e-04 - acc: 1.0000 - val_loss: 0.0431 - val_acc: 0.9915\n",
      "Epoch 37/100\n",
      "4222/4222 [==============================] - 2s 556us/step - loss: 2.9275e-04 - acc: 1.0000 - val_loss: 0.0434 - val_acc: 0.9915\n",
      "Epoch 38/100\n",
      "4222/4222 [==============================] - 2s 566us/step - loss: 2.7758e-04 - acc: 1.0000 - val_loss: 0.0435 - val_acc: 0.9924\n",
      "Epoch 39/100\n",
      "4222/4222 [==============================] - 2s 523us/step - loss: 0.0256 - acc: 0.9931 - val_loss: 0.0664 - val_acc: 0.9867\n",
      "Epoch 40/100\n",
      "4222/4222 [==============================] - 2s 526us/step - loss: 0.0019 - acc: 0.9998 - val_loss: 0.0550 - val_acc: 0.9877\n",
      "Epoch 41/100\n",
      "4222/4222 [==============================] - 2s 517us/step - loss: 5.8826e-04 - acc: 1.0000 - val_loss: 0.0507 - val_acc: 0.9896\n",
      "Epoch 42/100\n",
      "4222/4222 [==============================] - 2s 454us/step - loss: 0.0045 - acc: 0.9983 - val_loss: 0.0552 - val_acc: 0.9886\n",
      "Epoch 43/100\n",
      "4222/4222 [==============================] - 2s 489us/step - loss: 0.0029 - acc: 0.9991 - val_loss: 0.0485 - val_acc: 0.9915\n",
      "Epoch 44/100\n",
      "4222/4222 [==============================] - 2s 466us/step - loss: 0.0018 - acc: 0.9995 - val_loss: 0.0423 - val_acc: 0.9915\n",
      "Epoch 45/100\n",
      "4222/4222 [==============================] - 2s 472us/step - loss: 0.0049 - acc: 0.9993 - val_loss: 0.0688 - val_acc: 0.9848\n",
      "Epoch 46/100\n",
      "4222/4222 [==============================] - 2s 459us/step - loss: 6.1395e-04 - acc: 1.0000 - val_loss: 0.0410 - val_acc: 0.9915\n",
      "Epoch 47/100\n",
      "4222/4222 [==============================] - 2s 453us/step - loss: 2.2775e-04 - acc: 1.0000 - val_loss: 0.0410 - val_acc: 0.9905\n",
      "Epoch 48/100\n",
      "4222/4222 [==============================] - 2s 452us/step - loss: 1.8412e-04 - acc: 1.0000 - val_loss: 0.0414 - val_acc: 0.9905\n",
      "Epoch 49/100\n",
      "4222/4222 [==============================] - 2s 452us/step - loss: 1.5323e-04 - acc: 1.0000 - val_loss: 0.0432 - val_acc: 0.9905\n",
      "Epoch 50/100\n",
      "4222/4222 [==============================] - 2s 463us/step - loss: 1.3932e-04 - acc: 1.0000 - val_loss: 0.0425 - val_acc: 0.9905\n",
      "Epoch 51/100\n",
      "4222/4222 [==============================] - 2s 453us/step - loss: 1.1111e-04 - acc: 1.0000 - val_loss: 0.0414 - val_acc: 0.9905\n",
      "Epoch 52/100\n",
      "4222/4222 [==============================] - 2s 452us/step - loss: 1.0191e-04 - acc: 1.0000 - val_loss: 0.0398 - val_acc: 0.9905\n",
      "Epoch 53/100\n",
      "4222/4222 [==============================] - 2s 489us/step - loss: 8.4303e-05 - acc: 1.0000 - val_loss: 0.0420 - val_acc: 0.9905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/100\n",
      "4222/4222 [==============================] - 2s 495us/step - loss: 7.5406e-05 - acc: 1.0000 - val_loss: 0.0423 - val_acc: 0.9915\n",
      "Epoch 55/100\n",
      "4222/4222 [==============================] - 2s 443us/step - loss: 6.4505e-05 - acc: 1.0000 - val_loss: 0.0424 - val_acc: 0.9915\n",
      "Epoch 56/100\n",
      "4222/4222 [==============================] - 2s 442us/step - loss: 5.5985e-05 - acc: 1.0000 - val_loss: 0.0438 - val_acc: 0.9915\n",
      "Epoch 57/100\n",
      "4222/4222 [==============================] - 2s 491us/step - loss: 0.0439 - acc: 0.9901 - val_loss: 0.0583 - val_acc: 0.9915\n",
      "Epoch 58/100\n",
      "4222/4222 [==============================] - 3s 656us/step - loss: 0.0019 - acc: 0.9993 - val_loss: 0.0562 - val_acc: 0.9924\n",
      "Epoch 59/100\n",
      "4222/4222 [==============================] - 2s 475us/step - loss: 4.6156e-04 - acc: 1.0000 - val_loss: 0.0516 - val_acc: 0.9924\n",
      "Epoch 60/100\n",
      "4222/4222 [==============================] - 2s 512us/step - loss: 2.5405e-04 - acc: 1.0000 - val_loss: 0.0536 - val_acc: 0.9915\n",
      "Epoch 61/100\n",
      "4222/4222 [==============================] - 2s 446us/step - loss: 1.9278e-04 - acc: 1.0000 - val_loss: 0.0526 - val_acc: 0.9915\n",
      "Epoch 62/100\n",
      "4222/4222 [==============================] - 2s 462us/step - loss: 1.6499e-04 - acc: 1.0000 - val_loss: 0.0524 - val_acc: 0.9924\n",
      "Epoch 63/100\n",
      "4222/4222 [==============================] - 2s 461us/step - loss: 1.3920e-04 - acc: 1.0000 - val_loss: 0.0523 - val_acc: 0.9905\n",
      "Epoch 64/100\n",
      "4222/4222 [==============================] - 2s 498us/step - loss: 1.1371e-04 - acc: 1.0000 - val_loss: 0.0527 - val_acc: 0.9905\n",
      "Epoch 65/100\n",
      "4222/4222 [==============================] - 3s 656us/step - loss: 9.9223e-05 - acc: 1.0000 - val_loss: 0.0515 - val_acc: 0.9915\n",
      "Epoch 66/100\n",
      "4222/4222 [==============================] - 2s 561us/step - loss: 8.6307e-05 - acc: 1.0000 - val_loss: 0.0505 - val_acc: 0.9915\n",
      "Epoch 67/100\n",
      "4222/4222 [==============================] - 2s 581us/step - loss: 7.3295e-05 - acc: 1.0000 - val_loss: 0.0510 - val_acc: 0.9915\n",
      "Epoch 68/100\n",
      "4222/4222 [==============================] - 2s 529us/step - loss: 7.1249e-05 - acc: 1.0000 - val_loss: 0.0492 - val_acc: 0.9915\n",
      "Epoch 69/100\n",
      "4222/4222 [==============================] - 2s 500us/step - loss: 5.5966e-05 - acc: 1.0000 - val_loss: 0.0486 - val_acc: 0.9924\n",
      "Epoch 70/100\n",
      "4222/4222 [==============================] - 2s 461us/step - loss: 5.0594e-05 - acc: 1.0000 - val_loss: 0.0488 - val_acc: 0.9934\n",
      "Epoch 71/100\n",
      "4222/4222 [==============================] - 2s 442us/step - loss: 4.2441e-05 - acc: 1.0000 - val_loss: 0.0496 - val_acc: 0.9915\n",
      "Epoch 72/100\n",
      "4222/4222 [==============================] - 2s 445us/step - loss: 3.8431e-05 - acc: 1.0000 - val_loss: 0.0502 - val_acc: 0.9924\n",
      "Epoch 73/100\n",
      "4222/4222 [==============================] - 2s 443us/step - loss: 3.1362e-05 - acc: 1.0000 - val_loss: 0.0510 - val_acc: 0.9924\n",
      "Epoch 74/100\n",
      "4222/4222 [==============================] - 2s 440us/step - loss: 2.7937e-05 - acc: 1.0000 - val_loss: 0.0522 - val_acc: 0.9915\n",
      "Epoch 75/100\n",
      "4222/4222 [==============================] - 2s 438us/step - loss: 2.7916e-05 - acc: 1.0000 - val_loss: 0.0476 - val_acc: 0.9934\n",
      "Epoch 76/100\n",
      "4222/4222 [==============================] - 2s 442us/step - loss: 0.0237 - acc: 0.9957 - val_loss: 0.1973 - val_acc: 0.9678\n",
      "Epoch 77/100\n",
      "4222/4222 [==============================] - 2s 441us/step - loss: 0.0341 - acc: 0.9938 - val_loss: 0.0369 - val_acc: 0.9915\n",
      "Epoch 78/100\n",
      "4222/4222 [==============================] - 2s 437us/step - loss: 9.5128e-04 - acc: 0.9998 - val_loss: 0.0295 - val_acc: 0.9943\n",
      "Epoch 79/100\n",
      "4222/4222 [==============================] - 2s 441us/step - loss: 2.5735e-04 - acc: 1.0000 - val_loss: 0.0305 - val_acc: 0.9943\n",
      "Epoch 80/100\n",
      "4222/4222 [==============================] - 2s 444us/step - loss: 1.2700e-04 - acc: 1.0000 - val_loss: 0.0296 - val_acc: 0.9943\n",
      "Epoch 81/100\n",
      "4222/4222 [==============================] - 2s 440us/step - loss: 1.0536e-04 - acc: 1.0000 - val_loss: 0.0293 - val_acc: 0.9943\n",
      "Epoch 82/100\n",
      "4222/4222 [==============================] - 2s 444us/step - loss: 9.0647e-05 - acc: 1.0000 - val_loss: 0.0298 - val_acc: 0.9934\n",
      "Epoch 83/100\n",
      "4222/4222 [==============================] - 2s 438us/step - loss: 7.9941e-05 - acc: 1.0000 - val_loss: 0.0298 - val_acc: 0.9943\n",
      "Epoch 84/100\n",
      "4222/4222 [==============================] - 2s 438us/step - loss: 6.9124e-05 - acc: 1.0000 - val_loss: 0.0297 - val_acc: 0.9934\n",
      "Epoch 85/100\n",
      "4222/4222 [==============================] - 2s 440us/step - loss: 6.2143e-05 - acc: 1.0000 - val_loss: 0.0297 - val_acc: 0.9943\n",
      "Epoch 86/100\n",
      "4222/4222 [==============================] - 2s 442us/step - loss: 5.4970e-05 - acc: 1.0000 - val_loss: 0.0299 - val_acc: 0.9934\n",
      "Epoch 87/100\n",
      "4222/4222 [==============================] - 2s 444us/step - loss: 5.3498e-05 - acc: 1.0000 - val_loss: 0.0303 - val_acc: 0.9934\n",
      "Epoch 88/100\n",
      "4222/4222 [==============================] - 2s 441us/step - loss: 4.5068e-05 - acc: 1.0000 - val_loss: 0.0298 - val_acc: 0.9924\n",
      "Epoch 89/100\n",
      "4222/4222 [==============================] - 2s 440us/step - loss: 4.1182e-05 - acc: 1.0000 - val_loss: 0.0302 - val_acc: 0.9934\n",
      "Epoch 90/100\n",
      "4222/4222 [==============================] - 2s 458us/step - loss: 3.7698e-05 - acc: 1.0000 - val_loss: 0.0300 - val_acc: 0.9934\n",
      "Epoch 91/100\n",
      "4222/4222 [==============================] - 2s 497us/step - loss: 3.2420e-05 - acc: 1.0000 - val_loss: 0.0308 - val_acc: 0.9934\n",
      "Epoch 92/100\n",
      "4222/4222 [==============================] - 2s 525us/step - loss: 2.8232e-05 - acc: 1.0000 - val_loss: 0.0302 - val_acc: 0.9934\n",
      "Epoch 93/100\n",
      "4222/4222 [==============================] - 2s 481us/step - loss: 2.8130e-05 - acc: 1.0000 - val_loss: 0.0313 - val_acc: 0.9934\n",
      "Epoch 94/100\n",
      "4222/4222 [==============================] - 2s 451us/step - loss: 2.5113e-05 - acc: 1.0000 - val_loss: 0.0323 - val_acc: 0.9943\n",
      "Epoch 95/100\n",
      "4222/4222 [==============================] - 2s 484us/step - loss: 2.3473e-05 - acc: 1.0000 - val_loss: 0.0340 - val_acc: 0.9934\n",
      "Epoch 96/100\n",
      "4222/4222 [==============================] - 2s 450us/step - loss: 0.0223 - acc: 0.9955 - val_loss: 0.0929 - val_acc: 0.9877\n",
      "Epoch 97/100\n",
      "4222/4222 [==============================] - 2s 488us/step - loss: 0.0042 - acc: 0.9983 - val_loss: 0.0718 - val_acc: 0.9915\n",
      "Epoch 98/100\n",
      "4222/4222 [==============================] - 2s 484us/step - loss: 1.3440e-04 - acc: 1.0000 - val_loss: 0.0722 - val_acc: 0.9915\n",
      "Epoch 99/100\n",
      "4222/4222 [==============================] - 2s 488us/step - loss: 8.7245e-05 - acc: 1.0000 - val_loss: 0.0717 - val_acc: 0.9915\n",
      "Epoch 100/100\n",
      "4222/4222 [==============================] - 2s 467us/step - loss: 7.3184e-05 - acc: 1.0000 - val_loss: 0.0718 - val_acc: 0.9915\n",
      "[[1114    6]\n",
      " [   3  197]]\n",
      "0.9931818181818182\n"
     ]
    }
   ],
   "source": [
    "classifier = Sequential()\n",
    "\n",
    "classifier.add(Dense(units = 20, kernel_initializer = 'he_uniform', activation = 'relu', input_dim = 166))\n",
    "\n",
    "classifier.add(Dense(units = 6, kernel_initializer = 'he_uniform', activation = 'relu'))\n",
    "\n",
    "classifier.add(Dense(units = 1, kernel_initializer = 'glorot_uniform', activation = 'sigmoid'))\n",
    "\n",
    "classifier.summary()\n",
    "\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "model = classifier.fit(X_train, y_train, validation_split = 0.2, batch_size = 10, nb_epoch = 100)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "score = accuracy_score(y_pred, y_test)\n",
    "print(cm)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Simple Sequential model with [50,6,1] layers, batch size = 10 and epochs = 100.\n",
    "Increased the no. of nodes in 1st hidden layer which increased the accuracy to 99.469%</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_370 (Dense)            (None, 50)                8350      \n",
      "_________________________________________________________________\n",
      "dense_371 (Dense)            (None, 6)                 306       \n",
      "_________________________________________________________________\n",
      "dense_372 (Dense)            (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 8,663\n",
      "Trainable params: 8,663\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "Train on 4222 samples, validate on 1056 samples\n",
      "Epoch 1/100\n",
      "4222/4222 [==============================] - 11s 3ms/step - loss: 0.2656 - acc: 0.8823 - val_loss: 0.1604 - val_acc: 0.9441\n",
      "Epoch 2/100\n",
      "4222/4222 [==============================] - 2s 448us/step - loss: 0.1346 - acc: 0.9486 - val_loss: 0.1168 - val_acc: 0.9602\n",
      "Epoch 3/100\n",
      "4222/4222 [==============================] - 2s 443us/step - loss: 0.0982 - acc: 0.9621 - val_loss: 0.0910 - val_acc: 0.9678\n",
      "Epoch 4/100\n",
      "4222/4222 [==============================] - 2s 443us/step - loss: 0.0752 - acc: 0.9711 - val_loss: 0.0755 - val_acc: 0.9763\n",
      "Epoch 5/100\n",
      "4222/4222 [==============================] - 2s 446us/step - loss: 0.0567 - acc: 0.9787 - val_loss: 0.0638 - val_acc: 0.9792\n",
      "Epoch 6/100\n",
      "4222/4222 [==============================] - 2s 443us/step - loss: 0.0439 - acc: 0.9839 - val_loss: 0.0612 - val_acc: 0.9792\n",
      "Epoch 7/100\n",
      "4222/4222 [==============================] - 2s 449us/step - loss: 0.0381 - acc: 0.9860 - val_loss: 0.0598 - val_acc: 0.9811\n",
      "Epoch 8/100\n",
      "4222/4222 [==============================] - 2s 445us/step - loss: 0.0271 - acc: 0.9915 - val_loss: 0.0529 - val_acc: 0.9848\n",
      "Epoch 9/100\n",
      "4222/4222 [==============================] - 2s 469us/step - loss: 0.0219 - acc: 0.9934 - val_loss: 0.0527 - val_acc: 0.9820\n",
      "Epoch 10/100\n",
      "4222/4222 [==============================] - 2s 475us/step - loss: 0.0163 - acc: 0.9948 - val_loss: 0.0401 - val_acc: 0.9886\n",
      "Epoch 11/100\n",
      "4222/4222 [==============================] - 2s 513us/step - loss: 0.0165 - acc: 0.9950 - val_loss: 0.0502 - val_acc: 0.9877\n",
      "Epoch 12/100\n",
      "4222/4222 [==============================] - 2s 505us/step - loss: 0.0104 - acc: 0.9981 - val_loss: 0.0441 - val_acc: 0.9886\n",
      "Epoch 13/100\n",
      "4222/4222 [==============================] - 2s 526us/step - loss: 0.0135 - acc: 0.9957 - val_loss: 0.0468 - val_acc: 0.9867\n",
      "Epoch 14/100\n",
      "4222/4222 [==============================] - 2s 515us/step - loss: 0.0128 - acc: 0.9953 - val_loss: 0.0419 - val_acc: 0.9924\n",
      "Epoch 15/100\n",
      "4222/4222 [==============================] - 2s 471us/step - loss: 0.0091 - acc: 0.9964 - val_loss: 0.0537 - val_acc: 0.9877\n",
      "Epoch 16/100\n",
      "4222/4222 [==============================] - 2s 453us/step - loss: 0.0064 - acc: 0.9983 - val_loss: 0.0431 - val_acc: 0.9905\n",
      "Epoch 17/100\n",
      "4222/4222 [==============================] - 2s 459us/step - loss: 0.0059 - acc: 0.9981 - val_loss: 0.0462 - val_acc: 0.9896\n",
      "Epoch 18/100\n",
      "4222/4222 [==============================] - 2s 454us/step - loss: 0.0049 - acc: 0.9988 - val_loss: 0.0425 - val_acc: 0.9905\n",
      "Epoch 19/100\n",
      "4222/4222 [==============================] - 2s 452us/step - loss: 0.0023 - acc: 0.9995 - val_loss: 0.0444 - val_acc: 0.9905\n",
      "Epoch 20/100\n",
      "4222/4222 [==============================] - 2s 486us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0402 - val_acc: 0.9934\n",
      "Epoch 21/100\n",
      "4222/4222 [==============================] - 2s 520us/step - loss: 8.9111e-04 - acc: 1.0000 - val_loss: 0.0429 - val_acc: 0.9915\n",
      "Epoch 22/100\n",
      "4222/4222 [==============================] - 2s 471us/step - loss: 0.0027 - acc: 0.9993 - val_loss: 0.0770 - val_acc: 0.9801\n",
      "Epoch 23/100\n",
      "4222/4222 [==============================] - 2s 453us/step - loss: 0.0244 - acc: 0.9929 - val_loss: 0.0944 - val_acc: 0.9782\n",
      "Epoch 24/100\n",
      "4222/4222 [==============================] - 2s 455us/step - loss: 0.0176 - acc: 0.9948 - val_loss: 0.0475 - val_acc: 0.9934\n",
      "Epoch 25/100\n",
      "4222/4222 [==============================] - 2s 457us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0496 - val_acc: 0.9915\n",
      "Epoch 26/100\n",
      "4222/4222 [==============================] - 2s 458us/step - loss: 7.6805e-04 - acc: 1.0000 - val_loss: 0.0500 - val_acc: 0.9915\n",
      "Epoch 27/100\n",
      "4222/4222 [==============================] - 2s 449us/step - loss: 5.5221e-04 - acc: 1.0000 - val_loss: 0.0493 - val_acc: 0.9924\n",
      "Epoch 28/100\n",
      "4222/4222 [==============================] - 2s 456us/step - loss: 4.3048e-04 - acc: 1.0000 - val_loss: 0.0506 - val_acc: 0.9915\n",
      "Epoch 29/100\n",
      "4222/4222 [==============================] - 2s 541us/step - loss: 4.2915e-04 - acc: 1.0000 - val_loss: 0.0512 - val_acc: 0.9934\n",
      "Epoch 30/100\n",
      "4222/4222 [==============================] - 2s 560us/step - loss: 3.4890e-04 - acc: 1.0000 - val_loss: 0.0508 - val_acc: 0.9934\n",
      "Epoch 31/100\n",
      "4222/4222 [==============================] - 2s 483us/step - loss: 6.0553e-04 - acc: 1.0000 - val_loss: 0.0502 - val_acc: 0.9924\n",
      "Epoch 32/100\n",
      "4222/4222 [==============================] - 2s 578us/step - loss: 8.1351e-04 - acc: 0.9998 - val_loss: 0.0698 - val_acc: 0.9886\n",
      "Epoch 33/100\n",
      "4222/4222 [==============================] - 2s 453us/step - loss: 0.0342 - acc: 0.9901 - val_loss: 0.0621 - val_acc: 0.9905\n",
      "Epoch 34/100\n",
      "4222/4222 [==============================] - 2s 493us/step - loss: 0.0046 - acc: 0.9986 - val_loss: 0.0362 - val_acc: 0.9915\n",
      "Epoch 35/100\n",
      "4222/4222 [==============================] - 2s 456us/step - loss: 5.8370e-04 - acc: 1.0000 - val_loss: 0.0365 - val_acc: 0.9924\n",
      "Epoch 36/100\n",
      "4222/4222 [==============================] - 2s 491us/step - loss: 3.7279e-04 - acc: 1.0000 - val_loss: 0.0397 - val_acc: 0.9905\n",
      "Epoch 37/100\n",
      "4222/4222 [==============================] - 2s 529us/step - loss: 2.9524e-04 - acc: 1.0000 - val_loss: 0.0381 - val_acc: 0.9924\n",
      "Epoch 38/100\n",
      "4222/4222 [==============================] - 2s 459us/step - loss: 2.5337e-04 - acc: 1.0000 - val_loss: 0.0386 - val_acc: 0.9915\n",
      "Epoch 39/100\n",
      "4222/4222 [==============================] - 2s 443us/step - loss: 2.0347e-04 - acc: 1.0000 - val_loss: 0.0369 - val_acc: 0.9924\n",
      "Epoch 40/100\n",
      "4222/4222 [==============================] - 2s 435us/step - loss: 2.1441e-04 - acc: 1.0000 - val_loss: 0.0397 - val_acc: 0.9924\n",
      "Epoch 41/100\n",
      "4222/4222 [==============================] - 2s 443us/step - loss: 1.5540e-04 - acc: 1.0000 - val_loss: 0.0391 - val_acc: 0.9943\n",
      "Epoch 42/100\n",
      "4222/4222 [==============================] - 2s 441us/step - loss: 1.3763e-04 - acc: 1.0000 - val_loss: 0.0399 - val_acc: 0.9924\n",
      "Epoch 43/100\n",
      "4222/4222 [==============================] - 2s 439us/step - loss: 1.2890e-04 - acc: 1.0000 - val_loss: 0.0396 - val_acc: 0.9934\n",
      "Epoch 44/100\n",
      "4222/4222 [==============================] - 2s 447us/step - loss: 9.8361e-05 - acc: 1.0000 - val_loss: 0.0420 - val_acc: 0.9934\n",
      "Epoch 45/100\n",
      "4222/4222 [==============================] - 2s 438us/step - loss: 8.8753e-05 - acc: 1.0000 - val_loss: 0.0444 - val_acc: 0.9924\n",
      "Epoch 46/100\n",
      "4222/4222 [==============================] - 2s 436us/step - loss: 0.0576 - acc: 0.9889 - val_loss: 0.0544 - val_acc: 0.9896\n",
      "Epoch 47/100\n",
      "4222/4222 [==============================] - 2s 442us/step - loss: 0.0032 - acc: 0.9988 - val_loss: 0.0496 - val_acc: 0.9905\n",
      "Epoch 48/100\n",
      "4222/4222 [==============================] - 2s 440us/step - loss: 3.8903e-04 - acc: 1.0000 - val_loss: 0.0472 - val_acc: 0.9924\n",
      "Epoch 49/100\n",
      "4222/4222 [==============================] - 2s 443us/step - loss: 2.5277e-04 - acc: 1.0000 - val_loss: 0.0450 - val_acc: 0.9924\n",
      "Epoch 50/100\n",
      "4222/4222 [==============================] - 2s 443us/step - loss: 1.8562e-04 - acc: 1.0000 - val_loss: 0.0447 - val_acc: 0.9934\n",
      "Epoch 51/100\n",
      "4222/4222 [==============================] - 2s 441us/step - loss: 1.6603e-04 - acc: 1.0000 - val_loss: 0.0437 - val_acc: 0.9924\n",
      "Epoch 52/100\n",
      "4222/4222 [==============================] - 2s 438us/step - loss: 1.4028e-04 - acc: 1.0000 - val_loss: 0.0433 - val_acc: 0.9934\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4222/4222 [==============================] - 2s 439us/step - loss: 1.3160e-04 - acc: 1.0000 - val_loss: 0.0430 - val_acc: 0.9924\n",
      "Epoch 54/100\n",
      "4222/4222 [==============================] - 2s 463us/step - loss: 1.0316e-04 - acc: 1.0000 - val_loss: 0.0421 - val_acc: 0.9924\n",
      "Epoch 55/100\n",
      "4222/4222 [==============================] - 2s 536us/step - loss: 9.2316e-05 - acc: 1.0000 - val_loss: 0.0409 - val_acc: 0.9934\n",
      "Epoch 56/100\n",
      "4222/4222 [==============================] - 2s 501us/step - loss: 7.7555e-05 - acc: 1.0000 - val_loss: 0.0412 - val_acc: 0.9924\n",
      "Epoch 57/100\n",
      "4222/4222 [==============================] - 2s 476us/step - loss: 6.8717e-05 - acc: 1.0000 - val_loss: 0.0390 - val_acc: 0.9934\n",
      "Epoch 58/100\n",
      "4222/4222 [==============================] - 2s 466us/step - loss: 6.1147e-05 - acc: 1.0000 - val_loss: 0.0402 - val_acc: 0.9934\n",
      "Epoch 59/100\n",
      "4222/4222 [==============================] - 2s 444us/step - loss: 0.0341 - acc: 0.9934 - val_loss: 0.0964 - val_acc: 0.9820\n",
      "Epoch 60/100\n",
      "4222/4222 [==============================] - 2s 472us/step - loss: 0.0093 - acc: 0.9967 - val_loss: 0.0545 - val_acc: 0.9915\n",
      "Epoch 61/100\n",
      "4222/4222 [==============================] - 2s 466us/step - loss: 4.5757e-04 - acc: 1.0000 - val_loss: 0.0438 - val_acc: 0.9924\n",
      "Epoch 62/100\n",
      "4222/4222 [==============================] - 2s 485us/step - loss: 2.3483e-04 - acc: 1.0000 - val_loss: 0.0436 - val_acc: 0.9924\n",
      "Epoch 63/100\n",
      "4222/4222 [==============================] - 2s 470us/step - loss: 1.7789e-04 - acc: 1.0000 - val_loss: 0.0438 - val_acc: 0.9924\n",
      "Epoch 64/100\n",
      "4222/4222 [==============================] - 2s 475us/step - loss: 1.4978e-04 - acc: 1.0000 - val_loss: 0.0438 - val_acc: 0.9934\n",
      "Epoch 65/100\n",
      "4222/4222 [==============================] - 3s 618us/step - loss: 1.2473e-04 - acc: 1.0000 - val_loss: 0.0443 - val_acc: 0.9934\n",
      "Epoch 66/100\n",
      "4222/4222 [==============================] - 2s 572us/step - loss: 1.0478e-04 - acc: 1.0000 - val_loss: 0.0446 - val_acc: 0.9934\n",
      "Epoch 67/100\n",
      "4222/4222 [==============================] - 2s 442us/step - loss: 8.9148e-05 - acc: 1.0000 - val_loss: 0.0442 - val_acc: 0.9934\n",
      "Epoch 68/100\n",
      "4222/4222 [==============================] - 2s 450us/step - loss: 7.3174e-05 - acc: 1.0000 - val_loss: 0.0440 - val_acc: 0.9943\n",
      "Epoch 69/100\n",
      "4222/4222 [==============================] - 2s 446us/step - loss: 6.3818e-05 - acc: 1.0000 - val_loss: 0.0439 - val_acc: 0.9934\n",
      "Epoch 70/100\n",
      "4222/4222 [==============================] - 2s 445us/step - loss: 5.1266e-05 - acc: 1.0000 - val_loss: 0.0436 - val_acc: 0.9934\n",
      "Epoch 71/100\n",
      "4222/4222 [==============================] - 2s 446us/step - loss: 4.4553e-05 - acc: 1.0000 - val_loss: 0.0452 - val_acc: 0.9924\n",
      "Epoch 72/100\n",
      "4222/4222 [==============================] - 2s 450us/step - loss: 3.6644e-05 - acc: 1.0000 - val_loss: 0.0442 - val_acc: 0.9943\n",
      "Epoch 73/100\n",
      "4222/4222 [==============================] - 2s 446us/step - loss: 3.0992e-05 - acc: 1.0000 - val_loss: 0.0432 - val_acc: 0.9943\n",
      "Epoch 74/100\n",
      "4222/4222 [==============================] - 2s 450us/step - loss: 2.6388e-05 - acc: 1.0000 - val_loss: 0.0429 - val_acc: 0.9934\n",
      "Epoch 75/100\n",
      "4222/4222 [==============================] - 2s 445us/step - loss: 2.3325e-05 - acc: 1.0000 - val_loss: 0.0446 - val_acc: 0.9924\n",
      "Epoch 76/100\n",
      "4222/4222 [==============================] - 2s 443us/step - loss: 1.8351e-05 - acc: 1.0000 - val_loss: 0.0436 - val_acc: 0.9934\n",
      "Epoch 77/100\n",
      "4222/4222 [==============================] - 2s 450us/step - loss: 1.5723e-05 - acc: 1.0000 - val_loss: 0.0457 - val_acc: 0.9924\n",
      "Epoch 78/100\n",
      "4222/4222 [==============================] - 2s 444us/step - loss: 1.2392e-05 - acc: 1.0000 - val_loss: 0.0459 - val_acc: 0.9924\n",
      "Epoch 79/100\n",
      "4222/4222 [==============================] - 2s 445us/step - loss: 1.0816e-05 - acc: 1.0000 - val_loss: 0.0466 - val_acc: 0.9943\n",
      "Epoch 80/100\n",
      "4222/4222 [==============================] - 2s 447us/step - loss: 8.5885e-06 - acc: 1.0000 - val_loss: 0.0488 - val_acc: 0.9924\n",
      "Epoch 81/100\n",
      "4222/4222 [==============================] - 2s 455us/step - loss: 7.2843e-06 - acc: 1.0000 - val_loss: 0.0471 - val_acc: 0.9934\n",
      "Epoch 82/100\n",
      "4222/4222 [==============================] - 2s 448us/step - loss: 6.2563e-06 - acc: 1.0000 - val_loss: 0.0494 - val_acc: 0.9924\n",
      "Epoch 83/100\n",
      "4222/4222 [==============================] - 2s 444us/step - loss: 4.6315e-06 - acc: 1.0000 - val_loss: 0.0495 - val_acc: 0.9924\n",
      "Epoch 84/100\n",
      "4222/4222 [==============================] - 2s 441us/step - loss: 3.8790e-06 - acc: 1.0000 - val_loss: 0.0510 - val_acc: 0.9924\n",
      "Epoch 85/100\n",
      "4222/4222 [==============================] - 2s 445us/step - loss: 3.1630e-06 - acc: 1.0000 - val_loss: 0.0510 - val_acc: 0.9924\n",
      "Epoch 86/100\n",
      "4222/4222 [==============================] - 2s 450us/step - loss: 2.4077e-06 - acc: 1.0000 - val_loss: 0.0494 - val_acc: 0.9934\n",
      "Epoch 87/100\n",
      "4222/4222 [==============================] - 2s 445us/step - loss: 1.8012e-06 - acc: 1.0000 - val_loss: 0.0516 - val_acc: 0.9924\n",
      "Epoch 88/100\n",
      "4222/4222 [==============================] - 2s 449us/step - loss: 2.4416e-06 - acc: 1.0000 - val_loss: 0.0486 - val_acc: 0.9943\n",
      "Epoch 89/100\n",
      "4222/4222 [==============================] - 2s 447us/step - loss: 0.0386 - acc: 0.9905 - val_loss: 0.0619 - val_acc: 0.9905\n",
      "Epoch 90/100\n",
      "4222/4222 [==============================] - 2s 447us/step - loss: 0.0107 - acc: 0.9974 - val_loss: 0.0683 - val_acc: 0.9915\n",
      "Epoch 91/100\n",
      "4222/4222 [==============================] - 2s 448us/step - loss: 1.9481e-04 - acc: 1.0000 - val_loss: 0.0658 - val_acc: 0.9915\n",
      "Epoch 92/100\n",
      "4222/4222 [==============================] - 2s 458us/step - loss: 1.0535e-04 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9915\n",
      "Epoch 93/100\n",
      "4222/4222 [==============================] - 2s 532us/step - loss: 8.1827e-05 - acc: 1.0000 - val_loss: 0.0648 - val_acc: 0.9915\n",
      "Epoch 94/100\n",
      "4222/4222 [==============================] - 2s 514us/step - loss: 6.8345e-05 - acc: 1.0000 - val_loss: 0.0636 - val_acc: 0.9915\n",
      "Epoch 95/100\n",
      "4222/4222 [==============================] - 2s 465us/step - loss: 5.6364e-05 - acc: 1.0000 - val_loss: 0.0632 - val_acc: 0.9915\n",
      "Epoch 96/100\n",
      "4222/4222 [==============================] - 2s 457us/step - loss: 4.6933e-05 - acc: 1.0000 - val_loss: 0.0626 - val_acc: 0.9915\n",
      "Epoch 97/100\n",
      "4222/4222 [==============================] - 2s 455us/step - loss: 4.0544e-05 - acc: 1.0000 - val_loss: 0.0620 - val_acc: 0.9915\n",
      "Epoch 98/100\n",
      "4222/4222 [==============================] - 2s 456us/step - loss: 3.4676e-05 - acc: 1.0000 - val_loss: 0.0616 - val_acc: 0.9924\n",
      "Epoch 99/100\n",
      "4222/4222 [==============================] - 2s 455us/step - loss: 2.8211e-05 - acc: 1.0000 - val_loss: 0.0611 - val_acc: 0.9924\n",
      "Epoch 100/100\n",
      "4222/4222 [==============================] - 2s 461us/step - loss: 2.4148e-05 - acc: 1.0000 - val_loss: 0.0609 - val_acc: 0.9924\n",
      "[[1117    3]\n",
      " [   4  196]]\n",
      "0.9946969696969697\n"
     ]
    }
   ],
   "source": [
    "classifier = Sequential()\n",
    "\n",
    "classifier.add(Dense(units = 50, kernel_initializer = 'he_uniform', activation = 'relu', input_dim = 166))\n",
    "\n",
    "classifier.add(Dense(units = 6, kernel_initializer = 'he_uniform', activation = 'relu'))\n",
    "\n",
    "classifier.add(Dense(units = 1, kernel_initializer = 'glorot_uniform', activation = 'sigmoid'))\n",
    "\n",
    "classifier.summary()\n",
    "\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "model = classifier.fit(X_train, y_train, validation_split = 0.2, batch_size = 10, nb_epoch = 100)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "score = accuracy_score(y_pred, y_test)\n",
    "print(cm)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Simple Sequential model with [80,6,1] layers, batch size = 10 and epochs = 100.\n",
    "Increased the no. of nodes in 1st hidden layer which increased the accuracy to 99.545%</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_373 (Dense)            (None, 80)                13360     \n",
      "_________________________________________________________________\n",
      "dense_374 (Dense)            (None, 6)                 486       \n",
      "_________________________________________________________________\n",
      "dense_375 (Dense)            (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 13,853\n",
      "Trainable params: 13,853\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "Train on 4222 samples, validate on 1056 samples\n",
      "Epoch 1/100\n",
      "4222/4222 [==============================] - 11s 3ms/step - loss: 0.2652 - acc: 0.8892 - val_loss: 0.1525 - val_acc: 0.9299\n",
      "Epoch 2/100\n",
      "4222/4222 [==============================] - 2s 452us/step - loss: 0.1283 - acc: 0.9429 - val_loss: 0.1209 - val_acc: 0.9650\n",
      "Epoch 3/100\n",
      "4222/4222 [==============================] - 2s 451us/step - loss: 0.0917 - acc: 0.9683 - val_loss: 0.0912 - val_acc: 0.9669\n",
      "Epoch 4/100\n",
      "4222/4222 [==============================] - 2s 455us/step - loss: 0.0693 - acc: 0.9730 - val_loss: 0.0834 - val_acc: 0.9612\n",
      "Epoch 5/100\n",
      "4222/4222 [==============================] - 2s 453us/step - loss: 0.0535 - acc: 0.9787 - val_loss: 0.0612 - val_acc: 0.9754\n",
      "Epoch 6/100\n",
      "4222/4222 [==============================] - 2s 455us/step - loss: 0.0433 - acc: 0.9839 - val_loss: 0.0508 - val_acc: 0.9811\n",
      "Epoch 7/100\n",
      "4222/4222 [==============================] - 2s 451us/step - loss: 0.0363 - acc: 0.9863 - val_loss: 0.0483 - val_acc: 0.9848\n",
      "Epoch 8/100\n",
      "4222/4222 [==============================] - 2s 454us/step - loss: 0.0224 - acc: 0.9934 - val_loss: 0.0398 - val_acc: 0.9848\n",
      "Epoch 9/100\n",
      "4222/4222 [==============================] - 2s 457us/step - loss: 0.0184 - acc: 0.9927 - val_loss: 0.0358 - val_acc: 0.9886\n",
      "Epoch 10/100\n",
      "4222/4222 [==============================] - 2s 454us/step - loss: 0.0160 - acc: 0.9948 - val_loss: 0.0350 - val_acc: 0.9905\n",
      "Epoch 11/100\n",
      "4222/4222 [==============================] - 2s 457us/step - loss: 0.0125 - acc: 0.9957 - val_loss: 0.0508 - val_acc: 0.9839\n",
      "Epoch 12/100\n",
      "4222/4222 [==============================] - 2s 454us/step - loss: 0.0160 - acc: 0.9941 - val_loss: 0.0360 - val_acc: 0.9886\n",
      "Epoch 13/100\n",
      "4222/4222 [==============================] - 2s 453us/step - loss: 0.0103 - acc: 0.9964 - val_loss: 0.0333 - val_acc: 0.9924\n",
      "Epoch 14/100\n",
      "4222/4222 [==============================] - 2s 511us/step - loss: 0.0046 - acc: 0.9995 - val_loss: 0.0447 - val_acc: 0.9886\n",
      "Epoch 15/100\n",
      "4222/4222 [==============================] - 2s 460us/step - loss: 0.0072 - acc: 0.9986 - val_loss: 0.0344 - val_acc: 0.9905\n",
      "Epoch 16/100\n",
      "4222/4222 [==============================] - 2s 463us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0285 - val_acc: 0.9943\n",
      "Epoch 17/100\n",
      "4222/4222 [==============================] - 2s 461us/step - loss: 0.0019 - acc: 0.9998 - val_loss: 0.0311 - val_acc: 0.9915\n",
      "Epoch 18/100\n",
      "4222/4222 [==============================] - 2s 458us/step - loss: 0.0379 - acc: 0.9924 - val_loss: 0.1457 - val_acc: 0.9763\n",
      "Epoch 19/100\n",
      "4222/4222 [==============================] - 2s 500us/step - loss: 0.0254 - acc: 0.9941 - val_loss: 0.1020 - val_acc: 0.9659\n",
      "Epoch 20/100\n",
      "4222/4222 [==============================] - 2s 468us/step - loss: 0.0026 - acc: 0.9998 - val_loss: 0.0318 - val_acc: 0.9934\n",
      "Epoch 21/100\n",
      "4222/4222 [==============================] - 2s 469us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0317 - val_acc: 0.9905\n",
      "Epoch 22/100\n",
      "4222/4222 [==============================] - 2s 464us/step - loss: 8.5162e-04 - acc: 1.0000 - val_loss: 0.0283 - val_acc: 0.9934\n",
      "Epoch 23/100\n",
      "4222/4222 [==============================] - 2s 461us/step - loss: 6.5728e-04 - acc: 1.0000 - val_loss: 0.0274 - val_acc: 0.9934\n",
      "Epoch 24/100\n",
      "4222/4222 [==============================] - 2s 461us/step - loss: 5.1790e-04 - acc: 1.0000 - val_loss: 0.0285 - val_acc: 0.9943\n",
      "Epoch 25/100\n",
      "4222/4222 [==============================] - 2s 466us/step - loss: 0.0014 - acc: 0.9998 - val_loss: 0.0414 - val_acc: 0.9905\n",
      "Epoch 26/100\n",
      "4222/4222 [==============================] - 2s 468us/step - loss: 0.0368 - acc: 0.9901 - val_loss: 0.0437 - val_acc: 0.9915\n",
      "Epoch 27/100\n",
      "4222/4222 [==============================] - 2s 464us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0368 - val_acc: 0.9934\n",
      "Epoch 28/100\n",
      "4222/4222 [==============================] - 2s 462us/step - loss: 8.3557e-04 - acc: 1.0000 - val_loss: 0.0387 - val_acc: 0.9924\n",
      "Epoch 29/100\n",
      "4222/4222 [==============================] - 2s 471us/step - loss: 6.2508e-04 - acc: 1.0000 - val_loss: 0.0350 - val_acc: 0.9943\n",
      "Epoch 30/100\n",
      "4222/4222 [==============================] - 2s 464us/step - loss: 4.4476e-04 - acc: 1.0000 - val_loss: 0.0334 - val_acc: 0.9953\n",
      "Epoch 31/100\n",
      "4222/4222 [==============================] - 2s 490us/step - loss: 3.2460e-04 - acc: 1.0000 - val_loss: 0.0339 - val_acc: 0.9943\n",
      "Epoch 32/100\n",
      "4222/4222 [==============================] - 2s 511us/step - loss: 2.6804e-04 - acc: 1.0000 - val_loss: 0.0326 - val_acc: 0.9943\n",
      "Epoch 33/100\n",
      "4222/4222 [==============================] - 2s 461us/step - loss: 2.3557e-04 - acc: 1.0000 - val_loss: 0.0327 - val_acc: 0.9943\n",
      "Epoch 34/100\n",
      "4222/4222 [==============================] - 2s 501us/step - loss: 1.9985e-04 - acc: 1.0000 - val_loss: 0.0316 - val_acc: 0.9943\n",
      "Epoch 35/100\n",
      "4222/4222 [==============================] - 2s 461us/step - loss: 1.8283e-04 - acc: 1.0000 - val_loss: 0.0316 - val_acc: 0.9953\n",
      "Epoch 36/100\n",
      "4222/4222 [==============================] - 2s 457us/step - loss: 0.0528 - acc: 0.9853 - val_loss: 0.0943 - val_acc: 0.9792\n",
      "Epoch 37/100\n",
      "4222/4222 [==============================] - 2s 460us/step - loss: 0.0136 - acc: 0.9950 - val_loss: 0.0369 - val_acc: 0.9915\n",
      "Epoch 38/100\n",
      "4222/4222 [==============================] - 2s 459us/step - loss: 0.0046 - acc: 0.9988 - val_loss: 0.0484 - val_acc: 0.9858\n",
      "Epoch 39/100\n",
      "4222/4222 [==============================] - 2s 485us/step - loss: 0.0055 - acc: 0.9979 - val_loss: 0.0322 - val_acc: 0.9934\n",
      "Epoch 40/100\n",
      "4222/4222 [==============================] - 2s 464us/step - loss: 8.3727e-04 - acc: 1.0000 - val_loss: 0.0325 - val_acc: 0.9934\n",
      "Epoch 41/100\n",
      "4222/4222 [==============================] - 2s 520us/step - loss: 5.0588e-04 - acc: 1.0000 - val_loss: 0.0324 - val_acc: 0.9943\n",
      "Epoch 42/100\n",
      "4222/4222 [==============================] - 2s 469us/step - loss: 4.0629e-04 - acc: 1.0000 - val_loss: 0.0350 - val_acc: 0.9924\n",
      "Epoch 43/100\n",
      "4222/4222 [==============================] - 2s 458us/step - loss: 3.5926e-04 - acc: 1.0000 - val_loss: 0.0321 - val_acc: 0.9924\n",
      "Epoch 44/100\n",
      "4222/4222 [==============================] - 2s 464us/step - loss: 2.8835e-04 - acc: 1.0000 - val_loss: 0.0319 - val_acc: 0.9924\n",
      "Epoch 45/100\n",
      "4222/4222 [==============================] - 2s 459us/step - loss: 2.1912e-04 - acc: 1.0000 - val_loss: 0.0310 - val_acc: 0.9934\n",
      "Epoch 46/100\n",
      "4222/4222 [==============================] - 2s 514us/step - loss: 1.9568e-04 - acc: 1.0000 - val_loss: 0.0333 - val_acc: 0.9924\n",
      "Epoch 47/100\n",
      "4222/4222 [==============================] - 2s 590us/step - loss: 0.0071 - acc: 0.9976 - val_loss: 0.1001 - val_acc: 0.9792\n",
      "Epoch 48/100\n",
      "4222/4222 [==============================] - 2s 532us/step - loss: 0.0305 - acc: 0.9910 - val_loss: 0.0379 - val_acc: 0.9915\n",
      "Epoch 49/100\n",
      "4222/4222 [==============================] - 2s 453us/step - loss: 0.0024 - acc: 0.9993 - val_loss: 0.0484 - val_acc: 0.9896\n",
      "Epoch 50/100\n",
      "4222/4222 [==============================] - 2s 450us/step - loss: 8.9588e-04 - acc: 1.0000 - val_loss: 0.0443 - val_acc: 0.9905\n",
      "Epoch 51/100\n",
      "4222/4222 [==============================] - 2s 450us/step - loss: 2.3018e-04 - acc: 1.0000 - val_loss: 0.0395 - val_acc: 0.9934\n",
      "Epoch 52/100\n",
      "4222/4222 [==============================] - 2s 531us/step - loss: 1.3710e-04 - acc: 1.0000 - val_loss: 0.0375 - val_acc: 0.9943\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4222/4222 [==============================] - 2s 564us/step - loss: 1.0913e-04 - acc: 1.0000 - val_loss: 0.0370 - val_acc: 0.9943\n",
      "Epoch 54/100\n",
      "4222/4222 [==============================] - 2s 553us/step - loss: 8.7775e-05 - acc: 1.0000 - val_loss: 0.0368 - val_acc: 0.9943\n",
      "Epoch 55/100\n",
      "4222/4222 [==============================] - 2s 458us/step - loss: 7.3256e-05 - acc: 1.0000 - val_loss: 0.0367 - val_acc: 0.9943\n",
      "Epoch 56/100\n",
      "4222/4222 [==============================] - 2s 453us/step - loss: 6.2568e-05 - acc: 1.0000 - val_loss: 0.0354 - val_acc: 0.9943\n",
      "Epoch 57/100\n",
      "4222/4222 [==============================] - 2s 450us/step - loss: 5.3641e-05 - acc: 1.0000 - val_loss: 0.0353 - val_acc: 0.9943\n",
      "Epoch 58/100\n",
      "4222/4222 [==============================] - 2s 575us/step - loss: 4.4459e-05 - acc: 1.0000 - val_loss: 0.0344 - val_acc: 0.9943\n",
      "Epoch 59/100\n",
      "4222/4222 [==============================] - 3s 599us/step - loss: 3.8872e-05 - acc: 1.0000 - val_loss: 0.0355 - val_acc: 0.9934\n",
      "Epoch 60/100\n",
      "4222/4222 [==============================] - 2s 467us/step - loss: 3.3278e-05 - acc: 1.0000 - val_loss: 0.0342 - val_acc: 0.9943\n",
      "Epoch 61/100\n",
      "4222/4222 [==============================] - 2s 482us/step - loss: 3.0300e-05 - acc: 1.0000 - val_loss: 0.0351 - val_acc: 0.9934\n",
      "Epoch 62/100\n",
      "4222/4222 [==============================] - 2s 457us/step - loss: 2.3463e-05 - acc: 1.0000 - val_loss: 0.0333 - val_acc: 0.9943\n",
      "Epoch 63/100\n",
      "4222/4222 [==============================] - 2s 455us/step - loss: 1.9872e-05 - acc: 1.0000 - val_loss: 0.0332 - val_acc: 0.9943\n",
      "Epoch 64/100\n",
      "4222/4222 [==============================] - 2s 458us/step - loss: 1.6473e-05 - acc: 1.0000 - val_loss: 0.0332 - val_acc: 0.9943\n",
      "Epoch 65/100\n",
      "4222/4222 [==============================] - 2s 484us/step - loss: 1.4119e-05 - acc: 1.0000 - val_loss: 0.0334 - val_acc: 0.9943\n",
      "Epoch 66/100\n",
      "4222/4222 [==============================] - 2s 498us/step - loss: 1.1568e-05 - acc: 1.0000 - val_loss: 0.0323 - val_acc: 0.9953\n",
      "Epoch 67/100\n",
      "4222/4222 [==============================] - 2s 497us/step - loss: 9.6800e-06 - acc: 1.0000 - val_loss: 0.0328 - val_acc: 0.9953\n",
      "Epoch 68/100\n",
      "4222/4222 [==============================] - 2s 459us/step - loss: 8.2151e-06 - acc: 1.0000 - val_loss: 0.0327 - val_acc: 0.9943\n",
      "Epoch 69/100\n",
      "4222/4222 [==============================] - 2s 491us/step - loss: 6.5185e-06 - acc: 1.0000 - val_loss: 0.0330 - val_acc: 0.9943\n",
      "Epoch 70/100\n",
      "4222/4222 [==============================] - 2s 483us/step - loss: 0.0438 - acc: 0.9948 - val_loss: 0.1375 - val_acc: 0.9706\n",
      "Epoch 71/100\n",
      "4222/4222 [==============================] - 2s 472us/step - loss: 0.0263 - acc: 0.9943 - val_loss: 0.0659 - val_acc: 0.9877\n",
      "Epoch 72/100\n",
      "4222/4222 [==============================] - 2s 459us/step - loss: 0.0032 - acc: 0.9993 - val_loss: 0.0632 - val_acc: 0.9915\n",
      "Epoch 73/100\n",
      "4222/4222 [==============================] - 2s 518us/step - loss: 5.4072e-04 - acc: 1.0000 - val_loss: 0.0579 - val_acc: 0.9934\n",
      "Epoch 74/100\n",
      "4222/4222 [==============================] - 2s 474us/step - loss: 3.9052e-04 - acc: 1.0000 - val_loss: 0.0591 - val_acc: 0.9934\n",
      "Epoch 75/100\n",
      "4222/4222 [==============================] - 2s 461us/step - loss: 2.2609e-04 - acc: 1.0000 - val_loss: 0.0582 - val_acc: 0.9934\n",
      "Epoch 76/100\n",
      "4222/4222 [==============================] - 2s 459us/step - loss: 1.5609e-04 - acc: 1.0000 - val_loss: 0.0576 - val_acc: 0.9934\n",
      "Epoch 77/100\n",
      "4222/4222 [==============================] - 2s 459us/step - loss: 1.1501e-04 - acc: 1.0000 - val_loss: 0.0555 - val_acc: 0.9934\n",
      "Epoch 78/100\n",
      "4222/4222 [==============================] - 2s 459us/step - loss: 9.7122e-05 - acc: 1.0000 - val_loss: 0.0554 - val_acc: 0.9934\n",
      "Epoch 79/100\n",
      "4222/4222 [==============================] - 2s 459us/step - loss: 7.6498e-05 - acc: 1.0000 - val_loss: 0.0566 - val_acc: 0.9934\n",
      "Epoch 80/100\n",
      "4222/4222 [==============================] - 2s 460us/step - loss: 6.7053e-05 - acc: 1.0000 - val_loss: 0.0541 - val_acc: 0.9934\n",
      "Epoch 81/100\n",
      "4222/4222 [==============================] - 2s 489us/step - loss: 5.6819e-05 - acc: 1.0000 - val_loss: 0.0548 - val_acc: 0.9934\n",
      "Epoch 82/100\n",
      "4222/4222 [==============================] - 2s 504us/step - loss: 4.5622e-05 - acc: 1.0000 - val_loss: 0.0536 - val_acc: 0.9934\n",
      "Epoch 83/100\n",
      "4222/4222 [==============================] - 2s 491us/step - loss: 3.9145e-05 - acc: 1.0000 - val_loss: 0.0534 - val_acc: 0.9934\n",
      "Epoch 84/100\n",
      "4222/4222 [==============================] - 2s 492us/step - loss: 3.6144e-05 - acc: 1.0000 - val_loss: 0.0524 - val_acc: 0.9934\n",
      "Epoch 85/100\n",
      "4222/4222 [==============================] - 2s 492us/step - loss: 2.7968e-05 - acc: 1.0000 - val_loss: 0.0500 - val_acc: 0.9934\n",
      "Epoch 86/100\n",
      "4222/4222 [==============================] - 2s 473us/step - loss: 2.4857e-05 - acc: 1.0000 - val_loss: 0.0515 - val_acc: 0.9934\n",
      "Epoch 87/100\n",
      "4222/4222 [==============================] - 2s 486us/step - loss: 2.0493e-05 - acc: 1.0000 - val_loss: 0.0473 - val_acc: 0.9934\n",
      "Epoch 88/100\n",
      "4222/4222 [==============================] - 2s 508us/step - loss: 1.7567e-05 - acc: 1.0000 - val_loss: 0.0488 - val_acc: 0.9924\n",
      "Epoch 89/100\n",
      "4222/4222 [==============================] - 2s 503us/step - loss: 1.4547e-05 - acc: 1.0000 - val_loss: 0.0482 - val_acc: 0.9924\n",
      "Epoch 90/100\n",
      "4222/4222 [==============================] - 2s 502us/step - loss: 1.3423e-05 - acc: 1.0000 - val_loss: 0.0483 - val_acc: 0.9924\n",
      "Epoch 91/100\n",
      "4222/4222 [==============================] - 2s 500us/step - loss: 1.0673e-05 - acc: 1.0000 - val_loss: 0.0487 - val_acc: 0.9934\n",
      "Epoch 92/100\n",
      "4222/4222 [==============================] - 2s 501us/step - loss: 8.6921e-06 - acc: 1.0000 - val_loss: 0.0482 - val_acc: 0.9924\n",
      "Epoch 93/100\n",
      "4222/4222 [==============================] - 2s 506us/step - loss: 6.8668e-06 - acc: 1.0000 - val_loss: 0.0428 - val_acc: 0.9934\n",
      "Epoch 94/100\n",
      "4222/4222 [==============================] - 2s 507us/step - loss: 5.1762e-06 - acc: 1.0000 - val_loss: 0.0431 - val_acc: 0.9934\n",
      "Epoch 95/100\n",
      "4222/4222 [==============================] - 2s 492us/step - loss: 4.4005e-06 - acc: 1.0000 - val_loss: 0.0428 - val_acc: 0.9943\n",
      "Epoch 96/100\n",
      "4222/4222 [==============================] - 2s 495us/step - loss: 3.1784e-06 - acc: 1.0000 - val_loss: 0.0432 - val_acc: 0.9924\n",
      "Epoch 97/100\n",
      "4222/4222 [==============================] - 2s 491us/step - loss: 2.7002e-06 - acc: 1.0000 - val_loss: 0.0438 - val_acc: 0.9943\n",
      "Epoch 98/100\n",
      "4222/4222 [==============================] - 2s 486us/step - loss: 1.8990e-06 - acc: 1.0000 - val_loss: 0.0464 - val_acc: 0.9934\n",
      "Epoch 99/100\n",
      "4222/4222 [==============================] - 2s 475us/step - loss: 1.5092e-06 - acc: 1.0000 - val_loss: 0.0406 - val_acc: 0.9943\n",
      "Epoch 100/100\n",
      "4222/4222 [==============================] - 2s 490us/step - loss: 1.0818e-06 - acc: 1.0000 - val_loss: 0.0451 - val_acc: 0.9943\n",
      "[[1117    3]\n",
      " [   3  197]]\n",
      "0.9954545454545455\n"
     ]
    }
   ],
   "source": [
    "classifier = Sequential()\n",
    "\n",
    "classifier.add(Dense(units = 80, kernel_initializer = 'he_uniform', activation = 'relu', input_dim = 166))\n",
    "\n",
    "classifier.add(Dense(units = 6, kernel_initializer = 'he_uniform', activation = 'relu'))\n",
    "\n",
    "classifier.add(Dense(units = 1, kernel_initializer = 'glorot_uniform', activation = 'sigmoid'))\n",
    "\n",
    "classifier.summary()\n",
    "\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "model = classifier.fit(X_train, y_train, validation_split = 0.2, batch_size = 10, nb_epoch = 100)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "score = accuracy_score(y_pred, y_test)\n",
    "print(cm)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Simple Sequential model with [80,20,1] layers, batch size = 10 and epochs = 100.\n",
    "Increased the no. of nodes in 2nd hidden layer which didn't changed the accuracy.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_390 (Dense)            (None, 80)                13360     \n",
      "_________________________________________________________________\n",
      "dense_391 (Dense)            (None, 20)                1620      \n",
      "_________________________________________________________________\n",
      "dense_392 (Dense)            (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 15,001\n",
      "Trainable params: 15,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "Train on 4222 samples, validate on 1056 samples\n",
      "Epoch 1/100\n",
      "4222/4222 [==============================] - 14s 3ms/step - loss: 0.2232 - acc: 0.9112 - val_loss: 0.1352 - val_acc: 0.9479\n",
      "Epoch 2/100\n",
      "4222/4222 [==============================] - 2s 499us/step - loss: 0.1042 - acc: 0.9614 - val_loss: 0.1020 - val_acc: 0.9659\n",
      "Epoch 3/100\n",
      "4222/4222 [==============================] - 2s 482us/step - loss: 0.0743 - acc: 0.9706 - val_loss: 0.0789 - val_acc: 0.9706\n",
      "Epoch 4/100\n",
      "4222/4222 [==============================] - 2s 485us/step - loss: 0.0564 - acc: 0.9782 - val_loss: 0.0927 - val_acc: 0.9669\n",
      "Epoch 5/100\n",
      "4222/4222 [==============================] - 2s 487us/step - loss: 0.0464 - acc: 0.9820 - val_loss: 0.0732 - val_acc: 0.9754\n",
      "Epoch 6/100\n",
      "4222/4222 [==============================] - 2s 486us/step - loss: 0.0330 - acc: 0.9853 - val_loss: 0.0607 - val_acc: 0.9763\n",
      "Epoch 7/100\n",
      "4222/4222 [==============================] - 2s 487us/step - loss: 0.0304 - acc: 0.9893 - val_loss: 0.0554 - val_acc: 0.9811\n",
      "Epoch 8/100\n",
      "4222/4222 [==============================] - 2s 487us/step - loss: 0.0220 - acc: 0.9917 - val_loss: 0.0536 - val_acc: 0.9839\n",
      "Epoch 9/100\n",
      "4222/4222 [==============================] - 2s 492us/step - loss: 0.0178 - acc: 0.9941 - val_loss: 0.0514 - val_acc: 0.9858\n",
      "Epoch 10/100\n",
      "4222/4222 [==============================] - 2s 495us/step - loss: 0.0146 - acc: 0.9957 - val_loss: 0.0585 - val_acc: 0.9830\n",
      "Epoch 11/100\n",
      "4222/4222 [==============================] - 2s 486us/step - loss: 0.0152 - acc: 0.9936 - val_loss: 0.0580 - val_acc: 0.9867\n",
      "Epoch 12/100\n",
      "4222/4222 [==============================] - 2s 495us/step - loss: 0.0130 - acc: 0.9953 - val_loss: 0.0772 - val_acc: 0.9735\n",
      "Epoch 13/100\n",
      "4222/4222 [==============================] - 2s 493us/step - loss: 0.0172 - acc: 0.9929 - val_loss: 0.0552 - val_acc: 0.9877\n",
      "Epoch 14/100\n",
      "4222/4222 [==============================] - 2s 497us/step - loss: 0.0202 - acc: 0.9957 - val_loss: 0.0534 - val_acc: 0.9886\n",
      "Epoch 15/100\n",
      "4222/4222 [==============================] - 2s 501us/step - loss: 0.0066 - acc: 0.9969 - val_loss: 0.0508 - val_acc: 0.9896\n",
      "Epoch 16/100\n",
      "4222/4222 [==============================] - 2s 500us/step - loss: 0.0043 - acc: 0.9983 - val_loss: 0.0590 - val_acc: 0.9848\n",
      "Epoch 17/100\n",
      "4222/4222 [==============================] - 2s 490us/step - loss: 0.0037 - acc: 0.9991 - val_loss: 0.0499 - val_acc: 0.9905\n",
      "Epoch 18/100\n",
      "4222/4222 [==============================] - 2s 493us/step - loss: 0.0083 - acc: 0.9974 - val_loss: 0.0630 - val_acc: 0.9858\n",
      "Epoch 19/100\n",
      "4222/4222 [==============================] - 2s 501us/step - loss: 0.0021 - acc: 0.9998 - val_loss: 0.0465 - val_acc: 0.9915\n",
      "Epoch 20/100\n",
      "4222/4222 [==============================] - 2s 487us/step - loss: 0.0089 - acc: 0.9974 - val_loss: 0.0649 - val_acc: 0.9839\n",
      "Epoch 21/100\n",
      "4222/4222 [==============================] - 2s 494us/step - loss: 0.0275 - acc: 0.9912 - val_loss: 0.0679 - val_acc: 0.9858\n",
      "Epoch 22/100\n",
      "4222/4222 [==============================] - 2s 489us/step - loss: 0.0033 - acc: 0.9988 - val_loss: 0.0534 - val_acc: 0.9915\n",
      "Epoch 23/100\n",
      "4222/4222 [==============================] - 2s 489us/step - loss: 6.9295e-04 - acc: 1.0000 - val_loss: 0.0540 - val_acc: 0.9915\n",
      "Epoch 24/100\n",
      "4222/4222 [==============================] - 2s 492us/step - loss: 4.5565e-04 - acc: 1.0000 - val_loss: 0.0537 - val_acc: 0.9915\n",
      "Epoch 25/100\n",
      "4222/4222 [==============================] - 2s 488us/step - loss: 3.3095e-04 - acc: 1.0000 - val_loss: 0.0535 - val_acc: 0.9915\n",
      "Epoch 26/100\n",
      "4222/4222 [==============================] - 2s 488us/step - loss: 2.4745e-04 - acc: 1.0000 - val_loss: 0.0522 - val_acc: 0.9905\n",
      "Epoch 27/100\n",
      "4222/4222 [==============================] - 2s 490us/step - loss: 2.0592e-04 - acc: 1.0000 - val_loss: 0.0552 - val_acc: 0.9924\n",
      "Epoch 28/100\n",
      "4222/4222 [==============================] - 2s 489us/step - loss: 1.5334e-04 - acc: 1.0000 - val_loss: 0.0545 - val_acc: 0.9924\n",
      "Epoch 29/100\n",
      "4222/4222 [==============================] - 2s 504us/step - loss: 1.1593e-04 - acc: 1.0000 - val_loss: 0.0552 - val_acc: 0.9924\n",
      "Epoch 30/100\n",
      "4222/4222 [==============================] - 2s 496us/step - loss: 1.2190e-04 - acc: 1.0000 - val_loss: 0.0550 - val_acc: 0.9915\n",
      "Epoch 31/100\n",
      "4222/4222 [==============================] - 2s 493us/step - loss: 0.0237 - acc: 0.9941 - val_loss: 0.1973 - val_acc: 0.9583\n",
      "Epoch 32/100\n",
      "4222/4222 [==============================] - 2s 482us/step - loss: 0.0411 - acc: 0.9889 - val_loss: 0.0521 - val_acc: 0.9877\n",
      "Epoch 33/100\n",
      "4222/4222 [==============================] - 2s 483us/step - loss: 0.0064 - acc: 0.9979 - val_loss: 0.0415 - val_acc: 0.9924\n",
      "Epoch 34/100\n",
      "4222/4222 [==============================] - 2s 491us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0357 - val_acc: 0.9915\n",
      "Epoch 35/100\n",
      "4222/4222 [==============================] - 2s 483us/step - loss: 4.9085e-04 - acc: 1.0000 - val_loss: 0.0350 - val_acc: 0.9934\n",
      "Epoch 36/100\n",
      "4222/4222 [==============================] - 2s 486us/step - loss: 3.3113e-04 - acc: 1.0000 - val_loss: 0.0334 - val_acc: 0.9943\n",
      "Epoch 37/100\n",
      "4222/4222 [==============================] - 2s 489us/step - loss: 2.4631e-04 - acc: 1.0000 - val_loss: 0.0346 - val_acc: 0.9924\n",
      "Epoch 38/100\n",
      "4222/4222 [==============================] - 2s 484us/step - loss: 1.8896e-04 - acc: 1.0000 - val_loss: 0.0350 - val_acc: 0.9924\n",
      "Epoch 39/100\n",
      "4222/4222 [==============================] - 2s 484us/step - loss: 1.5054e-04 - acc: 1.0000 - val_loss: 0.0370 - val_acc: 0.9924\n",
      "Epoch 40/100\n",
      "4222/4222 [==============================] - 2s 480us/step - loss: 1.1557e-04 - acc: 1.0000 - val_loss: 0.0348 - val_acc: 0.9943\n",
      "Epoch 41/100\n",
      "4222/4222 [==============================] - 2s 493us/step - loss: 9.9234e-05 - acc: 1.0000 - val_loss: 0.0355 - val_acc: 0.9924\n",
      "Epoch 42/100\n",
      "4222/4222 [==============================] - 2s 564us/step - loss: 7.7291e-05 - acc: 1.0000 - val_loss: 0.0348 - val_acc: 0.9943\n",
      "Epoch 43/100\n",
      "4222/4222 [==============================] - 3s 651us/step - loss: 6.0619e-05 - acc: 1.0000 - val_loss: 0.0363 - val_acc: 0.9934\n",
      "Epoch 44/100\n",
      "4222/4222 [==============================] - 3s 634us/step - loss: 4.9334e-05 - acc: 1.0000 - val_loss: 0.0360 - val_acc: 0.9924\n",
      "Epoch 45/100\n",
      "4222/4222 [==============================] - 3s 615us/step - loss: 4.4204e-05 - acc: 1.0000 - val_loss: 0.0371 - val_acc: 0.9934\n",
      "Epoch 46/100\n",
      "4222/4222 [==============================] - 3s 616us/step - loss: 3.7306e-05 - acc: 1.0000 - val_loss: 0.0365 - val_acc: 0.9934\n",
      "Epoch 47/100\n",
      "4222/4222 [==============================] - 2s 503us/step - loss: 2.8110e-05 - acc: 1.0000 - val_loss: 0.0369 - val_acc: 0.9943\n",
      "Epoch 48/100\n",
      "4222/4222 [==============================] - 2s 511us/step - loss: 2.2816e-05 - acc: 1.0000 - val_loss: 0.0361 - val_acc: 0.9943\n",
      "Epoch 49/100\n",
      "4222/4222 [==============================] - 2s 486us/step - loss: 0.0164 - acc: 0.9974 - val_loss: 0.2167 - val_acc: 0.9716\n",
      "Epoch 50/100\n",
      "4222/4222 [==============================] - 2s 507us/step - loss: 0.0689 - acc: 0.9867 - val_loss: 0.0735 - val_acc: 0.9915\n",
      "Epoch 51/100\n",
      "4222/4222 [==============================] - 2s 571us/step - loss: 0.0041 - acc: 0.9991 - val_loss: 0.0702 - val_acc: 0.9953\n",
      "Epoch 52/100\n",
      "4222/4222 [==============================] - 2s 498us/step - loss: 0.0014 - acc: 0.9995 - val_loss: 0.0663 - val_acc: 0.9934\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4222/4222 [==============================] - 2s 481us/step - loss: 3.9341e-04 - acc: 1.0000 - val_loss: 0.0665 - val_acc: 0.9943\n",
      "Epoch 54/100\n",
      "4222/4222 [==============================] - 2s 494us/step - loss: 2.7055e-04 - acc: 1.0000 - val_loss: 0.0668 - val_acc: 0.9943\n",
      "Epoch 55/100\n",
      "4222/4222 [==============================] - 2s 566us/step - loss: 2.1239e-04 - acc: 1.0000 - val_loss: 0.0666 - val_acc: 0.9943\n",
      "Epoch 56/100\n",
      "4222/4222 [==============================] - 2s 483us/step - loss: 1.4648e-04 - acc: 1.0000 - val_loss: 0.0673 - val_acc: 0.9934\n",
      "Epoch 57/100\n",
      "4222/4222 [==============================] - 2s 550us/step - loss: 1.1403e-04 - acc: 1.0000 - val_loss: 0.0665 - val_acc: 0.9943\n",
      "Epoch 58/100\n",
      "4222/4222 [==============================] - 2s 525us/step - loss: 1.3395e-04 - acc: 1.0000 - val_loss: 0.0666 - val_acc: 0.9943\n",
      "Epoch 59/100\n",
      "4222/4222 [==============================] - 2s 482us/step - loss: 1.4891e-04 - acc: 1.0000 - val_loss: 0.0652 - val_acc: 0.9943\n",
      "Epoch 60/100\n",
      "4222/4222 [==============================] - 2s 491us/step - loss: 6.2669e-05 - acc: 1.0000 - val_loss: 0.0666 - val_acc: 0.9934\n",
      "Epoch 61/100\n",
      "4222/4222 [==============================] - 2s 485us/step - loss: 4.4057e-05 - acc: 1.0000 - val_loss: 0.0660 - val_acc: 0.9934\n",
      "Epoch 62/100\n",
      "4222/4222 [==============================] - 2s 493us/step - loss: 3.5540e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9943\n",
      "Epoch 63/100\n",
      "4222/4222 [==============================] - 2s 501us/step - loss: 3.0625e-05 - acc: 1.0000 - val_loss: 0.0645 - val_acc: 0.9943\n",
      "Epoch 64/100\n",
      "4222/4222 [==============================] - 2s 484us/step - loss: 2.5065e-05 - acc: 1.0000 - val_loss: 0.0655 - val_acc: 0.9943\n",
      "Epoch 65/100\n",
      "4222/4222 [==============================] - 2s 528us/step - loss: 2.0413e-05 - acc: 1.0000 - val_loss: 0.0644 - val_acc: 0.9943\n",
      "Epoch 66/100\n",
      "4222/4222 [==============================] - 2s 581us/step - loss: 1.7157e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9943\n",
      "Epoch 67/100\n",
      "4222/4222 [==============================] - 2s 548us/step - loss: 1.4087e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9943\n",
      "Epoch 68/100\n",
      "4222/4222 [==============================] - 2s 543us/step - loss: 1.1384e-05 - acc: 1.0000 - val_loss: 0.0648 - val_acc: 0.9943\n",
      "Epoch 69/100\n",
      "4222/4222 [==============================] - 2s 583us/step - loss: 9.8067e-06 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9943\n",
      "Epoch 70/100\n",
      "4222/4222 [==============================] - 2s 492us/step - loss: 0.0550 - acc: 0.9891 - val_loss: 0.0591 - val_acc: 0.9877\n",
      "Epoch 71/100\n",
      "4222/4222 [==============================] - 2s 489us/step - loss: 0.0070 - acc: 0.9974 - val_loss: 0.0588 - val_acc: 0.9896\n",
      "Epoch 72/100\n",
      "4222/4222 [==============================] - 2s 487us/step - loss: 0.0011 - acc: 0.9995 - val_loss: 0.0553 - val_acc: 0.9934\n",
      "Epoch 73/100\n",
      "4222/4222 [==============================] - 2s 485us/step - loss: 1.6777e-04 - acc: 1.0000 - val_loss: 0.0554 - val_acc: 0.9934\n",
      "Epoch 74/100\n",
      "4222/4222 [==============================] - 2s 486us/step - loss: 1.2925e-04 - acc: 1.0000 - val_loss: 0.0555 - val_acc: 0.9934\n",
      "Epoch 75/100\n",
      "4222/4222 [==============================] - 2s 494us/step - loss: 1.0226e-04 - acc: 1.0000 - val_loss: 0.0554 - val_acc: 0.9934\n",
      "Epoch 76/100\n",
      "4222/4222 [==============================] - 2s 490us/step - loss: 8.3215e-05 - acc: 1.0000 - val_loss: 0.0555 - val_acc: 0.9934\n",
      "Epoch 77/100\n",
      "4222/4222 [==============================] - 2s 513us/step - loss: 6.8969e-05 - acc: 1.0000 - val_loss: 0.0556 - val_acc: 0.9924\n",
      "Epoch 78/100\n",
      "4222/4222 [==============================] - 3s 669us/step - loss: 5.7185e-05 - acc: 1.0000 - val_loss: 0.0555 - val_acc: 0.9924\n",
      "Epoch 79/100\n",
      "4222/4222 [==============================] - 3s 609us/step - loss: 4.7160e-05 - acc: 1.0000 - val_loss: 0.0549 - val_acc: 0.9924\n",
      "Epoch 80/100\n",
      "4222/4222 [==============================] - 3s 593us/step - loss: 3.9634e-05 - acc: 1.0000 - val_loss: 0.0544 - val_acc: 0.9924\n",
      "Epoch 81/100\n",
      "4222/4222 [==============================] - 2s 534us/step - loss: 3.2275e-05 - acc: 1.0000 - val_loss: 0.0564 - val_acc: 0.9924\n",
      "Epoch 82/100\n",
      "4222/4222 [==============================] - 2s 557us/step - loss: 2.6709e-05 - acc: 1.0000 - val_loss: 0.0552 - val_acc: 0.9934\n",
      "Epoch 83/100\n",
      "4222/4222 [==============================] - 2s 573us/step - loss: 2.2142e-05 - acc: 1.0000 - val_loss: 0.0548 - val_acc: 0.9934\n",
      "Epoch 84/100\n",
      "4222/4222 [==============================] - 2s 583us/step - loss: 1.7468e-05 - acc: 1.0000 - val_loss: 0.0545 - val_acc: 0.9924\n",
      "Epoch 85/100\n",
      "4222/4222 [==============================] - 2s 583us/step - loss: 1.4734e-05 - acc: 1.0000 - val_loss: 0.0555 - val_acc: 0.9934\n",
      "Epoch 86/100\n",
      "4222/4222 [==============================] - 2s 581us/step - loss: 1.1872e-05 - acc: 1.0000 - val_loss: 0.0548 - val_acc: 0.9934\n",
      "Epoch 87/100\n",
      "4222/4222 [==============================] - 3s 599us/step - loss: 9.7076e-06 - acc: 1.0000 - val_loss: 0.0557 - val_acc: 0.9934\n",
      "Epoch 88/100\n",
      "4222/4222 [==============================] - 2s 585us/step - loss: 7.9905e-06 - acc: 1.0000 - val_loss: 0.0535 - val_acc: 0.9943\n",
      "Epoch 89/100\n",
      "4222/4222 [==============================] - 2s 569us/step - loss: 6.4255e-06 - acc: 1.0000 - val_loss: 0.0552 - val_acc: 0.9943\n",
      "Epoch 90/100\n",
      "4222/4222 [==============================] - 2s 592us/step - loss: 5.3151e-06 - acc: 1.0000 - val_loss: 0.0557 - val_acc: 0.9943\n",
      "Epoch 91/100\n",
      "4222/4222 [==============================] - 2s 581us/step - loss: 4.3367e-06 - acc: 1.0000 - val_loss: 0.0553 - val_acc: 0.9934\n",
      "Epoch 92/100\n",
      "4222/4222 [==============================] - 2s 590us/step - loss: 3.5452e-06 - acc: 1.0000 - val_loss: 0.0559 - val_acc: 0.9943\n",
      "Epoch 93/100\n",
      "4222/4222 [==============================] - 2s 588us/step - loss: 3.3036e-06 - acc: 1.0000 - val_loss: 0.0554 - val_acc: 0.9943\n",
      "Epoch 94/100\n",
      "4222/4222 [==============================] - 3s 598us/step - loss: 2.6043e-06 - acc: 1.0000 - val_loss: 0.0555 - val_acc: 0.9943\n",
      "Epoch 95/100\n",
      "4222/4222 [==============================] - 2s 527us/step - loss: 2.1467e-06 - acc: 1.0000 - val_loss: 0.0567 - val_acc: 0.9943\n",
      "Epoch 96/100\n",
      "4222/4222 [==============================] - 2s 520us/step - loss: 1.8954e-06 - acc: 1.0000 - val_loss: 0.0574 - val_acc: 0.9924\n",
      "Epoch 97/100\n",
      "4222/4222 [==============================] - 2s 551us/step - loss: 1.5077e-06 - acc: 1.0000 - val_loss: 0.0543 - val_acc: 0.9934\n",
      "Epoch 98/100\n",
      "4222/4222 [==============================] - 2s 522us/step - loss: 1.2635e-06 - acc: 1.0000 - val_loss: 0.0558 - val_acc: 0.9943\n",
      "Epoch 99/100\n",
      "4222/4222 [==============================] - 2s 539us/step - loss: 1.0300e-06 - acc: 1.0000 - val_loss: 0.0562 - val_acc: 0.9943\n",
      "Epoch 100/100\n",
      "4222/4222 [==============================] - 2s 558us/step - loss: 8.8171e-07 - acc: 1.0000 - val_loss: 0.0561 - val_acc: 0.9943\n",
      "[[1117    3]\n",
      " [   3  197]]\n",
      "0.9954545454545455\n"
     ]
    }
   ],
   "source": [
    "classifier = Sequential()\n",
    "\n",
    "classifier.add(Dense(units = 80, kernel_initializer = 'he_uniform', activation = 'relu', input_dim = 166))\n",
    "\n",
    "classifier.add(Dense(units = 20, kernel_initializer = 'he_uniform', activation = 'relu'))\n",
    "\n",
    "classifier.add(Dense(units = 1, kernel_initializer = 'glorot_uniform', activation = 'sigmoid'))\n",
    "\n",
    "classifier.summary()\n",
    "\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "model = classifier.fit(X_train, y_train, validation_split = 0.2, batch_size = 10, nb_epoch = 100)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "score = accuracy_score(y_pred, y_test)\n",
    "print(cm)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Adding dropouts or extra layers decreased the accuracy.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_383 (Dense)            (None, 50)                8350      \n",
      "_________________________________________________________________\n",
      "dense_384 (Dense)            (None, 6)                 306       \n",
      "_________________________________________________________________\n",
      "dense_385 (Dense)            (None, 6)                 42        \n",
      "_________________________________________________________________\n",
      "dense_386 (Dense)            (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 8,705\n",
      "Trainable params: 8,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "Train on 4222 samples, validate on 1056 samples\n",
      "Epoch 1/100\n",
      "4222/4222 [==============================] - 12s 3ms/step - loss: 0.3327 - acc: 0.8671 - val_loss: 0.1724 - val_acc: 0.9394\n",
      "Epoch 2/100\n",
      "4222/4222 [==============================] - 2s 514us/step - loss: 0.1321 - acc: 0.9488 - val_loss: 0.1208 - val_acc: 0.9574\n",
      "Epoch 3/100\n",
      "4222/4222 [==============================] - 2s 489us/step - loss: 0.0944 - acc: 0.9666 - val_loss: 0.1015 - val_acc: 0.9631\n",
      "Epoch 4/100\n",
      "4222/4222 [==============================] - 2s 491us/step - loss: 0.0709 - acc: 0.9756 - val_loss: 0.0788 - val_acc: 0.9659\n",
      "Epoch 5/100\n",
      "4222/4222 [==============================] - 2s 524us/step - loss: 0.0612 - acc: 0.9758 - val_loss: 0.0693 - val_acc: 0.9744\n",
      "Epoch 6/100\n",
      "4222/4222 [==============================] - 2s 501us/step - loss: 0.0442 - acc: 0.9837 - val_loss: 0.0579 - val_acc: 0.9782\n",
      "Epoch 7/100\n",
      "4222/4222 [==============================] - 2s 499us/step - loss: 0.0379 - acc: 0.9846 - val_loss: 0.0592 - val_acc: 0.9754\n",
      "Epoch 8/100\n",
      "4222/4222 [==============================] - 2s 524us/step - loss: 0.0324 - acc: 0.9872 - val_loss: 0.0519 - val_acc: 0.9820\n",
      "Epoch 9/100\n",
      "4222/4222 [==============================] - 2s 501us/step - loss: 0.0226 - acc: 0.9908 - val_loss: 0.0559 - val_acc: 0.9839\n",
      "Epoch 10/100\n",
      "4222/4222 [==============================] - 2s 492us/step - loss: 0.0207 - acc: 0.9929 - val_loss: 0.0565 - val_acc: 0.9811\n",
      "Epoch 11/100\n",
      "4222/4222 [==============================] - 2s 495us/step - loss: 0.0179 - acc: 0.9946 - val_loss: 0.0428 - val_acc: 0.9830\n",
      "Epoch 12/100\n",
      "4222/4222 [==============================] - 2s 537us/step - loss: 0.0101 - acc: 0.9972 - val_loss: 0.0421 - val_acc: 0.9848\n",
      "Epoch 13/100\n",
      "4222/4222 [==============================] - 2s 494us/step - loss: 0.0098 - acc: 0.9967 - val_loss: 0.0424 - val_acc: 0.9877\n",
      "Epoch 14/100\n",
      "4222/4222 [==============================] - 2s 495us/step - loss: 0.0068 - acc: 0.9986 - val_loss: 0.0415 - val_acc: 0.9877\n",
      "Epoch 15/100\n",
      "4222/4222 [==============================] - 2s 493us/step - loss: 0.0093 - acc: 0.9976 - val_loss: 0.0465 - val_acc: 0.9848\n",
      "Epoch 16/100\n",
      "4222/4222 [==============================] - 2s 512us/step - loss: 0.0483 - acc: 0.9870 - val_loss: 0.0640 - val_acc: 0.9792\n",
      "Epoch 17/100\n",
      "4222/4222 [==============================] - 2s 523us/step - loss: 0.0076 - acc: 0.9983 - val_loss: 0.0428 - val_acc: 0.9877\n",
      "Epoch 18/100\n",
      "4222/4222 [==============================] - 2s 502us/step - loss: 0.0036 - acc: 0.9998 - val_loss: 0.0416 - val_acc: 0.9886\n",
      "Epoch 19/100\n",
      "4222/4222 [==============================] - 2s 504us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0427 - val_acc: 0.9886\n",
      "Epoch 20/100\n",
      "4222/4222 [==============================] - 2s 528us/step - loss: 0.0032 - acc: 0.9993 - val_loss: 0.0479 - val_acc: 0.9877\n",
      "Epoch 21/100\n",
      "4222/4222 [==============================] - 2s 524us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0440 - val_acc: 0.9896\n",
      "Epoch 22/100\n",
      "4222/4222 [==============================] - 2s 499us/step - loss: 0.0017 - acc: 0.9998 - val_loss: 0.0552 - val_acc: 0.9848\n",
      "Epoch 23/100\n",
      "4222/4222 [==============================] - 2s 496us/step - loss: 0.0285 - acc: 0.9905 - val_loss: 0.0623 - val_acc: 0.9867\n",
      "Epoch 24/100\n",
      "4222/4222 [==============================] - 2s 494us/step - loss: 0.0103 - acc: 0.9967 - val_loss: 0.0594 - val_acc: 0.9858\n",
      "Epoch 25/100\n",
      "4222/4222 [==============================] - 2s 513us/step - loss: 0.0027 - acc: 0.9995 - val_loss: 0.0519 - val_acc: 0.9934\n",
      "Epoch 26/100\n",
      "4222/4222 [==============================] - 2s 498us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0489 - val_acc: 0.9934\n",
      "Epoch 27/100\n",
      "4222/4222 [==============================] - 2s 492us/step - loss: 8.1139e-04 - acc: 1.0000 - val_loss: 0.0485 - val_acc: 0.9934\n",
      "Epoch 28/100\n",
      "4222/4222 [==============================] - 2s 497us/step - loss: 7.2465e-04 - acc: 1.0000 - val_loss: 0.0478 - val_acc: 0.9934\n",
      "Epoch 29/100\n",
      "4222/4222 [==============================] - 2s 493us/step - loss: 6.0970e-04 - acc: 1.0000 - val_loss: 0.0478 - val_acc: 0.9924\n",
      "Epoch 30/100\n",
      "4222/4222 [==============================] - 2s 493us/step - loss: 7.3043e-04 - acc: 1.0000 - val_loss: 0.0466 - val_acc: 0.9924\n",
      "Epoch 31/100\n",
      "4222/4222 [==============================] - 2s 488us/step - loss: 4.6976e-04 - acc: 1.0000 - val_loss: 0.0468 - val_acc: 0.9924\n",
      "Epoch 32/100\n",
      "4222/4222 [==============================] - 2s 489us/step - loss: 0.0300 - acc: 0.9915 - val_loss: 0.0766 - val_acc: 0.9867\n",
      "Epoch 33/100\n",
      "4222/4222 [==============================] - 2s 484us/step - loss: 0.0092 - acc: 0.9983 - val_loss: 0.0393 - val_acc: 0.9934\n",
      "Epoch 34/100\n",
      "4222/4222 [==============================] - 2s 489us/step - loss: 0.0110 - acc: 0.9969 - val_loss: 0.0561 - val_acc: 0.9867\n",
      "Epoch 35/100\n",
      "4222/4222 [==============================] - 2s 485us/step - loss: 0.0016 - acc: 0.9995 - val_loss: 0.0409 - val_acc: 0.9924\n",
      "Epoch 36/100\n",
      "4222/4222 [==============================] - 2s 500us/step - loss: 5.9827e-04 - acc: 1.0000 - val_loss: 0.0403 - val_acc: 0.9915\n",
      "Epoch 37/100\n",
      "4222/4222 [==============================] - 2s 500us/step - loss: 5.2148e-04 - acc: 1.0000 - val_loss: 0.0393 - val_acc: 0.9915\n",
      "Epoch 38/100\n",
      "4222/4222 [==============================] - 2s 493us/step - loss: 4.6056e-04 - acc: 1.0000 - val_loss: 0.0385 - val_acc: 0.9915\n",
      "Epoch 39/100\n",
      "4222/4222 [==============================] - 2s 486us/step - loss: 4.2110e-04 - acc: 1.0000 - val_loss: 0.0379 - val_acc: 0.9915\n",
      "Epoch 40/100\n",
      "4222/4222 [==============================] - 2s 492us/step - loss: 4.1245e-04 - acc: 1.0000 - val_loss: 0.0381 - val_acc: 0.9915\n",
      "Epoch 41/100\n",
      "4222/4222 [==============================] - 2s 489us/step - loss: 3.5708e-04 - acc: 1.0000 - val_loss: 0.0369 - val_acc: 0.9915\n",
      "Epoch 42/100\n",
      "4222/4222 [==============================] - 2s 512us/step - loss: 3.6572e-04 - acc: 1.0000 - val_loss: 0.0343 - val_acc: 0.9934\n",
      "Epoch 43/100\n",
      "4222/4222 [==============================] - 2s 509us/step - loss: 3.2554e-04 - acc: 1.0000 - val_loss: 0.0356 - val_acc: 0.9934\n",
      "Epoch 44/100\n",
      "4222/4222 [==============================] - 2s 491us/step - loss: 2.8215e-04 - acc: 1.0000 - val_loss: 0.0348 - val_acc: 0.9924\n",
      "Epoch 45/100\n",
      "4222/4222 [==============================] - 2s 511us/step - loss: 0.0378 - acc: 0.9936 - val_loss: 0.1537 - val_acc: 0.9659\n",
      "Epoch 46/100\n",
      "4222/4222 [==============================] - 2s 493us/step - loss: 0.0373 - acc: 0.9919 - val_loss: 0.0475 - val_acc: 0.9886\n",
      "Epoch 47/100\n",
      "4222/4222 [==============================] - 2s 489us/step - loss: 0.0036 - acc: 0.9991 - val_loss: 0.0396 - val_acc: 0.9934\n",
      "Epoch 48/100\n",
      "4222/4222 [==============================] - 2s 504us/step - loss: 0.0014 - acc: 0.9995 - val_loss: 0.0396 - val_acc: 0.9915\n",
      "Epoch 49/100\n",
      "4222/4222 [==============================] - 2s 518us/step - loss: 6.1680e-04 - acc: 1.0000 - val_loss: 0.0398 - val_acc: 0.9924\n",
      "Epoch 50/100\n",
      "4222/4222 [==============================] - 2s 533us/step - loss: 4.9032e-04 - acc: 1.0000 - val_loss: 0.0384 - val_acc: 0.9924\n",
      "Epoch 51/100\n",
      "4222/4222 [==============================] - 2s 514us/step - loss: 4.2397e-04 - acc: 1.0000 - val_loss: 0.0393 - val_acc: 0.9915\n",
      "Epoch 52/100\n",
      "4222/4222 [==============================] - 2s 525us/step - loss: 3.7415e-04 - acc: 1.0000 - val_loss: 0.0394 - val_acc: 0.9915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/100\n",
      "4222/4222 [==============================] - 2s 505us/step - loss: 3.3448e-04 - acc: 1.0000 - val_loss: 0.0401 - val_acc: 0.9915\n",
      "Epoch 54/100\n",
      "4222/4222 [==============================] - 2s 540us/step - loss: 3.0276e-04 - acc: 1.0000 - val_loss: 0.0390 - val_acc: 0.9915\n",
      "Epoch 55/100\n",
      "4222/4222 [==============================] - 2s 505us/step - loss: 2.8369e-04 - acc: 1.0000 - val_loss: 0.0388 - val_acc: 0.9915\n",
      "Epoch 56/100\n",
      "4222/4222 [==============================] - 2s 516us/step - loss: 2.7238e-04 - acc: 1.0000 - val_loss: 0.0404 - val_acc: 0.9905\n",
      "Epoch 57/100\n",
      "4222/4222 [==============================] - 2s 515us/step - loss: 2.4241e-04 - acc: 1.0000 - val_loss: 0.0379 - val_acc: 0.9915\n",
      "Epoch 58/100\n",
      "4222/4222 [==============================] - 2s 495us/step - loss: 2.2326e-04 - acc: 1.0000 - val_loss: 0.0378 - val_acc: 0.9915\n",
      "Epoch 59/100\n",
      "4222/4222 [==============================] - 2s 522us/step - loss: 2.0576e-04 - acc: 1.0000 - val_loss: 0.0391 - val_acc: 0.9915\n",
      "Epoch 60/100\n",
      "4222/4222 [==============================] - 2s 489us/step - loss: 0.0236 - acc: 0.9931 - val_loss: 0.0823 - val_acc: 0.9820\n",
      "Epoch 61/100\n",
      "4222/4222 [==============================] - 2s 489us/step - loss: 0.0071 - acc: 0.9979 - val_loss: 0.0484 - val_acc: 0.9924\n",
      "Epoch 62/100\n",
      "4222/4222 [==============================] - 2s 522us/step - loss: 9.2798e-04 - acc: 1.0000 - val_loss: 0.0470 - val_acc: 0.9934\n",
      "Epoch 63/100\n",
      "4222/4222 [==============================] - 2s 519us/step - loss: 5.2257e-04 - acc: 1.0000 - val_loss: 0.0456 - val_acc: 0.9924\n",
      "Epoch 64/100\n",
      "4222/4222 [==============================] - 2s 535us/step - loss: 3.5360e-04 - acc: 1.0000 - val_loss: 0.0442 - val_acc: 0.9924\n",
      "Epoch 65/100\n",
      "4222/4222 [==============================] - 2s 515us/step - loss: 3.1484e-04 - acc: 1.0000 - val_loss: 0.0418 - val_acc: 0.9924\n",
      "Epoch 66/100\n",
      "4222/4222 [==============================] - 2s 514us/step - loss: 2.6556e-04 - acc: 1.0000 - val_loss: 0.0400 - val_acc: 0.9934\n",
      "Epoch 67/100\n",
      "4222/4222 [==============================] - 2s 517us/step - loss: 2.3457e-04 - acc: 1.0000 - val_loss: 0.0375 - val_acc: 0.9934\n",
      "Epoch 68/100\n",
      "4222/4222 [==============================] - 2s 519us/step - loss: 2.1259e-04 - acc: 1.0000 - val_loss: 0.0375 - val_acc: 0.9934\n",
      "Epoch 69/100\n",
      "4222/4222 [==============================] - 2s 514us/step - loss: 1.9776e-04 - acc: 1.0000 - val_loss: 0.0367 - val_acc: 0.9934\n",
      "Epoch 70/100\n",
      "4222/4222 [==============================] - 2s 516us/step - loss: 1.8365e-04 - acc: 1.0000 - val_loss: 0.0357 - val_acc: 0.9934\n",
      "Epoch 71/100\n",
      "4222/4222 [==============================] - 2s 518us/step - loss: 1.6946e-04 - acc: 1.0000 - val_loss: 0.0362 - val_acc: 0.9934\n",
      "Epoch 72/100\n",
      "4222/4222 [==============================] - 2s 507us/step - loss: 1.6134e-04 - acc: 1.0000 - val_loss: 0.0357 - val_acc: 0.9934\n",
      "Epoch 73/100\n",
      "4222/4222 [==============================] - 2s 522us/step - loss: 1.4969e-04 - acc: 1.0000 - val_loss: 0.0357 - val_acc: 0.9943\n",
      "Epoch 74/100\n",
      "4222/4222 [==============================] - 2s 512us/step - loss: 1.4325e-04 - acc: 1.0000 - val_loss: 0.0343 - val_acc: 0.9934\n",
      "Epoch 75/100\n",
      "4222/4222 [==============================] - 2s 522us/step - loss: 1.3305e-04 - acc: 1.0000 - val_loss: 0.0343 - val_acc: 0.9934\n",
      "Epoch 76/100\n",
      "4222/4222 [==============================] - 2s 513us/step - loss: 0.0597 - acc: 0.9893 - val_loss: 0.0867 - val_acc: 0.9830\n",
      "Epoch 77/100\n",
      "4222/4222 [==============================] - 2s 483us/step - loss: 0.0170 - acc: 0.9950 - val_loss: 0.0462 - val_acc: 0.9886\n",
      "Epoch 78/100\n",
      "4222/4222 [==============================] - 2s 558us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0480 - val_acc: 0.9896\n",
      "Epoch 79/100\n",
      "4222/4222 [==============================] - 2s 585us/step - loss: 3.9069e-04 - acc: 1.0000 - val_loss: 0.0487 - val_acc: 0.9896\n",
      "Epoch 80/100\n",
      "4222/4222 [==============================] - 3s 613us/step - loss: 3.1590e-04 - acc: 1.0000 - val_loss: 0.0479 - val_acc: 0.9896\n",
      "Epoch 81/100\n",
      "4222/4222 [==============================] - 2s 517us/step - loss: 2.7698e-04 - acc: 1.0000 - val_loss: 0.0473 - val_acc: 0.9896\n",
      "Epoch 82/100\n",
      "4222/4222 [==============================] - 2s 478us/step - loss: 2.4676e-04 - acc: 1.0000 - val_loss: 0.0476 - val_acc: 0.9896\n",
      "Epoch 83/100\n",
      "4222/4222 [==============================] - 2s 478us/step - loss: 2.2657e-04 - acc: 1.0000 - val_loss: 0.0475 - val_acc: 0.9896\n",
      "Epoch 84/100\n",
      "4222/4222 [==============================] - 2s 476us/step - loss: 2.0339e-04 - acc: 1.0000 - val_loss: 0.0465 - val_acc: 0.9905\n",
      "Epoch 85/100\n",
      "4222/4222 [==============================] - 2s 499us/step - loss: 1.8793e-04 - acc: 1.0000 - val_loss: 0.0460 - val_acc: 0.9905\n",
      "Epoch 86/100\n",
      "4222/4222 [==============================] - 2s 551us/step - loss: 1.7525e-04 - acc: 1.0000 - val_loss: 0.0466 - val_acc: 0.9905\n",
      "Epoch 87/100\n",
      "4222/4222 [==============================] - 2s 590us/step - loss: 1.6346e-04 - acc: 1.0000 - val_loss: 0.0457 - val_acc: 0.9905\n",
      "Epoch 88/100\n",
      "4222/4222 [==============================] - 2s 485us/step - loss: 1.5074e-04 - acc: 1.0000 - val_loss: 0.0461 - val_acc: 0.9915\n",
      "Epoch 89/100\n",
      "4222/4222 [==============================] - 2s 474us/step - loss: 1.4003e-04 - acc: 1.0000 - val_loss: 0.0455 - val_acc: 0.9915\n",
      "Epoch 90/100\n",
      "4222/4222 [==============================] - 2s 506us/step - loss: 1.3046e-04 - acc: 1.0000 - val_loss: 0.0461 - val_acc: 0.9915\n",
      "Epoch 91/100\n",
      "4222/4222 [==============================] - 2s 498us/step - loss: 1.2102e-04 - acc: 1.0000 - val_loss: 0.0477 - val_acc: 0.9886\n",
      "Epoch 92/100\n",
      "4222/4222 [==============================] - 2s 495us/step - loss: 1.1439e-04 - acc: 1.0000 - val_loss: 0.0457 - val_acc: 0.9905\n",
      "Epoch 93/100\n",
      "4222/4222 [==============================] - 2s 483us/step - loss: 1.0575e-04 - acc: 1.0000 - val_loss: 0.0448 - val_acc: 0.9905\n",
      "Epoch 94/100\n",
      "4222/4222 [==============================] - 2s 477us/step - loss: 1.0028e-04 - acc: 1.0000 - val_loss: 0.0452 - val_acc: 0.9905\n",
      "Epoch 95/100\n",
      "4222/4222 [==============================] - 2s 558us/step - loss: 9.2301e-05 - acc: 1.0000 - val_loss: 0.0449 - val_acc: 0.9915\n",
      "Epoch 96/100\n",
      "4222/4222 [==============================] - 2s 579us/step - loss: 8.6622e-05 - acc: 1.0000 - val_loss: 0.0445 - val_acc: 0.9915\n",
      "Epoch 97/100\n",
      "4222/4222 [==============================] - 2s 544us/step - loss: 8.0041e-05 - acc: 1.0000 - val_loss: 0.0454 - val_acc: 0.9915\n",
      "Epoch 98/100\n",
      "4222/4222 [==============================] - 2s 528us/step - loss: 7.5280e-05 - acc: 1.0000 - val_loss: 0.0460 - val_acc: 0.9915\n",
      "Epoch 99/100\n",
      "4222/4222 [==============================] - 2s 516us/step - loss: 0.0472 - acc: 0.9941 - val_loss: 0.3662 - val_acc: 0.9555\n",
      "Epoch 100/100\n",
      "4222/4222 [==============================] - 2s 516us/step - loss: 0.0354 - acc: 0.9912 - val_loss: 0.0443 - val_acc: 0.9934\n",
      "[[1112    8]\n",
      " [   8  192]]\n",
      "0.9878787878787879\n"
     ]
    }
   ],
   "source": [
    "classifier = Sequential()\n",
    "\n",
    "classifier.add(Dense(units = 50, kernel_initializer = 'he_uniform', activation = 'relu', input_dim = 166))\n",
    "\n",
    "classifier.add(Dense(units = 6, kernel_initializer = 'he_uniform', activation = 'relu'))\n",
    "\n",
    "classifier.add(Dense(units = 6, kernel_initializer = 'he_uniform', activation = 'relu'))\n",
    "\n",
    "classifier.add(Dense(units = 1, kernel_initializer = 'glorot_uniform', activation = 'sigmoid'))\n",
    "\n",
    "classifier.summary()\n",
    "\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "model = classifier.fit(X_train, y_train, validation_split = 0.2, batch_size = 10, nb_epoch = 100)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "score = accuracy_score(y_pred, y_test)\n",
    "print(cm)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_387 (Dense)            (None, 50)                8350      \n",
      "_________________________________________________________________\n",
      "dropout_246 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_388 (Dense)            (None, 6)                 306       \n",
      "_________________________________________________________________\n",
      "dense_389 (Dense)            (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 8,663\n",
      "Trainable params: 8,663\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "Train on 4222 samples, validate on 1056 samples\n",
      "Epoch 1/100\n",
      "4222/4222 [==============================] - 14s 3ms/step - loss: 0.3642 - acc: 0.8505 - val_loss: 0.1741 - val_acc: 0.9261\n",
      "Epoch 2/100\n",
      "4222/4222 [==============================] - 2s 567us/step - loss: 0.1810 - acc: 0.9273 - val_loss: 0.1311 - val_acc: 0.9498\n",
      "Epoch 3/100\n",
      "4222/4222 [==============================] - 2s 588us/step - loss: 0.1389 - acc: 0.9472 - val_loss: 0.1140 - val_acc: 0.9583\n",
      "Epoch 4/100\n",
      "4222/4222 [==============================] - 2s 551us/step - loss: 0.1109 - acc: 0.9562 - val_loss: 0.0928 - val_acc: 0.9669\n",
      "Epoch 5/100\n",
      "4222/4222 [==============================] - 3s 614us/step - loss: 0.0860 - acc: 0.9683 - val_loss: 0.0771 - val_acc: 0.9744\n",
      "Epoch 6/100\n",
      "4222/4222 [==============================] - 2s 562us/step - loss: 0.0867 - acc: 0.9645 - val_loss: 0.0858 - val_acc: 0.9602\n",
      "Epoch 7/100\n",
      "4222/4222 [==============================] - 2s 565us/step - loss: 0.0746 - acc: 0.9716 - val_loss: 0.0696 - val_acc: 0.9735\n",
      "Epoch 8/100\n",
      "4222/4222 [==============================] - 2s 567us/step - loss: 0.0723 - acc: 0.9709 - val_loss: 0.0595 - val_acc: 0.9782\n",
      "Epoch 9/100\n",
      "4222/4222 [==============================] - 3s 611us/step - loss: 0.0595 - acc: 0.9754 - val_loss: 0.0566 - val_acc: 0.9811\n",
      "Epoch 10/100\n",
      "4222/4222 [==============================] - 2s 559us/step - loss: 0.0524 - acc: 0.9784 - val_loss: 0.0496 - val_acc: 0.9848\n",
      "Epoch 11/100\n",
      "4222/4222 [==============================] - 3s 607us/step - loss: 0.0456 - acc: 0.9832 - val_loss: 0.0475 - val_acc: 0.9839\n",
      "Epoch 12/100\n",
      "4222/4222 [==============================] - 2s 579us/step - loss: 0.0400 - acc: 0.9858 - val_loss: 0.0430 - val_acc: 0.9839\n",
      "Epoch 13/100\n",
      "4222/4222 [==============================] - 2s 568us/step - loss: 0.0554 - acc: 0.9792 - val_loss: 0.0477 - val_acc: 0.9839\n",
      "Epoch 14/100\n",
      "4222/4222 [==============================] - 2s 517us/step - loss: 0.0405 - acc: 0.9846 - val_loss: 0.0502 - val_acc: 0.9848\n",
      "Epoch 15/100\n",
      "4222/4222 [==============================] - 2s 518us/step - loss: 0.0355 - acc: 0.9886 - val_loss: 0.0429 - val_acc: 0.9848\n",
      "Epoch 16/100\n",
      "4222/4222 [==============================] - 2s 505us/step - loss: 0.0310 - acc: 0.9879 - val_loss: 0.0447 - val_acc: 0.9848\n",
      "Epoch 17/100\n",
      "4222/4222 [==============================] - 2s 508us/step - loss: 0.0301 - acc: 0.9886 - val_loss: 0.0436 - val_acc: 0.9877\n",
      "Epoch 18/100\n",
      "4222/4222 [==============================] - 2s 555us/step - loss: 0.0292 - acc: 0.9884 - val_loss: 0.0409 - val_acc: 0.9867\n",
      "Epoch 19/100\n",
      "4222/4222 [==============================] - 2s 521us/step - loss: 0.0350 - acc: 0.9848 - val_loss: 0.0357 - val_acc: 0.9886\n",
      "Epoch 20/100\n",
      "4222/4222 [==============================] - 3s 598us/step - loss: 0.0250 - acc: 0.9903 - val_loss: 0.0582 - val_acc: 0.9848\n",
      "Epoch 21/100\n",
      "4222/4222 [==============================] - 3s 620us/step - loss: 0.0246 - acc: 0.9898 - val_loss: 0.0359 - val_acc: 0.9886\n",
      "Epoch 22/100\n",
      "4222/4222 [==============================] - 3s 610us/step - loss: 0.0238 - acc: 0.9912 - val_loss: 0.0427 - val_acc: 0.9877\n",
      "Epoch 23/100\n",
      "4222/4222 [==============================] - 2s 502us/step - loss: 0.0253 - acc: 0.9910 - val_loss: 0.0427 - val_acc: 0.9867\n",
      "Epoch 24/100\n",
      "4222/4222 [==============================] - 2s 490us/step - loss: 0.0227 - acc: 0.9924 - val_loss: 0.0521 - val_acc: 0.9867\n",
      "Epoch 25/100\n",
      "4222/4222 [==============================] - 2s 493us/step - loss: 0.0215 - acc: 0.9919 - val_loss: 0.0464 - val_acc: 0.9886\n",
      "Epoch 26/100\n",
      "4222/4222 [==============================] - 2s 491us/step - loss: 0.0211 - acc: 0.9919 - val_loss: 0.0421 - val_acc: 0.9905\n",
      "Epoch 27/100\n",
      "4222/4222 [==============================] - 2s 494us/step - loss: 0.0166 - acc: 0.9946 - val_loss: 0.0465 - val_acc: 0.9867\n",
      "Epoch 28/100\n",
      "4222/4222 [==============================] - 2s 497us/step - loss: 0.0193 - acc: 0.9943 - val_loss: 0.0412 - val_acc: 0.9896\n",
      "Epoch 29/100\n",
      "4222/4222 [==============================] - 2s 496us/step - loss: 0.0140 - acc: 0.9957 - val_loss: 0.0551 - val_acc: 0.9877\n",
      "Epoch 30/100\n",
      "4222/4222 [==============================] - 2s 522us/step - loss: 0.0235 - acc: 0.9908 - val_loss: 0.0450 - val_acc: 0.9896\n",
      "Epoch 31/100\n",
      "4222/4222 [==============================] - 2s 538us/step - loss: 0.0202 - acc: 0.9922 - val_loss: 0.0526 - val_acc: 0.9858\n",
      "Epoch 32/100\n",
      "4222/4222 [==============================] - 2s 529us/step - loss: 0.0134 - acc: 0.9953 - val_loss: 0.0484 - val_acc: 0.9924\n",
      "Epoch 33/100\n",
      "4222/4222 [==============================] - 2s 497us/step - loss: 0.0136 - acc: 0.9957 - val_loss: 0.0431 - val_acc: 0.9905\n",
      "Epoch 34/100\n",
      "4222/4222 [==============================] - 2s 497us/step - loss: 0.0163 - acc: 0.9941 - val_loss: 0.0448 - val_acc: 0.9877\n",
      "Epoch 35/100\n",
      "4222/4222 [==============================] - 2s 506us/step - loss: 0.0132 - acc: 0.9953 - val_loss: 0.0417 - val_acc: 0.9905\n",
      "Epoch 36/100\n",
      "4222/4222 [==============================] - 2s 514us/step - loss: 0.0138 - acc: 0.9946 - val_loss: 0.0419 - val_acc: 0.9915\n",
      "Epoch 37/100\n",
      "4222/4222 [==============================] - 2s 495us/step - loss: 0.0222 - acc: 0.9922 - val_loss: 0.0404 - val_acc: 0.9924\n",
      "Epoch 38/100\n",
      "4222/4222 [==============================] - 2s 495us/step - loss: 0.0155 - acc: 0.9948 - val_loss: 0.0382 - val_acc: 0.9915\n",
      "Epoch 39/100\n",
      "4222/4222 [==============================] - 2s 495us/step - loss: 0.0174 - acc: 0.9931 - val_loss: 0.0453 - val_acc: 0.9915\n",
      "Epoch 40/100\n",
      "4222/4222 [==============================] - 2s 494us/step - loss: 0.0243 - acc: 0.9922 - val_loss: 0.0441 - val_acc: 0.9867\n",
      "Epoch 41/100\n",
      "4222/4222 [==============================] - 2s 496us/step - loss: 0.0124 - acc: 0.9955 - val_loss: 0.0284 - val_acc: 0.9924\n",
      "Epoch 42/100\n",
      "4222/4222 [==============================] - 2s 498us/step - loss: 0.0142 - acc: 0.9943 - val_loss: 0.0552 - val_acc: 0.9886\n",
      "Epoch 43/100\n",
      "4222/4222 [==============================] - 2s 494us/step - loss: 0.0155 - acc: 0.9936 - val_loss: 0.0480 - val_acc: 0.9877\n",
      "Epoch 44/100\n",
      "4222/4222 [==============================] - 2s 497us/step - loss: 0.0150 - acc: 0.9950 - val_loss: 0.0379 - val_acc: 0.9924\n",
      "Epoch 45/100\n",
      "4222/4222 [==============================] - 2s 497us/step - loss: 0.0109 - acc: 0.9969 - val_loss: 0.0459 - val_acc: 0.9896\n",
      "Epoch 46/100\n",
      "4222/4222 [==============================] - 2s 502us/step - loss: 0.0100 - acc: 0.9955 - val_loss: 0.0447 - val_acc: 0.9943\n",
      "Epoch 47/100\n",
      "4222/4222 [==============================] - 2s 499us/step - loss: 0.0169 - acc: 0.9941 - val_loss: 0.0434 - val_acc: 0.9953\n",
      "Epoch 48/100\n",
      "4222/4222 [==============================] - 2s 496us/step - loss: 0.0108 - acc: 0.9962 - val_loss: 0.0473 - val_acc: 0.9934\n",
      "Epoch 49/100\n",
      "4222/4222 [==============================] - 2s 495us/step - loss: 0.0197 - acc: 0.9927 - val_loss: 0.0440 - val_acc: 0.9896\n",
      "Epoch 50/100\n",
      "4222/4222 [==============================] - 2s 495us/step - loss: 0.0119 - acc: 0.9960 - val_loss: 0.0398 - val_acc: 0.9915\n",
      "Epoch 51/100\n",
      "4222/4222 [==============================] - 2s 497us/step - loss: 0.0081 - acc: 0.9974 - val_loss: 0.0318 - val_acc: 0.9953\n",
      "Epoch 52/100\n",
      "4222/4222 [==============================] - 2s 495us/step - loss: 0.0084 - acc: 0.9981 - val_loss: 0.0332 - val_acc: 0.9924\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4222/4222 [==============================] - 2s 487us/step - loss: 0.0138 - acc: 0.9950 - val_loss: 0.0362 - val_acc: 0.9915\n",
      "Epoch 54/100\n",
      "4222/4222 [==============================] - 2s 485us/step - loss: 0.0086 - acc: 0.9967 - val_loss: 0.0371 - val_acc: 0.9924\n",
      "Epoch 55/100\n",
      "4222/4222 [==============================] - 2s 487us/step - loss: 0.0099 - acc: 0.9955 - val_loss: 0.0340 - val_acc: 0.9924\n",
      "Epoch 56/100\n",
      "4222/4222 [==============================] - 2s 485us/step - loss: 0.0082 - acc: 0.9974 - val_loss: 0.0346 - val_acc: 0.9924\n",
      "Epoch 57/100\n",
      "4222/4222 [==============================] - 2s 484us/step - loss: 0.0133 - acc: 0.9967 - val_loss: 0.0414 - val_acc: 0.9896\n",
      "Epoch 58/100\n",
      "4222/4222 [==============================] - 2s 485us/step - loss: 0.0122 - acc: 0.9960 - val_loss: 0.0391 - val_acc: 0.9924\n",
      "Epoch 59/100\n",
      "4222/4222 [==============================] - 2s 487us/step - loss: 0.0080 - acc: 0.9972 - val_loss: 0.0534 - val_acc: 0.9896\n",
      "Epoch 60/100\n",
      "4222/4222 [==============================] - 2s 488us/step - loss: 0.0118 - acc: 0.9953 - val_loss: 0.0394 - val_acc: 0.9886\n",
      "Epoch 61/100\n",
      "4222/4222 [==============================] - 2s 557us/step - loss: 0.0148 - acc: 0.9929 - val_loss: 0.0412 - val_acc: 0.9915\n",
      "Epoch 62/100\n",
      "4222/4222 [==============================] - 2s 531us/step - loss: 0.0150 - acc: 0.9941 - val_loss: 0.0317 - val_acc: 0.9962\n",
      "Epoch 63/100\n",
      "4222/4222 [==============================] - 2s 485us/step - loss: 0.0104 - acc: 0.9969 - val_loss: 0.0326 - val_acc: 0.9953\n",
      "Epoch 64/100\n",
      "4222/4222 [==============================] - 2s 487us/step - loss: 0.0098 - acc: 0.9967 - val_loss: 0.0388 - val_acc: 0.9943\n",
      "Epoch 65/100\n",
      "4222/4222 [==============================] - 2s 488us/step - loss: 0.0116 - acc: 0.9967 - val_loss: 0.0332 - val_acc: 0.9943\n",
      "Epoch 66/100\n",
      "4222/4222 [==============================] - 2s 553us/step - loss: 0.0077 - acc: 0.9976 - val_loss: 0.0383 - val_acc: 0.9915\n",
      "Epoch 67/100\n",
      "4222/4222 [==============================] - 2s 486us/step - loss: 0.0106 - acc: 0.9960 - val_loss: 0.0343 - val_acc: 0.9915\n",
      "Epoch 68/100\n",
      "4222/4222 [==============================] - 2s 484us/step - loss: 0.0170 - acc: 0.9953 - val_loss: 0.0274 - val_acc: 0.9953\n",
      "Epoch 69/100\n",
      "4222/4222 [==============================] - 2s 484us/step - loss: 0.0047 - acc: 0.9983 - val_loss: 0.0302 - val_acc: 0.9953\n",
      "Epoch 70/100\n",
      "4222/4222 [==============================] - 2s 487us/step - loss: 0.0054 - acc: 0.9986 - val_loss: 0.0334 - val_acc: 0.9943\n",
      "Epoch 71/100\n",
      "4222/4222 [==============================] - 2s 490us/step - loss: 0.0117 - acc: 0.9953 - val_loss: 0.0371 - val_acc: 0.9934\n",
      "Epoch 72/100\n",
      "4222/4222 [==============================] - 2s 487us/step - loss: 0.0106 - acc: 0.9967 - val_loss: 0.0410 - val_acc: 0.9953\n",
      "Epoch 73/100\n",
      "4222/4222 [==============================] - 2s 489us/step - loss: 0.0135 - acc: 0.9957 - val_loss: 0.0440 - val_acc: 0.9905\n",
      "Epoch 74/100\n",
      "4222/4222 [==============================] - 2s 488us/step - loss: 0.0094 - acc: 0.9969 - val_loss: 0.0457 - val_acc: 0.9915\n",
      "Epoch 75/100\n",
      "4222/4222 [==============================] - 2s 488us/step - loss: 0.0060 - acc: 0.9969 - val_loss: 0.0369 - val_acc: 0.9934\n",
      "Epoch 76/100\n",
      "4222/4222 [==============================] - 2s 557us/step - loss: 0.0069 - acc: 0.9967 - val_loss: 0.0307 - val_acc: 0.9934\n",
      "Epoch 77/100\n",
      "4222/4222 [==============================] - 2s 538us/step - loss: 0.0073 - acc: 0.9974 - val_loss: 0.0348 - val_acc: 0.9943\n",
      "Epoch 78/100\n",
      "4222/4222 [==============================] - 2s 496us/step - loss: 0.0140 - acc: 0.9948 - val_loss: 0.0469 - val_acc: 0.9953\n",
      "Epoch 79/100\n",
      "4222/4222 [==============================] - 2s 492us/step - loss: 0.0116 - acc: 0.9962 - val_loss: 0.0515 - val_acc: 0.9924\n",
      "Epoch 80/100\n",
      "4222/4222 [==============================] - 2s 499us/step - loss: 0.0128 - acc: 0.9964 - val_loss: 0.0640 - val_acc: 0.9905\n",
      "Epoch 81/100\n",
      "4222/4222 [==============================] - 2s 494us/step - loss: 0.0123 - acc: 0.9967 - val_loss: 0.0469 - val_acc: 0.9953\n",
      "Epoch 82/100\n",
      "4222/4222 [==============================] - 2s 529us/step - loss: 0.0124 - acc: 0.9950 - val_loss: 0.0563 - val_acc: 0.9924\n",
      "Epoch 83/100\n",
      "4222/4222 [==============================] - 2s 495us/step - loss: 0.0056 - acc: 0.9981 - val_loss: 0.0534 - val_acc: 0.9943\n",
      "Epoch 84/100\n",
      "4222/4222 [==============================] - 2s 522us/step - loss: 0.0082 - acc: 0.9979 - val_loss: 0.0516 - val_acc: 0.9905\n",
      "Epoch 85/100\n",
      "4222/4222 [==============================] - 2s 513us/step - loss: 0.0097 - acc: 0.9964 - val_loss: 0.0517 - val_acc: 0.9943\n",
      "Epoch 86/100\n",
      "4222/4222 [==============================] - 2s 524us/step - loss: 0.0135 - acc: 0.9948 - val_loss: 0.0458 - val_acc: 0.9943\n",
      "Epoch 87/100\n",
      "4222/4222 [==============================] - 2s 503us/step - loss: 0.0064 - acc: 0.9974 - val_loss: 0.0537 - val_acc: 0.9943\n",
      "Epoch 88/100\n",
      "4222/4222 [==============================] - 2s 520us/step - loss: 0.0070 - acc: 0.9986 - val_loss: 0.0455 - val_acc: 0.9943\n",
      "Epoch 89/100\n",
      "4222/4222 [==============================] - 2s 510us/step - loss: 0.0084 - acc: 0.9976 - val_loss: 0.0432 - val_acc: 0.9953\n",
      "Epoch 90/100\n",
      "4222/4222 [==============================] - 2s 496us/step - loss: 0.0054 - acc: 0.9974 - val_loss: 0.0484 - val_acc: 0.9924\n",
      "Epoch 91/100\n",
      "4222/4222 [==============================] - 2s 518us/step - loss: 0.0091 - acc: 0.9974 - val_loss: 0.0709 - val_acc: 0.9924\n",
      "Epoch 92/100\n",
      "4222/4222 [==============================] - 2s 520us/step - loss: 0.0081 - acc: 0.9974 - val_loss: 0.0542 - val_acc: 0.9924\n",
      "Epoch 93/100\n",
      "4222/4222 [==============================] - 2s 516us/step - loss: 0.0082 - acc: 0.9974 - val_loss: 0.0390 - val_acc: 0.9943\n",
      "Epoch 94/100\n",
      "4222/4222 [==============================] - 2s 520us/step - loss: 0.0060 - acc: 0.9981 - val_loss: 0.0481 - val_acc: 0.9943\n",
      "Epoch 95/100\n",
      "4222/4222 [==============================] - 2s 518us/step - loss: 0.0081 - acc: 0.9969 - val_loss: 0.0331 - val_acc: 0.9953\n",
      "Epoch 96/100\n",
      "4222/4222 [==============================] - 2s 521us/step - loss: 0.0066 - acc: 0.9976 - val_loss: 0.0395 - val_acc: 0.9943\n",
      "Epoch 97/100\n",
      "4222/4222 [==============================] - 2s 516us/step - loss: 0.0075 - acc: 0.9983 - val_loss: 0.0359 - val_acc: 0.9953\n",
      "Epoch 98/100\n",
      "4222/4222 [==============================] - 2s 496us/step - loss: 0.0038 - acc: 0.9986 - val_loss: 0.0316 - val_acc: 0.9953\n",
      "Epoch 99/100\n",
      "4222/4222 [==============================] - 2s 516us/step - loss: 0.0030 - acc: 0.9993 - val_loss: 0.0488 - val_acc: 0.9943\n",
      "Epoch 100/100\n",
      "4222/4222 [==============================] - 2s 520us/step - loss: 0.0082 - acc: 0.9981 - val_loss: 0.0445 - val_acc: 0.9924\n",
      "[[1118    2]\n",
      " [  12  188]]\n",
      "0.9893939393939394\n"
     ]
    }
   ],
   "source": [
    "classifier = Sequential()\n",
    "\n",
    "classifier.add(Dense(units = 50, kernel_initializer = 'he_uniform', activation = 'relu', input_dim = 166))\n",
    "classifier.add(Dropout(0.3))\n",
    "\n",
    "classifier.add(Dense(units = 6, kernel_initializer = 'he_uniform', activation = 'relu'))\n",
    "\n",
    "classifier.add(Dense(units = 1, kernel_initializer = 'glorot_uniform', activation = 'sigmoid'))\n",
    "\n",
    "classifier.summary()\n",
    "\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "model = classifier.fit(X_train, y_train, validation_split = 0.2, batch_size = 10, nb_epoch = 100)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "score = accuracy_score(y_pred, y_test)\n",
    "print(cm)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_399 (Dense)            (None, 120)               20040     \n",
      "_________________________________________________________________\n",
      "dense_400 (Dense)            (None, 6)                 726       \n",
      "_________________________________________________________________\n",
      "dense_401 (Dense)            (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 20,773\n",
      "Trainable params: 20,773\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "Train on 4222 samples, validate on 1056 samples\n",
      "Epoch 1/100\n",
      "4222/4222 [==============================] - 13s 3ms/step - loss: 0.1754 - acc: 0.9330 - val_loss: 0.1237 - val_acc: 0.9536\n",
      "Epoch 2/100\n",
      "4222/4222 [==============================] - 2s 507us/step - loss: 0.0934 - acc: 0.9652 - val_loss: 0.0916 - val_acc: 0.9631\n",
      "Epoch 3/100\n",
      "4222/4222 [==============================] - 2s 510us/step - loss: 0.0658 - acc: 0.9728 - val_loss: 0.0680 - val_acc: 0.9669\n",
      "Epoch 4/100\n",
      "4222/4222 [==============================] - 2s 510us/step - loss: 0.0462 - acc: 0.9813 - val_loss: 0.0650 - val_acc: 0.9706\n",
      "Epoch 5/100\n",
      "4222/4222 [==============================] - 2s 510us/step - loss: 0.0343 - acc: 0.9872 - val_loss: 0.0535 - val_acc: 0.9820\n",
      "Epoch 6/100\n",
      "4222/4222 [==============================] - 2s 516us/step - loss: 0.0254 - acc: 0.9910 - val_loss: 0.0444 - val_acc: 0.9867\n",
      "Epoch 7/100\n",
      "4222/4222 [==============================] - 2s 524us/step - loss: 0.0229 - acc: 0.9924 - val_loss: 0.0413 - val_acc: 0.9848\n",
      "Epoch 8/100\n",
      "4222/4222 [==============================] - 2s 523us/step - loss: 0.0120 - acc: 0.9981 - val_loss: 0.0320 - val_acc: 0.9896\n",
      "Epoch 9/100\n",
      "4222/4222 [==============================] - 2s 517us/step - loss: 0.0114 - acc: 0.9960 - val_loss: 0.0315 - val_acc: 0.9896\n",
      "Epoch 10/100\n",
      "4222/4222 [==============================] - 2s 518us/step - loss: 0.0111 - acc: 0.9964 - val_loss: 0.0554 - val_acc: 0.9858\n",
      "Epoch 11/100\n",
      "4222/4222 [==============================] - 2s 513us/step - loss: 0.0273 - acc: 0.9903 - val_loss: 0.0622 - val_acc: 0.9820\n",
      "Epoch 12/100\n",
      "4222/4222 [==============================] - 2s 516us/step - loss: 0.0077 - acc: 0.9979 - val_loss: 0.0447 - val_acc: 0.9886\n",
      "Epoch 13/100\n",
      "4222/4222 [==============================] - 2s 510us/step - loss: 0.0051 - acc: 0.9981 - val_loss: 0.0276 - val_acc: 0.9953\n",
      "Epoch 14/100\n",
      "4222/4222 [==============================] - 2s 509us/step - loss: 0.0019 - acc: 0.9998 - val_loss: 0.0265 - val_acc: 0.9943\n",
      "Epoch 15/100\n",
      "4222/4222 [==============================] - 2s 512us/step - loss: 0.0042 - acc: 0.9993 - val_loss: 0.0444 - val_acc: 0.9877\n",
      "Epoch 16/100\n",
      "4222/4222 [==============================] - 2s 521us/step - loss: 0.0446 - acc: 0.9893 - val_loss: 0.0315 - val_acc: 0.9886\n",
      "Epoch 17/100\n",
      "4222/4222 [==============================] - 2s 511us/step - loss: 0.0062 - acc: 0.9986 - val_loss: 0.0307 - val_acc: 0.9934\n",
      "Epoch 18/100\n",
      "4222/4222 [==============================] - 2s 521us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0306 - val_acc: 0.9943\n",
      "Epoch 19/100\n",
      "4222/4222 [==============================] - 2s 508us/step - loss: 7.9936e-04 - acc: 1.0000 - val_loss: 0.0277 - val_acc: 0.9943\n",
      "Epoch 20/100\n",
      "4222/4222 [==============================] - 3s 597us/step - loss: 6.4621e-04 - acc: 1.0000 - val_loss: 0.0322 - val_acc: 0.9943\n",
      "Epoch 21/100\n",
      "4222/4222 [==============================] - 2s 521us/step - loss: 5.1315e-04 - acc: 1.0000 - val_loss: 0.0293 - val_acc: 0.9943\n",
      "Epoch 22/100\n",
      "4222/4222 [==============================] - 2s 542us/step - loss: 5.3241e-04 - acc: 1.0000 - val_loss: 0.0286 - val_acc: 0.9943\n",
      "Epoch 23/100\n",
      "4222/4222 [==============================] - 2s 517us/step - loss: 4.0666e-04 - acc: 1.0000 - val_loss: 0.0285 - val_acc: 0.9953\n",
      "Epoch 24/100\n",
      "4222/4222 [==============================] - 2s 524us/step - loss: 0.0314 - acc: 0.9910 - val_loss: 0.1678 - val_acc: 0.9631\n",
      "Epoch 25/100\n",
      "4222/4222 [==============================] - 2s 547us/step - loss: 0.0257 - acc: 0.9924 - val_loss: 0.0258 - val_acc: 0.9943\n",
      "Epoch 26/100\n",
      "4222/4222 [==============================] - 2s 524us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0292 - val_acc: 0.9934\n",
      "Epoch 27/100\n",
      "4222/4222 [==============================] - 2s 522us/step - loss: 6.6985e-04 - acc: 1.0000 - val_loss: 0.0349 - val_acc: 0.9934\n",
      "Epoch 28/100\n",
      "4222/4222 [==============================] - 2s 519us/step - loss: 4.7090e-04 - acc: 1.0000 - val_loss: 0.0300 - val_acc: 0.9943\n",
      "Epoch 29/100\n",
      "4222/4222 [==============================] - 2s 521us/step - loss: 3.4890e-04 - acc: 1.0000 - val_loss: 0.0299 - val_acc: 0.9943\n",
      "Epoch 30/100\n",
      "4222/4222 [==============================] - 2s 522us/step - loss: 2.8159e-04 - acc: 1.0000 - val_loss: 0.0280 - val_acc: 0.9943\n",
      "Epoch 31/100\n",
      "4222/4222 [==============================] - 2s 548us/step - loss: 2.3147e-04 - acc: 1.0000 - val_loss: 0.0289 - val_acc: 0.9953\n",
      "Epoch 32/100\n",
      "4222/4222 [==============================] - 2s 522us/step - loss: 1.9140e-04 - acc: 1.0000 - val_loss: 0.0286 - val_acc: 0.9953\n",
      "Epoch 33/100\n",
      "4222/4222 [==============================] - 2s 526us/step - loss: 1.6274e-04 - acc: 1.0000 - val_loss: 0.0299 - val_acc: 0.9953\n",
      "Epoch 34/100\n",
      "4222/4222 [==============================] - 2s 522us/step - loss: 1.3726e-04 - acc: 1.0000 - val_loss: 0.0282 - val_acc: 0.9943\n",
      "Epoch 35/100\n",
      "4222/4222 [==============================] - 2s 527us/step - loss: 1.1748e-04 - acc: 1.0000 - val_loss: 0.0281 - val_acc: 0.9943\n",
      "Epoch 36/100\n",
      "4222/4222 [==============================] - 2s 529us/step - loss: 9.5420e-05 - acc: 1.0000 - val_loss: 0.0277 - val_acc: 0.9943\n",
      "Epoch 37/100\n",
      "4222/4222 [==============================] - 2s 520us/step - loss: 8.4036e-05 - acc: 1.0000 - val_loss: 0.0284 - val_acc: 0.9943\n",
      "Epoch 38/100\n",
      "4222/4222 [==============================] - 2s 533us/step - loss: 6.4129e-05 - acc: 1.0000 - val_loss: 0.0277 - val_acc: 0.9953\n",
      "Epoch 39/100\n",
      "4222/4222 [==============================] - 2s 552us/step - loss: 5.7002e-05 - acc: 1.0000 - val_loss: 0.0296 - val_acc: 0.9953\n",
      "Epoch 40/100\n",
      "4222/4222 [==============================] - 2s 515us/step - loss: 4.8484e-05 - acc: 1.0000 - val_loss: 0.0302 - val_acc: 0.9962\n",
      "Epoch 41/100\n",
      "4222/4222 [==============================] - 2s 522us/step - loss: 4.0795e-05 - acc: 1.0000 - val_loss: 0.0308 - val_acc: 0.9953\n",
      "Epoch 42/100\n",
      "4222/4222 [==============================] - 2s 532us/step - loss: 3.4646e-05 - acc: 1.0000 - val_loss: 0.0340 - val_acc: 0.9943\n",
      "Epoch 43/100\n",
      "4222/4222 [==============================] - 2s 526us/step - loss: 0.0728 - acc: 0.9865 - val_loss: 0.0582 - val_acc: 0.9896\n",
      "Epoch 44/100\n",
      "4222/4222 [==============================] - 2s 520us/step - loss: 0.0111 - acc: 0.9964 - val_loss: 0.0469 - val_acc: 0.9858\n",
      "Epoch 45/100\n",
      "4222/4222 [==============================] - 2s 520us/step - loss: 0.0040 - acc: 0.9983 - val_loss: 0.0615 - val_acc: 0.9915\n",
      "Epoch 46/100\n",
      "4222/4222 [==============================] - 2s 529us/step - loss: 8.4574e-04 - acc: 0.9998 - val_loss: 0.0395 - val_acc: 0.9934\n",
      "Epoch 47/100\n",
      "4222/4222 [==============================] - 2s 523us/step - loss: 1.7053e-04 - acc: 1.0000 - val_loss: 0.0398 - val_acc: 0.9934\n",
      "Epoch 48/100\n",
      "4222/4222 [==============================] - 2s 523us/step - loss: 1.3523e-04 - acc: 1.0000 - val_loss: 0.0397 - val_acc: 0.9934\n",
      "Epoch 49/100\n",
      "4222/4222 [==============================] - 2s 527us/step - loss: 1.1201e-04 - acc: 1.0000 - val_loss: 0.0391 - val_acc: 0.9924\n",
      "Epoch 50/100\n",
      "4222/4222 [==============================] - 2s 525us/step - loss: 9.3788e-05 - acc: 1.0000 - val_loss: 0.0400 - val_acc: 0.9924\n",
      "Epoch 51/100\n",
      "4222/4222 [==============================] - 2s 528us/step - loss: 8.1686e-05 - acc: 1.0000 - val_loss: 0.0377 - val_acc: 0.9934\n",
      "Epoch 52/100\n",
      "4222/4222 [==============================] - 2s 528us/step - loss: 7.1467e-05 - acc: 1.0000 - val_loss: 0.0389 - val_acc: 0.9924\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4222/4222 [==============================] - 2s 520us/step - loss: 6.2714e-05 - acc: 1.0000 - val_loss: 0.0379 - val_acc: 0.9924\n",
      "Epoch 54/100\n",
      "4222/4222 [==============================] - 2s 517us/step - loss: 5.4912e-05 - acc: 1.0000 - val_loss: 0.0379 - val_acc: 0.9924\n",
      "Epoch 55/100\n",
      "4222/4222 [==============================] - 2s 512us/step - loss: 4.7355e-05 - acc: 1.0000 - val_loss: 0.0366 - val_acc: 0.9934\n",
      "Epoch 56/100\n",
      "4222/4222 [==============================] - 2s 519us/step - loss: 4.1102e-05 - acc: 1.0000 - val_loss: 0.0383 - val_acc: 0.9924\n",
      "Epoch 57/100\n",
      "4222/4222 [==============================] - 2s 508us/step - loss: 3.7128e-05 - acc: 1.0000 - val_loss: 0.0368 - val_acc: 0.9934\n",
      "Epoch 58/100\n",
      "4222/4222 [==============================] - 2s 521us/step - loss: 3.2140e-05 - acc: 1.0000 - val_loss: 0.0360 - val_acc: 0.9934\n",
      "Epoch 59/100\n",
      "4222/4222 [==============================] - 2s 537us/step - loss: 2.6527e-05 - acc: 1.0000 - val_loss: 0.0391 - val_acc: 0.9934\n",
      "Epoch 60/100\n",
      "4222/4222 [==============================] - 2s 517us/step - loss: 2.6113e-05 - acc: 1.0000 - val_loss: 0.0373 - val_acc: 0.9924\n",
      "Epoch 61/100\n",
      "4222/4222 [==============================] - 2s 510us/step - loss: 2.0449e-05 - acc: 1.0000 - val_loss: 0.0377 - val_acc: 0.9924\n",
      "Epoch 62/100\n",
      "4222/4222 [==============================] - 2s 500us/step - loss: 0.0481 - acc: 0.9915 - val_loss: 0.0568 - val_acc: 0.9811\n",
      "Epoch 63/100\n",
      "4222/4222 [==============================] - 2s 508us/step - loss: 0.0128 - acc: 0.9953 - val_loss: 0.0411 - val_acc: 0.9924\n",
      "Epoch 64/100\n",
      "4222/4222 [==============================] - 2s 513us/step - loss: 0.0107 - acc: 0.9964 - val_loss: 0.0293 - val_acc: 0.9934\n",
      "Epoch 65/100\n",
      "4222/4222 [==============================] - 2s 503us/step - loss: 5.7851e-04 - acc: 1.0000 - val_loss: 0.0268 - val_acc: 0.9953\n",
      "Epoch 66/100\n",
      "4222/4222 [==============================] - 2s 528us/step - loss: 2.7768e-04 - acc: 1.0000 - val_loss: 0.0255 - val_acc: 0.9962\n",
      "Epoch 67/100\n",
      "4222/4222 [==============================] - 2s 506us/step - loss: 2.1112e-04 - acc: 1.0000 - val_loss: 0.0239 - val_acc: 0.9962\n",
      "Epoch 68/100\n",
      "4222/4222 [==============================] - 2s 511us/step - loss: 1.4198e-04 - acc: 1.0000 - val_loss: 0.0238 - val_acc: 0.9962\n",
      "Epoch 69/100\n",
      "4222/4222 [==============================] - 2s 548us/step - loss: 1.1397e-04 - acc: 1.0000 - val_loss: 0.0231 - val_acc: 0.9962\n",
      "Epoch 70/100\n",
      "4222/4222 [==============================] - 2s 564us/step - loss: 9.8591e-05 - acc: 1.0000 - val_loss: 0.0226 - val_acc: 0.9962\n",
      "Epoch 71/100\n",
      "4222/4222 [==============================] - 2s 550us/step - loss: 8.0367e-05 - acc: 1.0000 - val_loss: 0.0222 - val_acc: 0.9962\n",
      "Epoch 72/100\n",
      "4222/4222 [==============================] - 2s 518us/step - loss: 6.9018e-05 - acc: 1.0000 - val_loss: 0.0218 - val_acc: 0.9962\n",
      "Epoch 73/100\n",
      "4222/4222 [==============================] - 2s 551us/step - loss: 5.8069e-05 - acc: 1.0000 - val_loss: 0.0215 - val_acc: 0.9962\n",
      "Epoch 74/100\n",
      "4222/4222 [==============================] - 3s 615us/step - loss: 4.7764e-05 - acc: 1.0000 - val_loss: 0.0210 - val_acc: 0.9962\n",
      "Epoch 75/100\n",
      "4222/4222 [==============================] - 2s 561us/step - loss: 3.9169e-05 - acc: 1.0000 - val_loss: 0.0210 - val_acc: 0.9962\n",
      "Epoch 76/100\n",
      "4222/4222 [==============================] - 2s 526us/step - loss: 3.2974e-05 - acc: 1.0000 - val_loss: 0.0213 - val_acc: 0.9962\n",
      "Epoch 77/100\n",
      "4222/4222 [==============================] - 2s 544us/step - loss: 2.6997e-05 - acc: 1.0000 - val_loss: 0.0204 - val_acc: 0.9972\n",
      "Epoch 78/100\n",
      "4222/4222 [==============================] - 2s 514us/step - loss: 2.4494e-05 - acc: 1.0000 - val_loss: 0.0205 - val_acc: 0.9972\n",
      "Epoch 79/100\n",
      "4222/4222 [==============================] - 2s 551us/step - loss: 2.0192e-05 - acc: 1.0000 - val_loss: 0.0205 - val_acc: 0.9972\n",
      "Epoch 80/100\n",
      "4222/4222 [==============================] - 2s 538us/step - loss: 1.8778e-05 - acc: 1.0000 - val_loss: 0.0203 - val_acc: 0.9972\n",
      "Epoch 81/100\n",
      "4222/4222 [==============================] - 2s 540us/step - loss: 1.1933e-05 - acc: 1.0000 - val_loss: 0.0199 - val_acc: 0.9972\n",
      "Epoch 82/100\n",
      "4222/4222 [==============================] - 2s 551us/step - loss: 1.0252e-05 - acc: 1.0000 - val_loss: 0.0201 - val_acc: 0.9972\n",
      "Epoch 83/100\n",
      "4222/4222 [==============================] - 2s 541us/step - loss: 7.8299e-06 - acc: 1.0000 - val_loss: 0.0199 - val_acc: 0.9972\n",
      "Epoch 84/100\n",
      "4222/4222 [==============================] - 2s 558us/step - loss: 6.4883e-06 - acc: 1.0000 - val_loss: 0.0200 - val_acc: 0.9972\n",
      "Epoch 85/100\n",
      "4222/4222 [==============================] - 2s 550us/step - loss: 5.5874e-06 - acc: 1.0000 - val_loss: 0.0200 - val_acc: 0.9972\n",
      "Epoch 86/100\n",
      "4222/4222 [==============================] - 3s 596us/step - loss: 4.5033e-06 - acc: 1.0000 - val_loss: 0.0200 - val_acc: 0.9972\n",
      "Epoch 87/100\n",
      "4222/4222 [==============================] - 2s 559us/step - loss: 3.8719e-06 - acc: 1.0000 - val_loss: 0.0207 - val_acc: 0.9962\n",
      "Epoch 88/100\n",
      "4222/4222 [==============================] - 2s 523us/step - loss: 3.0354e-06 - acc: 1.0000 - val_loss: 0.0212 - val_acc: 0.9972\n",
      "Epoch 89/100\n",
      "4222/4222 [==============================] - 3s 599us/step - loss: 2.5071e-06 - acc: 1.0000 - val_loss: 0.0208 - val_acc: 0.9972\n",
      "Epoch 90/100\n",
      "4222/4222 [==============================] - 3s 667us/step - loss: 2.0658e-06 - acc: 1.0000 - val_loss: 0.0199 - val_acc: 0.9981\n",
      "Epoch 91/100\n",
      "4222/4222 [==============================] - 3s 615us/step - loss: 1.7121e-06 - acc: 1.0000 - val_loss: 0.0213 - val_acc: 0.9962\n",
      "Epoch 92/100\n",
      "4222/4222 [==============================] - 2s 580us/step - loss: 1.4946e-06 - acc: 1.0000 - val_loss: 0.0221 - val_acc: 0.9953\n",
      "Epoch 93/100\n",
      "4222/4222 [==============================] - 3s 602us/step - loss: 0.0362 - acc: 0.9929 - val_loss: 0.0401 - val_acc: 0.9905\n",
      "Epoch 94/100\n",
      "4222/4222 [==============================] - 2s 526us/step - loss: 0.0208 - acc: 0.9957 - val_loss: 0.0555 - val_acc: 0.9934\n",
      "Epoch 95/100\n",
      "4222/4222 [==============================] - 2s 513us/step - loss: 0.0021 - acc: 0.9995 - val_loss: 0.0254 - val_acc: 0.9972\n",
      "Epoch 96/100\n",
      "4222/4222 [==============================] - 2s 554us/step - loss: 2.9812e-04 - acc: 1.0000 - val_loss: 0.0282 - val_acc: 0.9972\n",
      "Epoch 97/100\n",
      "4222/4222 [==============================] - 2s 554us/step - loss: 1.4941e-04 - acc: 1.0000 - val_loss: 0.0294 - val_acc: 0.9972\n",
      "Epoch 98/100\n",
      "4222/4222 [==============================] - 2s 544us/step - loss: 1.1502e-04 - acc: 1.0000 - val_loss: 0.0300 - val_acc: 0.9972\n",
      "Epoch 99/100\n",
      "4222/4222 [==============================] - 2s 571us/step - loss: 9.8527e-05 - acc: 1.0000 - val_loss: 0.0296 - val_acc: 0.9972\n",
      "Epoch 100/100\n",
      "4222/4222 [==============================] - 2s 545us/step - loss: 1.0680e-04 - acc: 1.0000 - val_loss: 0.0307 - val_acc: 0.9972\n",
      "[[1117    3]\n",
      " [   2  198]]\n",
      "0.9962121212121212\n"
     ]
    }
   ],
   "source": [
    "classifier = Sequential()\n",
    "\n",
    "classifier.add(Dense(units = 120, kernel_initializer = 'he_uniform', activation = 'relu', input_dim = 166))\n",
    "\n",
    "classifier.add(Dense(units = 6, kernel_initializer = 'he_uniform', activation = 'relu'))\n",
    "\n",
    "classifier.add(Dense(units = 1, kernel_initializer = 'glorot_uniform', activation = 'sigmoid'))\n",
    "\n",
    "classifier.summary()\n",
    "\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "model = classifier.fit(X_train, y_train, validation_split = 0.2, batch_size = 10, nb_epoch = 100)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "score = accuracy_score(y_pred, y_test)\n",
    "print(cm)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_402 (Dense)            (None, 120)               20040     \n",
      "_________________________________________________________________\n",
      "dense_403 (Dense)            (None, 50)                6050      \n",
      "_________________________________________________________________\n",
      "dense_404 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 26,141\n",
      "Trainable params: 26,141\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "Train on 4222 samples, validate on 1056 samples\n",
      "Epoch 1/100\n",
      "4222/4222 [==============================] - 13s 3ms/step - loss: 0.1724 - acc: 0.9311 - val_loss: 0.1111 - val_acc: 0.9612\n",
      "Epoch 2/100\n",
      "4222/4222 [==============================] - 2s 506us/step - loss: 0.0872 - acc: 0.9664 - val_loss: 0.0771 - val_acc: 0.9687\n",
      "Epoch 3/100\n",
      "4222/4222 [==============================] - 2s 520us/step - loss: 0.0539 - acc: 0.9777 - val_loss: 0.0672 - val_acc: 0.9706\n",
      "Epoch 4/100\n",
      "4222/4222 [==============================] - 2s 510us/step - loss: 0.0397 - acc: 0.9832 - val_loss: 0.0598 - val_acc: 0.9782\n",
      "Epoch 5/100\n",
      "4222/4222 [==============================] - 2s 528us/step - loss: 0.0323 - acc: 0.9870 - val_loss: 0.0481 - val_acc: 0.9839\n",
      "Epoch 6/100\n",
      "4222/4222 [==============================] - 3s 603us/step - loss: 0.0241 - acc: 0.9922 - val_loss: 0.1914 - val_acc: 0.9403\n",
      "Epoch 7/100\n",
      "4222/4222 [==============================] - 2s 566us/step - loss: 0.0219 - acc: 0.9929 - val_loss: 0.0414 - val_acc: 0.9839\n",
      "Epoch 8/100\n",
      "4222/4222 [==============================] - 2s 511us/step - loss: 0.0127 - acc: 0.9962 - val_loss: 0.0351 - val_acc: 0.9867\n",
      "Epoch 9/100\n",
      "4222/4222 [==============================] - 2s 514us/step - loss: 0.0110 - acc: 0.9964 - val_loss: 0.0397 - val_acc: 0.9839\n",
      "Epoch 10/100\n",
      "4222/4222 [==============================] - 2s 528us/step - loss: 0.0111 - acc: 0.9969 - val_loss: 0.0775 - val_acc: 0.9820\n",
      "Epoch 11/100\n",
      "4222/4222 [==============================] - 2s 585us/step - loss: 0.0410 - acc: 0.9884 - val_loss: 0.0470 - val_acc: 0.9830\n",
      "Epoch 12/100\n",
      "4222/4222 [==============================] - 2s 559us/step - loss: 0.0080 - acc: 0.9969 - val_loss: 0.0369 - val_acc: 0.9886\n",
      "Epoch 13/100\n",
      "4222/4222 [==============================] - 2s 512us/step - loss: 0.0055 - acc: 0.9983 - val_loss: 0.0233 - val_acc: 0.9915\n",
      "Epoch 14/100\n",
      "4222/4222 [==============================] - 2s 526us/step - loss: 0.0026 - acc: 0.9995 - val_loss: 0.0194 - val_acc: 0.9924\n",
      "Epoch 15/100\n",
      "4222/4222 [==============================] - 2s 514us/step - loss: 0.0088 - acc: 0.9969 - val_loss: 0.0325 - val_acc: 0.9886\n",
      "Epoch 16/100\n",
      "4222/4222 [==============================] - 2s 550us/step - loss: 0.0214 - acc: 0.9927 - val_loss: 0.0513 - val_acc: 0.9839\n",
      "Epoch 17/100\n",
      "4222/4222 [==============================] - 2s 526us/step - loss: 0.0128 - acc: 0.9953 - val_loss: 0.0528 - val_acc: 0.9858\n",
      "Epoch 18/100\n",
      "4222/4222 [==============================] - 2s 514us/step - loss: 0.0025 - acc: 0.9995 - val_loss: 0.0279 - val_acc: 0.9943\n",
      "Epoch 19/100\n",
      "4222/4222 [==============================] - 2s 525us/step - loss: 4.9350e-04 - acc: 1.0000 - val_loss: 0.0260 - val_acc: 0.9943\n",
      "Epoch 20/100\n",
      "4222/4222 [==============================] - 2s 537us/step - loss: 2.9944e-04 - acc: 1.0000 - val_loss: 0.0261 - val_acc: 0.9943\n",
      "Epoch 21/100\n",
      "4222/4222 [==============================] - 2s 532us/step - loss: 2.4292e-04 - acc: 1.0000 - val_loss: 0.0244 - val_acc: 0.9943\n",
      "Epoch 22/100\n",
      "4222/4222 [==============================] - 2s 518us/step - loss: 1.7461e-04 - acc: 1.0000 - val_loss: 0.0241 - val_acc: 0.9943\n",
      "Epoch 23/100\n",
      "4222/4222 [==============================] - 2s 564us/step - loss: 1.3401e-04 - acc: 1.0000 - val_loss: 0.0243 - val_acc: 0.9934\n",
      "Epoch 24/100\n",
      "4222/4222 [==============================] - 2s 523us/step - loss: 1.1740e-04 - acc: 1.0000 - val_loss: 0.0244 - val_acc: 0.9934\n",
      "Epoch 25/100\n",
      "4222/4222 [==============================] - 2s 524us/step - loss: 8.2149e-05 - acc: 1.0000 - val_loss: 0.0253 - val_acc: 0.9943\n",
      "Epoch 26/100\n",
      "4222/4222 [==============================] - 2s 516us/step - loss: 6.5581e-05 - acc: 1.0000 - val_loss: 0.0243 - val_acc: 0.9943\n",
      "Epoch 27/100\n",
      "4222/4222 [==============================] - 2s 516us/step - loss: 5.2582e-05 - acc: 1.0000 - val_loss: 0.0238 - val_acc: 0.9943\n",
      "Epoch 28/100\n",
      "4222/4222 [==============================] - 2s 535us/step - loss: 4.1481e-05 - acc: 1.0000 - val_loss: 0.0240 - val_acc: 0.9943\n",
      "Epoch 29/100\n",
      "4222/4222 [==============================] - 2s 511us/step - loss: 3.2084e-05 - acc: 1.0000 - val_loss: 0.0230 - val_acc: 0.9943\n",
      "Epoch 30/100\n",
      "4222/4222 [==============================] - 2s 518us/step - loss: 2.6018e-05 - acc: 1.0000 - val_loss: 0.0228 - val_acc: 0.9934\n",
      "Epoch 31/100\n",
      "4222/4222 [==============================] - 2s 516us/step - loss: 1.9748e-05 - acc: 1.0000 - val_loss: 0.0227 - val_acc: 0.9943\n",
      "Epoch 32/100\n",
      "4222/4222 [==============================] - 2s 515us/step - loss: 1.9641e-05 - acc: 1.0000 - val_loss: 0.0232 - val_acc: 0.9934\n",
      "Epoch 33/100\n",
      "4222/4222 [==============================] - 2s 511us/step - loss: 1.3096e-05 - acc: 1.0000 - val_loss: 0.0221 - val_acc: 0.9943\n",
      "Epoch 34/100\n",
      "4222/4222 [==============================] - 2s 516us/step - loss: 9.4711e-06 - acc: 1.0000 - val_loss: 0.0227 - val_acc: 0.9953\n",
      "Epoch 35/100\n",
      "4222/4222 [==============================] - 2s 511us/step - loss: 7.2082e-06 - acc: 1.0000 - val_loss: 0.0249 - val_acc: 0.9924\n",
      "Epoch 36/100\n",
      "4222/4222 [==============================] - 2s 587us/step - loss: 6.1376e-06 - acc: 1.0000 - val_loss: 0.0219 - val_acc: 0.9953\n",
      "Epoch 37/100\n",
      "4222/4222 [==============================] - 2s 556us/step - loss: 4.9015e-06 - acc: 1.0000 - val_loss: 0.0230 - val_acc: 0.9943\n",
      "Epoch 38/100\n",
      "4222/4222 [==============================] - 2s 548us/step - loss: 0.1721 - acc: 0.9860 - val_loss: 0.7929 - val_acc: 0.9280\n",
      "Epoch 39/100\n",
      "4222/4222 [==============================] - 3s 617us/step - loss: 0.1016 - acc: 0.9799 - val_loss: 0.0446 - val_acc: 0.9896\n",
      "Epoch 40/100\n",
      "4222/4222 [==============================] - 2s 495us/step - loss: 0.0032 - acc: 0.9993 - val_loss: 0.0418 - val_acc: 0.9915\n",
      "Epoch 41/100\n",
      "4222/4222 [==============================] - 2s 499us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0404 - val_acc: 0.9924\n",
      "Epoch 42/100\n",
      "4222/4222 [==============================] - 2s 492us/step - loss: 0.0041 - acc: 0.9981 - val_loss: 0.0356 - val_acc: 0.9915\n",
      "Epoch 43/100\n",
      "4222/4222 [==============================] - 2s 498us/step - loss: 0.0027 - acc: 0.9991 - val_loss: 0.0330 - val_acc: 0.9915\n",
      "Epoch 44/100\n",
      "4222/4222 [==============================] - 2s 501us/step - loss: 3.0633e-04 - acc: 1.0000 - val_loss: 0.0338 - val_acc: 0.9924\n",
      "Epoch 45/100\n",
      "4222/4222 [==============================] - 2s 510us/step - loss: 2.2121e-04 - acc: 1.0000 - val_loss: 0.0337 - val_acc: 0.9915\n",
      "Epoch 46/100\n",
      "4222/4222 [==============================] - 2s 502us/step - loss: 1.3736e-04 - acc: 1.0000 - val_loss: 0.0329 - val_acc: 0.9934\n",
      "Epoch 47/100\n",
      "4222/4222 [==============================] - 2s 506us/step - loss: 1.0108e-04 - acc: 1.0000 - val_loss: 0.0323 - val_acc: 0.9934\n",
      "Epoch 48/100\n",
      "4222/4222 [==============================] - 2s 530us/step - loss: 7.8512e-05 - acc: 1.0000 - val_loss: 0.0337 - val_acc: 0.9924\n",
      "Epoch 49/100\n",
      "4222/4222 [==============================] - 2s 509us/step - loss: 6.3809e-05 - acc: 1.0000 - val_loss: 0.0336 - val_acc: 0.9924\n",
      "Epoch 50/100\n",
      "4222/4222 [==============================] - 2s 508us/step - loss: 5.3187e-05 - acc: 1.0000 - val_loss: 0.0332 - val_acc: 0.9924\n",
      "Epoch 51/100\n",
      "4222/4222 [==============================] - 2s 503us/step - loss: 3.9677e-05 - acc: 1.0000 - val_loss: 0.0353 - val_acc: 0.9934\n",
      "Epoch 52/100\n",
      "4222/4222 [==============================] - 2s 503us/step - loss: 3.2493e-05 - acc: 1.0000 - val_loss: 0.0341 - val_acc: 0.9924\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4222/4222 [==============================] - 3s 608us/step - loss: 2.7423e-05 - acc: 1.0000 - val_loss: 0.0353 - val_acc: 0.9924\n",
      "Epoch 54/100\n",
      "4222/4222 [==============================] - 2s 554us/step - loss: 2.0923e-05 - acc: 1.0000 - val_loss: 0.0354 - val_acc: 0.9924\n",
      "Epoch 55/100\n",
      "4222/4222 [==============================] - 2s 508us/step - loss: 1.8148e-05 - acc: 1.0000 - val_loss: 0.0350 - val_acc: 0.9924\n",
      "Epoch 56/100\n",
      "4222/4222 [==============================] - 2s 504us/step - loss: 1.3515e-05 - acc: 1.0000 - val_loss: 0.0365 - val_acc: 0.9924\n",
      "Epoch 57/100\n",
      "4222/4222 [==============================] - 2s 510us/step - loss: 1.0733e-05 - acc: 1.0000 - val_loss: 0.0355 - val_acc: 0.9924\n",
      "Epoch 58/100\n",
      "4222/4222 [==============================] - 2s 505us/step - loss: 8.2460e-06 - acc: 1.0000 - val_loss: 0.0363 - val_acc: 0.9924\n",
      "Epoch 59/100\n",
      "4222/4222 [==============================] - 2s 507us/step - loss: 6.4869e-06 - acc: 1.0000 - val_loss: 0.0373 - val_acc: 0.9924\n",
      "Epoch 60/100\n",
      "4222/4222 [==============================] - 2s 510us/step - loss: 4.9515e-06 - acc: 1.0000 - val_loss: 0.0365 - val_acc: 0.9924\n",
      "Epoch 61/100\n",
      "4222/4222 [==============================] - 2s 509us/step - loss: 3.8212e-06 - acc: 1.0000 - val_loss: 0.0383 - val_acc: 0.9924\n",
      "Epoch 62/100\n",
      "4222/4222 [==============================] - 2s 509us/step - loss: 3.4781e-06 - acc: 1.0000 - val_loss: 0.0374 - val_acc: 0.9924\n",
      "Epoch 63/100\n",
      "4222/4222 [==============================] - 2s 508us/step - loss: 2.6888e-06 - acc: 1.0000 - val_loss: 0.0377 - val_acc: 0.9924\n",
      "Epoch 64/100\n",
      "4222/4222 [==============================] - 2s 511us/step - loss: 2.3129e-06 - acc: 1.0000 - val_loss: 0.0380 - val_acc: 0.9924\n",
      "Epoch 65/100\n",
      "4222/4222 [==============================] - 2s 506us/step - loss: 1.7909e-06 - acc: 1.0000 - val_loss: 0.0391 - val_acc: 0.9924\n",
      "Epoch 66/100\n",
      "4222/4222 [==============================] - 2s 504us/step - loss: 1.4324e-06 - acc: 1.0000 - val_loss: 0.0391 - val_acc: 0.9924\n",
      "Epoch 67/100\n",
      "4222/4222 [==============================] - 2s 504us/step - loss: 1.1412e-06 - acc: 1.0000 - val_loss: 0.0396 - val_acc: 0.9924\n",
      "Epoch 68/100\n",
      "4222/4222 [==============================] - 2s 507us/step - loss: 9.3118e-07 - acc: 1.0000 - val_loss: 0.0383 - val_acc: 0.9924\n",
      "Epoch 69/100\n",
      "4222/4222 [==============================] - 2s 512us/step - loss: 7.7654e-07 - acc: 1.0000 - val_loss: 0.0400 - val_acc: 0.9924\n",
      "Epoch 70/100\n",
      "4222/4222 [==============================] - 2s 514us/step - loss: 6.1936e-07 - acc: 1.0000 - val_loss: 0.0398 - val_acc: 0.9924\n",
      "Epoch 71/100\n",
      "4222/4222 [==============================] - 2s 506us/step - loss: 5.2811e-07 - acc: 1.0000 - val_loss: 0.0397 - val_acc: 0.9924\n",
      "Epoch 72/100\n",
      "4222/4222 [==============================] - 2s 506us/step - loss: 4.8013e-07 - acc: 1.0000 - val_loss: 0.0387 - val_acc: 0.9924\n",
      "Epoch 73/100\n",
      "4222/4222 [==============================] - 2s 505us/step - loss: 3.7681e-07 - acc: 1.0000 - val_loss: 0.0401 - val_acc: 0.9924\n",
      "Epoch 74/100\n",
      "4222/4222 [==============================] - 2s 507us/step - loss: 3.0731e-07 - acc: 1.0000 - val_loss: 0.0433 - val_acc: 0.9924\n",
      "Epoch 75/100\n",
      "4222/4222 [==============================] - 2s 510us/step - loss: 2.7526e-07 - acc: 1.0000 - val_loss: 0.0418 - val_acc: 0.9924\n",
      "Epoch 76/100\n",
      "4222/4222 [==============================] - 2s 510us/step - loss: 2.2425e-07 - acc: 1.0000 - val_loss: 0.0409 - val_acc: 0.9924\n",
      "Epoch 77/100\n",
      "4222/4222 [==============================] - 2s 506us/step - loss: 2.0076e-07 - acc: 1.0000 - val_loss: 0.0432 - val_acc: 0.9924\n",
      "Epoch 78/100\n",
      "4222/4222 [==============================] - 2s 509us/step - loss: 1.7957e-07 - acc: 1.0000 - val_loss: 0.0434 - val_acc: 0.9924\n",
      "Epoch 79/100\n",
      "4222/4222 [==============================] - 3s 600us/step - loss: 1.6703e-07 - acc: 1.0000 - val_loss: 0.0439 - val_acc: 0.9924\n",
      "Epoch 80/100\n",
      "4222/4222 [==============================] - 2s 509us/step - loss: 1.6360e-07 - acc: 1.0000 - val_loss: 0.0451 - val_acc: 0.9924\n",
      "Epoch 81/100\n",
      "4222/4222 [==============================] - 2s 535us/step - loss: 1.4213e-07 - acc: 1.0000 - val_loss: 0.0446 - val_acc: 0.9924\n",
      "Epoch 82/100\n",
      "4222/4222 [==============================] - 2s 507us/step - loss: 0.1438 - acc: 0.9834 - val_loss: 0.1508 - val_acc: 0.9744\n",
      "Epoch 83/100\n",
      "4222/4222 [==============================] - 2s 516us/step - loss: 0.0366 - acc: 0.9903 - val_loss: 0.0526 - val_acc: 0.9905\n",
      "Epoch 84/100\n",
      "4222/4222 [==============================] - 2s 524us/step - loss: 0.0014 - acc: 0.9998 - val_loss: 0.0460 - val_acc: 0.9924\n",
      "Epoch 85/100\n",
      "4222/4222 [==============================] - 2s 535us/step - loss: 3.9494e-04 - acc: 1.0000 - val_loss: 0.0457 - val_acc: 0.9905\n",
      "Epoch 86/100\n",
      "4222/4222 [==============================] - 2s 518us/step - loss: 2.6406e-04 - acc: 1.0000 - val_loss: 0.0434 - val_acc: 0.9924\n",
      "Epoch 87/100\n",
      "4222/4222 [==============================] - 2s 516us/step - loss: 1.6366e-04 - acc: 1.0000 - val_loss: 0.0433 - val_acc: 0.9924\n",
      "Epoch 88/100\n",
      "4222/4222 [==============================] - 2s 529us/step - loss: 1.1865e-04 - acc: 1.0000 - val_loss: 0.0428 - val_acc: 0.9924\n",
      "Epoch 89/100\n",
      "4222/4222 [==============================] - 2s 564us/step - loss: 8.7365e-05 - acc: 1.0000 - val_loss: 0.0436 - val_acc: 0.9924\n",
      "Epoch 90/100\n",
      "4222/4222 [==============================] - 2s 550us/step - loss: 6.6710e-05 - acc: 1.0000 - val_loss: 0.0430 - val_acc: 0.9915\n",
      "Epoch 91/100\n",
      "4222/4222 [==============================] - 2s 568us/step - loss: 5.6967e-05 - acc: 1.0000 - val_loss: 0.0444 - val_acc: 0.9924\n",
      "Epoch 92/100\n",
      "4222/4222 [==============================] - 2s 522us/step - loss: 4.0429e-05 - acc: 1.0000 - val_loss: 0.0435 - val_acc: 0.9924\n",
      "Epoch 93/100\n",
      "4222/4222 [==============================] - 2s 520us/step - loss: 3.0114e-05 - acc: 1.0000 - val_loss: 0.0432 - val_acc: 0.9924\n",
      "Epoch 94/100\n",
      "4222/4222 [==============================] - 2s 515us/step - loss: 2.5247e-05 - acc: 1.0000 - val_loss: 0.0435 - val_acc: 0.9924\n",
      "Epoch 95/100\n",
      "4222/4222 [==============================] - 2s 519us/step - loss: 1.9612e-05 - acc: 1.0000 - val_loss: 0.0434 - val_acc: 0.9924\n",
      "Epoch 96/100\n",
      "4222/4222 [==============================] - 3s 592us/step - loss: 1.6257e-05 - acc: 1.0000 - val_loss: 0.0443 - val_acc: 0.9915\n",
      "Epoch 97/100\n",
      "4222/4222 [==============================] - 2s 538us/step - loss: 1.2818e-05 - acc: 1.0000 - val_loss: 0.0443 - val_acc: 0.9915\n",
      "Epoch 98/100\n",
      "4222/4222 [==============================] - 2s 545us/step - loss: 1.0903e-05 - acc: 1.0000 - val_loss: 0.0448 - val_acc: 0.9915\n",
      "Epoch 99/100\n",
      "4222/4222 [==============================] - 2s 531us/step - loss: 8.6612e-06 - acc: 1.0000 - val_loss: 0.0466 - val_acc: 0.9924\n",
      "Epoch 100/100\n",
      "4222/4222 [==============================] - 2s 524us/step - loss: 7.4874e-06 - acc: 1.0000 - val_loss: 0.0464 - val_acc: 0.9915\n",
      "[[1117    3]\n",
      " [   5  195]]\n",
      "0.9939393939393939\n"
     ]
    }
   ],
   "source": [
    "classifier = Sequential()\n",
    "\n",
    "classifier.add(Dense(units = 120, kernel_initializer = 'he_uniform', activation = 'relu', input_dim = 166))\n",
    "\n",
    "classifier.add(Dense(units = 50, kernel_initializer = 'he_uniform', activation = 'relu'))\n",
    "\n",
    "classifier.add(Dense(units = 1, kernel_initializer = 'glorot_uniform', activation = 'sigmoid'))\n",
    "\n",
    "classifier.summary()\n",
    "\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "model = classifier.fit(X_train, y_train, validation_split = 0.2, batch_size = 10, nb_epoch = 100)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "score = accuracy_score(y_pred, y_test)\n",
    "print(cm)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_405 (Dense)            (None, 120)               20040     \n",
      "_________________________________________________________________\n",
      "dense_406 (Dense)            (None, 6)                 726       \n",
      "_________________________________________________________________\n",
      "dense_407 (Dense)            (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 20,773\n",
      "Trainable params: 20,773\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "Train on 4222 samples, validate on 1056 samples\n",
      "Epoch 1/10\n",
      "4222/4222 [==============================] - 13s 3ms/step - loss: 0.1882 - acc: 0.9230 - val_loss: 0.1202 - val_acc: 0.9545\n",
      "Epoch 2/10\n",
      "4222/4222 [==============================] - 2s 521us/step - loss: 0.0967 - acc: 0.9642 - val_loss: 0.1068 - val_acc: 0.9564\n",
      "Epoch 3/10\n",
      "4222/4222 [==============================] - 2s 513us/step - loss: 0.0724 - acc: 0.9725 - val_loss: 0.0759 - val_acc: 0.9716\n",
      "Epoch 4/10\n",
      "4222/4222 [==============================] - 2s 524us/step - loss: 0.0502 - acc: 0.9813 - val_loss: 0.0539 - val_acc: 0.9811\n",
      "Epoch 5/10\n",
      "4222/4222 [==============================] - 2s 563us/step - loss: 0.0392 - acc: 0.9841 - val_loss: 0.0432 - val_acc: 0.9867\n",
      "Epoch 6/10\n",
      "4222/4222 [==============================] - 2s 531us/step - loss: 0.0310 - acc: 0.9882 - val_loss: 0.0463 - val_acc: 0.9820\n",
      "Epoch 7/10\n",
      "4222/4222 [==============================] - 2s 523us/step - loss: 0.0215 - acc: 0.9908 - val_loss: 0.0436 - val_acc: 0.9877\n",
      "Epoch 8/10\n",
      "4222/4222 [==============================] - 2s 545us/step - loss: 0.0243 - acc: 0.9908 - val_loss: 0.0550 - val_acc: 0.9820\n",
      "Epoch 9/10\n",
      "4222/4222 [==============================] - 2s 553us/step - loss: 0.0136 - acc: 0.9948 - val_loss: 0.0328 - val_acc: 0.9877\n",
      "Epoch 10/10\n",
      "4222/4222 [==============================] - 2s 526us/step - loss: 0.0350 - acc: 0.9898 - val_loss: 0.0363 - val_acc: 0.9886\n",
      "[[1116    4]\n",
      " [   6  194]]\n",
      "0.9924242424242424\n"
     ]
    }
   ],
   "source": [
    "classifier = Sequential()\n",
    "\n",
    "classifier.add(Dense(units = 120, kernel_initializer = 'he_uniform', activation = 'relu', input_dim = 166))\n",
    "\n",
    "classifier.add(Dense(units = 6, kernel_initializer = 'he_uniform', activation = 'relu'))\n",
    "\n",
    "classifier.add(Dense(units = 1, kernel_initializer = 'glorot_uniform', activation = 'sigmoid'))\n",
    "\n",
    "classifier.summary()\n",
    "\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "model = classifier.fit(X_train, y_train, validation_split = 0.2, batch_size = 10, nb_epoch = 10)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "score = accuracy_score(y_pred, y_test)\n",
    "print(cm)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_408 (Dense)            (None, 120)               20040     \n",
      "_________________________________________________________________\n",
      "dense_409 (Dense)            (None, 6)                 726       \n",
      "_________________________________________________________________\n",
      "dense_410 (Dense)            (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 20,773\n",
      "Trainable params: 20,773\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "Train on 4222 samples, validate on 1056 samples\n",
      "Epoch 1/10\n",
      "4222/4222 [==============================] - 12s 3ms/step - loss: 0.3403 - acc: 0.8629 - val_loss: 0.2137 - val_acc: 0.9167\n",
      "Epoch 2/10\n",
      "4222/4222 [==============================] - 0s 58us/step - loss: 0.1793 - acc: 0.9237 - val_loss: 0.1601 - val_acc: 0.9337\n",
      "Epoch 3/10\n",
      "4222/4222 [==============================] - 0s 60us/step - loss: 0.1408 - acc: 0.9382 - val_loss: 0.1371 - val_acc: 0.9489\n",
      "Epoch 4/10\n",
      "4222/4222 [==============================] - 0s 58us/step - loss: 0.1190 - acc: 0.9576 - val_loss: 0.1199 - val_acc: 0.9612\n",
      "Epoch 5/10\n",
      "4222/4222 [==============================] - 0s 57us/step - loss: 0.1019 - acc: 0.9642 - val_loss: 0.1101 - val_acc: 0.9621\n",
      "Epoch 6/10\n",
      "4222/4222 [==============================] - 0s 81us/step - loss: 0.0875 - acc: 0.9716 - val_loss: 0.1045 - val_acc: 0.9631\n",
      "Epoch 7/10\n",
      "4222/4222 [==============================] - 0s 57us/step - loss: 0.0792 - acc: 0.9704 - val_loss: 0.0878 - val_acc: 0.9697\n",
      "Epoch 8/10\n",
      "4222/4222 [==============================] - 0s 58us/step - loss: 0.0668 - acc: 0.9761 - val_loss: 0.0810 - val_acc: 0.9716\n",
      "Epoch 9/10\n",
      "4222/4222 [==============================] - 0s 74us/step - loss: 0.0555 - acc: 0.9825 - val_loss: 0.0726 - val_acc: 0.9744\n",
      "Epoch 10/10\n",
      "4222/4222 [==============================] - 0s 71us/step - loss: 0.0482 - acc: 0.9839 - val_loss: 0.0648 - val_acc: 0.9792\n",
      "[[1115    5]\n",
      " [  26  174]]\n",
      "0.9765151515151516\n"
     ]
    }
   ],
   "source": [
    "classifier = Sequential()\n",
    "\n",
    "classifier.add(Dense(units = 120, kernel_initializer = 'he_uniform', activation = 'relu', input_dim = 166))\n",
    "\n",
    "classifier.add(Dense(units = 6, kernel_initializer = 'he_uniform', activation = 'relu'))\n",
    "\n",
    "classifier.add(Dense(units = 1, kernel_initializer = 'glorot_uniform', activation = 'sigmoid'))\n",
    "\n",
    "classifier.summary()\n",
    "\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "model = classifier.fit(X_train, y_train, validation_split = 0.2, batch_size = 100, nb_epoch = 10)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "score = accuracy_score(y_pred, y_test)\n",
    "print(cm)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
